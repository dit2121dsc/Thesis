{
    "paper_id": "3514221",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2024-03-20T17:53:04.766211Z"
    },
    "title": "LearnedSQLGen: Constraint-aware SQL Generation using Reinforcement Learning",
    "authors": [
        {
            "first": "Lixi",
            "middle": [],
            "last": "Zhang",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Tsinghua University",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Chengliang",
            "middle": [],
            "last": "Chai",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Tsinghua University",
                "location": {}
            },
            "email": ""
        },
        {
            "first": "Xuanhe",
            "middle": [],
            "last": "Zhou",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Tsinghua University",
                "location": {}
            },
            "email": "zhouxuan19@mails.tsinghua.edu.cn"
        },
        {
            "first": "Guoliang",
            "middle": [],
            "last": "Li",
            "suffix": "",
            "affiliation": {
                "laboratory": "",
                "institution": "Tsinghua University",
                "location": {}
            },
            "email": "liguoliang@tsinghua.edu.cn"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Many database optimization problems, e.g., slow SQL diagnosis, database testing, optimizer tuning, require a large volume of SQL queries. Due to privacy issues, it is hard to obtain real SQL queries, and thus SQL generation is a very important task in database optimization. Existing SQL generation methods either randomly generate SQL queries or rely on human-crafted SQL templates to generate SQL queries, but they cannot meet various user speci c requirements, e.g., slow SQL queries, SQL queries with large result sizes. To address this problem, this paper studies the problem of constraintaware SQL generation, which, given a constraint (e.g., cardinality within [1k,2k]), generates SQL queries satisfying the constraint. This problem is rather challenging, because it is rather hard to capture the relationship from query constraint (e.g., cardinality and cost) to SQL queries and thus it is hard to guide a generation method to explore the SQL generation direction towards meeting the constraint. To address this challenge, we propose a reinforcement learning (RL) based framework LearnedSQLGen, for generating queries satisfying the constraint. LearnedSQLGen adopts an exploration-exploitation strategy that exploits the generation direction following the query constraint, which is learned from query execution feedback. We judiciously design the reward function in RL to guide the generation process accurately. We also integrate a nite-state machine in our model to generate valid SQL queries. Experimental results on three benchmarks showed that LearnedSQLGen signi cantly outperformed the baselines in terms of both accuracy (30% better) and e ciency (10-35\u00d7).",
    "pdf_parse": {
        "abstract": [
            {
                "text": "Many database optimization problems, e.g., slow SQL diagnosis, database testing, optimizer tuning, require a large volume of SQL queries. Due to privacy issues, it is hard to obtain real SQL queries, and thus SQL generation is a very important task in database optimization. Existing SQL generation methods either randomly generate SQL queries or rely on human-crafted SQL templates to generate SQL queries, but they cannot meet various user speci c requirements, e.g., slow SQL queries, SQL queries with large result sizes. To address this problem, this paper studies the problem of constraintaware SQL generation, which, given a constraint (e.g., cardinality within [1k,2k]), generates SQL queries satisfying the constraint. This problem is rather challenging, because it is rather hard to capture the relationship from query constraint (e.g., cardinality and cost) to SQL queries and thus it is hard to guide a generation method to explore the SQL generation direction towards meeting the constraint. To address this challenge, we propose a reinforcement learning (RL) based framework LearnedSQLGen, for generating queries satisfying the constraint. LearnedSQLGen adopts an exploration-exploitation strategy that exploits the generation direction following the query constraint, which is learned from query execution feedback. We judiciously design the reward function in RL to guide the generation process accurately. We also integrate a nite-state machine in our model to generate valid SQL queries. Experimental results on three benchmarks showed that LearnedSQLGen signi cantly outperformed the baselines in terms of both accuracy (30% better) and e ciency (10-35\u00d7).",
                "cite_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Many database optimization problems require a large volume of SQL queries, e.g., slow SQL diagnosis [18, 45] , database testing [47, 49, 62] , optimizer tuning [9, 16, 19, 65, 66] , learned cardinality estimator [20, 34] . For example, to make database optimizer more robust, it is important to feed the optimizer with a huge number of SQL queries. For another example, to train a high-quality learned cardinality estimator, it also requires to generate a large number of SQL queries [20] . However, it is rather hard to obtain a large number of real SQL queries due to privacy issues, and thus SQL generation is a very important task in database optimization [16] .",
                "cite_spans": [
                    {
                        "start": 100,
                        "end": 104,
                        "text": "[18,",
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 105,
                        "end": 108,
                        "text": "45]",
                        "ref_id": "BIBREF43"
                    },
                    {
                        "start": 128,
                        "end": 132,
                        "text": "[47,",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 133,
                        "end": 136,
                        "text": "49,",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 137,
                        "end": 140,
                        "text": "62]",
                        "ref_id": "BIBREF60"
                    },
                    {
                        "start": 160,
                        "end": 163,
                        "text": "[9,",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 164,
                        "end": 167,
                        "text": "16,",
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 168,
                        "end": 171,
                        "text": "19,",
                        "ref_id": "BIBREF17"
                    },
                    {
                        "start": 172,
                        "end": 175,
                        "text": "65,",
                        "ref_id": "BIBREF63"
                    },
                    {
                        "start": 176,
                        "end": 179,
                        "text": "66]",
                        "ref_id": "BIBREF64"
                    },
                    {
                        "start": 212,
                        "end": 216,
                        "text": "[20,",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 217,
                        "end": 220,
                        "text": "34]",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 484,
                        "end": 488,
                        "text": "[20]",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 660,
                        "end": 664,
                        "text": "[16]",
                        "ref_id": "BIBREF14"
                    }
                ],
                "section": "INTRODUCTION",
                "sec_num": "1"
            },
            {
                "text": "Although there are some SQL generation tools, e.g., SQLsmith [47] and RAGs [49] , they have several limitations. First, they randomly generate SQL queries and the generated queries may be useless, e.g., empty result. Second, they cannot generate SQL queries that meet user requirements. For example, if we nd that an optimizer should be enhanced for optimizing the SQL queries with small cardinality (e.g., cardinality within [1,10]), we need to generate SQL queries satisfying this constraint.",
                "cite_spans": [
                    {
                        "start": 61,
                        "end": 65,
                        "text": "[47]",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 75,
                        "end": 79,
                        "text": "[49]",
                        "ref_id": "BIBREF47"
                    }
                ],
                "section": "INTRODUCTION",
                "sec_num": "1"
            },
            {
                "text": "To address this limitation, this paper studies the problem of constraint-aware SQL generation, which, given a constraint (e.g., cardinality within a range, query cost within a range), generates SQL queries satisfying this constraint. A straightforward method, which rst randomly generates SQL queries with existing tools [47] , and then validates whether each generated SQL query satis es the constraint, is rather expensive, because each generated query has very low probability satisfying the constraint. Although there are some works [10, 38] that attempt to generate SQL queries satisfying a constraint, they have several limitations. First, they require database experts to craft some high-quality SQL query templates (SQL structures without predicate values). Obviously, it is expensive to craft templates for many constraints, and it is hard to craft templates for new databases that the expert is not familiar with. Second, there are many di erent constraints (e.g., slow SQL queries for various scenarios), and using the crafted templates (1) may not nd queries satisfying the constraints and (2) may miss important SQL queries.",
                "cite_spans": [
                    {
                        "start": 321,
                        "end": 325,
                        "text": "[47]",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 537,
                        "end": 541,
                        "text": "[10,",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 542,
                        "end": 545,
                        "text": "38]",
                        "ref_id": "BIBREF36"
                    }
                ],
                "section": "INTRODUCTION",
                "sec_num": "1"
            },
            {
                "text": "Because the experts may miss some important templates, and thus the corresponding SQL queries will be missed.",
                "cite_spans": [],
                "section": "INTRODUCTION",
                "sec_num": "1"
            },
            {
                "text": "There are three main challenges in constraint-aware SQL query generation. (C1) SQL queries may have diverse cardinality/cost, and it is challenging to capture the relationship from a constraint to SQL queries. (C2) There are many di erent constraints required by users in di erent scenarios, and it is challenging to adapt to di erent constraints. (C3) The generated SQL queries must be valid (syntactically and semantically correct), and we need to guarantee the query validity. To address these challenges, we propose a system, LearnedSQLGen, which utilizes reinforcement learning (RL) to generate queries with target constraints. RL is a typical machine learning paradigm that an agent learns from the query-execution feedback by trial-and-error interactions with the environment (database system), which adopts an exploration-exploitation strategy. LearnedSQLGen generates queries by trying di erent actions (\ud835\udc56.\ud835\udc52., tokens like reserved words, metadata, operands in a query), and the database system (\ud835\udc56.\ud835\udc52., environment) can return the feedback by executing the generated query. Based on the feedback, LearnedSQLGen can exploit the optimal generation direction that leads to the target constraint (addressing C1). Moreover, we utilize a meta-critic network that makes our framework generalizable to other SQL generation tasks with di erent constraints e ectively (addressing C2). Furthermore, we use a nite-state machine to restrict the action space so that each generated query is valid (addressing C3).",
                "cite_spans": [],
                "section": "INTRODUCTION",
                "sec_num": "1"
            },
            {
                "text": "To summarize, we make the following contributions.",
                "cite_spans": [],
                "section": "INTRODUCTION",
                "sec_num": "1"
            },
            {
                "text": "(1) We propose a reinforcement learning based framework to generate queries with target constraints. To the best of our knowledge, this work is the rst attempt that uses a learning-based method to address the constraint-aware SQL generation problem, satisfying cost or cardinality constraints (see Section 3).",
                "cite_spans": [],
                "section": "INTRODUCTION",
                "sec_num": "1"
            },
            {
                "text": "(2) We judiciously design reward functions in RL to guide the generation process accurately. For each type of constraint (point or range), we design reward functions, and then we use the actor-critic network to achieve robust training in RL (see Section 4) . (3) We adopt a nite-state machine that incorporates SQL grammar and semantic rules to guarantee query validity, which can be extended to support various types of queries, like nested queries, insert/update/delete queries, etc. (see Section 5) . (4) We design a meta-critic strategy that rst pre-trains a model for di erent constraints and then uses the pre-trained model to support online query generation requirements (see Section 6) . (5) We have conducted experiments on three datasets, and the results showed that our method signi cantly improved the accuracy and e ciency by 30% and 10-35\u00d7 respectively (see Section 7) .",
                "cite_spans": [
                    {
                        "start": 246,
                        "end": 256,
                        "text": "Section 4)",
                        "ref_id": null
                    },
                    {
                        "start": 259,
                        "end": 262,
                        "text": "(3)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 491,
                        "end": 501,
                        "text": "Section 5)",
                        "ref_id": null
                    },
                    {
                        "start": 504,
                        "end": 507,
                        "text": "(4)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 683,
                        "end": 693,
                        "text": "Section 6)",
                        "ref_id": null
                    },
                    {
                        "start": 696,
                        "end": 699,
                        "text": "(5)",
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 872,
                        "end": 882,
                        "text": "Section 7)",
                        "ref_id": null
                    }
                ],
                "section": "INTRODUCTION",
                "sec_num": "1"
            },
            {
                "text": "Given a database, a user wants to generate a set of SQL queries that satisfy a constraint. An intuitive question is how to formulate the constraint. Two widely-used metrics for SQL queries are cardinality and cost. The former quanti es the number of results for a SQL query, and the latter quanti es the cost of executing the SQL query. So we use cardinality or cost to formulate the constraint and de ne the constraint-aware SQL generation problem as below.",
                "cite_spans": [],
                "section": "PRELIMINARY 2.1 Problem Formulation",
                "sec_num": "2"
            },
            {
                "text": "). Consider a database D = {R 1 , R 2 , ..., R d } with \ud835\udc51 relations, where each relation has multiple attributes. Given a cardinality/cost constraint C (a point or range constraint) and the number \ud835\udc41 of generated queries provided by the user, the query generation problem is to generate a set Q of SQL queries, such that \u2200\ud835\udc44 \u2208 Q, \ud835\udc44 satis es the constraint C and |Q| = \ud835\udc41 .",
                "cite_spans": [],
                "section": "D 1 (SQL G",
                "sec_num": null
            },
            {
                "text": "1. As shown in Figure 1 , database D has two relations. A user provides a range constraint Cardinality in [1K, 2K] with respect to the cardinality, which means that the cardinalities of the generated queries should be between 1K and 2K. Also, a user can input a point constraint Cost = 10, which represents that the user expects the costs of generated queries are close to 10 as much as possible.",
                "cite_spans": [],
                "section": "E",
                "sec_num": null
            },
            {
                "text": "Complexity Analysis. Our problem is NP-hard, which can be proved using the same proof provided in [10] (Theorem 4.1). The reduction is from the subset-sum problem (we are given \ud835\udc5a numbers \ud835\udc60 1 , ..., \ud835\udc60 \ud835\udc5a , and the goal is to choose a subset of numbers with total sum being exactly \ud835\udc60). For each given number \ud835\udc60 \ud835\udc56 in the subset sum instance, we create a relation \ud835\udc45 with \ud835\udc60 \ud835\udc56 tuples with exact the same attribute values. The observation is that if any such tuple is selected by a query, all \ud835\udc60 \ud835\udc56 tuples should be selected. Hence, generating an SQL whose output cardinality is exactly \ud835\udc60 is equivalent to nding a subset of numbers with total sum being \ud835\udc60. Note that although \ud835\udc45 is exponential sized, the authors in [10] show that \ud835\udc45 can be encoded by a join of several poly-sized relations. Remark. (1) In most scenarios, only the database tables associated with schemes are available before SQL query generation. Hence, our framework focuses on the case that there are no available SQL queries. (2) As our framework can well support both the cardinality and cost constraint, we do not distinguish them for ease of representation. (3) We can also allow users to specify the latency as a constraint, but it is sensitive to the hardware environment, so we use cost instead (like optimizers also use cost). ( 4) Since SQL generation is an NP-hard problem [10] , it is rather hard to guarantee that any query or template will not be missed. Thus our method may also miss SQL queries, but our method is capable of discovering more satis ed SQL queries through an exploration-exploitation strategy, as discussed and evaluated in the following sections.",
                "cite_spans": [
                    {
                        "start": 98,
                        "end": 102,
                        "text": "[10]",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 703,
                        "end": 707,
                        "text": "[10]",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 1118,
                        "end": 1121,
                        "text": "(3)",
                        "ref_id": "BIBREF1"
                    },
                    {
                        "start": 1339,
                        "end": 1343,
                        "text": "[10]",
                        "ref_id": "BIBREF8"
                    }
                ],
                "section": "E",
                "sec_num": null
            },
            {
                "text": "SQL query generation. Existing query generation methods can be broadly divided into two categories.",
                "cite_spans": [],
                "section": "Related Work",
                "sec_num": "2.2"
            },
            {
                "text": "(1) Query-driven method. It relies on a large number of given SQL queries to train a model, and then uses the model to generate similar SQL queries. Liu et al. [32] proposed a GAN-based model to randomly synthesize new SQL queries from historical queries. Hence it cannot be directly applied to our problem for two reasons. First, it requires many prepared training SQLs, which are expensive to acquire in real scenarios. Second, they purely generate random SQLs, and cannot meet the user-speci ed constraints.",
                "cite_spans": [
                    {
                        "start": 160,
                        "end": 164,
                        "text": "[32]",
                        "ref_id": "BIBREF30"
                    }
                ],
                "section": "Related Work",
                "sec_num": "2.2"
            },
            {
                "text": "(2) Query generation without given queries. Generally speaking, this category can further be classi ed into two categories. (\ud835\udc56) Random methods [47, 49] . Slutz et al [49] proposed to generate SQL queries by randomly walking on a parse tree and executing them on multiple database instances so as to compare their results for consistency detection (di erential testing). SQLsmith [47] is a typical random query generation tool, which generates complex SQL queries but they may produce empty results. Bati [8] proposed a genetic algorithm that randomly synthesizes queries (e.g., addition/removal of predicates) so as to trigger rarely covered code paths (e.g., spill to disk when a join does not t in the memory). However, they ignore the important constraints for database testing (e.g., cardinality ranges), and thus have low e ciency in generating desired queries with constraints. (\ud835\udc56\ud835\udc56) Template-based methods [10, 38] . They rely on some given SQL templates and change the values in the predicates of the templates to generate queries satisfying the given constraints. Bruno et al [10] proposed to generate desired queries by tweaking the predicate values in the given query template (e.g., the x in R.a < x). To satisfy the cardinality constraint, they utilize a hill-climbing algorithm that selects predicate values to minimize the distance from the target constraint. Besides, Chaitanya et al [38] proposed a space-pruning technique to reduce the searching space on the SQL templates. Speci cally, they iteratively sample some values of the predicates and restrict the search space based on the top-\ud835\udc58 selected areas with shortest distance from the cardinality. Template-based methods have higher e ciency than random methods. However, (i) the generation performance heavily depends on the quality of templates, which need to be manually designed by experts; (ii) Although some high-quality templates can be provided by experts, it is hard for these templates to cover various constraints thoroughly. Reinforcement learning is an ML paradigm that an agent learns from the feedback from the environment through trial-and-error interactions. RL is often utilized in sequence generation, which veri es that RL naturally ts our problem because a query can be seen as a sequence of tokens. For example, applications like machine translation [24, 42, 57] , text generation [7, 44] , and dialogue system [30, 48] can be solved by RL. However, their problems are very di erent from us, and thus the solutions cannot be applied. Learning Models for Databases. Machine learning has gained great development and received much attention in database community [5, 22, 25-29, 36, 43, 53, 54, 58, 61, 64, 67] and they can bene t each other [11-14, 33, 63] . Database researchers have used it in many topics like entity matching [15, 40] , approximate query processing (AQP) [35, 46] . For database systems, there are learningbased works like reinforcement learning for knob tuning [6, 28, 61] , reinforcement learning for query optimizer [37, 37, 59] , hybrid algorithms for materialized view selection [4, 60] , and deep learning for learned data layouts [17, 23, 41] . These works focus on optimizing database components. Note that many query-based methods (e.g., cardinality estimation, index/view advisor) [28, 37, 37, 59, 60, 67] rely on numerous queries to train learning models. Here we try to solve the constraint-aware query generation problem with reinforcement learning.",
                "cite_spans": [
                    {
                        "start": 143,
                        "end": 147,
                        "text": "[47,",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 148,
                        "end": 151,
                        "text": "49]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 166,
                        "end": 170,
                        "text": "[49]",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 379,
                        "end": 383,
                        "text": "[47]",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 504,
                        "end": 507,
                        "text": "[8]",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 912,
                        "end": 916,
                        "text": "[10,",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 917,
                        "end": 920,
                        "text": "38]",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 1084,
                        "end": 1088,
                        "text": "[10]",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 1399,
                        "end": 1403,
                        "text": "[38]",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 2341,
                        "end": 2345,
                        "text": "[24,",
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 2346,
                        "end": 2349,
                        "text": "42,",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 2350,
                        "end": 2353,
                        "text": "57]",
                        "ref_id": "BIBREF55"
                    },
                    {
                        "start": 2372,
                        "end": 2375,
                        "text": "[7,",
                        "ref_id": "BIBREF5"
                    },
                    {
                        "start": 2376,
                        "end": 2379,
                        "text": "44]",
                        "ref_id": "BIBREF42"
                    },
                    {
                        "start": 2402,
                        "end": 2406,
                        "text": "[30,",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 2407,
                        "end": 2410,
                        "text": "48]",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 2652,
                        "end": 2698,
                        "text": "[5, 22, 25-29, 36, 43, 53, 54, 58, 61, 64, 67]",
                        "ref_id": null
                    },
                    {
                        "start": 2730,
                        "end": 2745,
                        "text": "[11-14, 33, 63]",
                        "ref_id": null
                    },
                    {
                        "start": 2818,
                        "end": 2822,
                        "text": "[15,",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 2823,
                        "end": 2826,
                        "text": "40]",
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 2864,
                        "end": 2868,
                        "text": "[35,",
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 2869,
                        "end": 2872,
                        "text": "46]",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 2971,
                        "end": 2974,
                        "text": "[6,",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 2975,
                        "end": 2978,
                        "text": "28,",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 2979,
                        "end": 2982,
                        "text": "61]",
                        "ref_id": "BIBREF59"
                    },
                    {
                        "start": 3028,
                        "end": 3032,
                        "text": "[37,",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 3033,
                        "end": 3036,
                        "text": "37,",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 3037,
                        "end": 3040,
                        "text": "59]",
                        "ref_id": "BIBREF57"
                    },
                    {
                        "start": 3093,
                        "end": 3096,
                        "text": "[4,",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 3097,
                        "end": 3100,
                        "text": "60]",
                        "ref_id": "BIBREF58"
                    },
                    {
                        "start": 3146,
                        "end": 3150,
                        "text": "[17,",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 3151,
                        "end": 3154,
                        "text": "23,",
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 3155,
                        "end": 3158,
                        "text": "41]",
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 3300,
                        "end": 3304,
                        "text": "[28,",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 3305,
                        "end": 3308,
                        "text": "37,",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 3309,
                        "end": 3312,
                        "text": "37,",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 3313,
                        "end": 3316,
                        "text": "59,",
                        "ref_id": "BIBREF57"
                    },
                    {
                        "start": 3317,
                        "end": 3320,
                        "text": "60,",
                        "ref_id": "BIBREF58"
                    },
                    {
                        "start": 3321,
                        "end": 3324,
                        "text": "67]",
                        "ref_id": "BIBREF65"
                    }
                ],
                "section": "Related Work",
                "sec_num": "2.2"
            },
            {
                "text": "We propose LearnedSQLGen, a query generation framework using an RL model. In this section, we rst summarize the challenges and overall solution of LearnedSQLGen (Section 3.1), and then introduce the training and inference step respectively at a high level in Section 3.2 and 3.3. Note that in this section, we introduce the overall framework that generates queries using the RL model for one given constraint, and will discuss how to generalize the model to multiple di erent constraints in Section 6.",
                "cite_spans": [],
                "section": "SYSTEM FRAMEWORK",
                "sec_num": "3"
            },
            {
                "text": "Although there are many cost-estimation approaches to evaluate the cardinality and cost of queries, they cannot directly generate queries that satisfy a constraint, because they have to enumerate many queries to check whether the queries satisfy the constraint and obviously this solution is rather expensive, as most of the generated queries cannot satisfy the constraint. Basic Idea of LearnedSQLGen. We propose to use a reinforcement learning (RL) framework to address the constraint-aware SQL generation problem. RL is an ML paradigm that an agent learns from the feedback through trial-and-error interactions. Hence, there is a natural connection between RL and our problem. More concretely, considering the current state (i.e., current generated query), the agent predicts the next action (i.e., the next token), which hopefully can lead to the highest reward, i.e., satisfying the constraint. Thus, the RL mechanism seamlessly ts the generation process of SQL queries with constraints. Furthermore, the reason why RL can well solve our problem is that the exploitation of RL guarantees the accuracy of generated queries (\ud835\udc56.\ud835\udc52., meeting the constraints), and the exploration allows us to generate more queries with large diversity rather than generating highly similar ones towards existing directions. To summarize, our RL-based method adopts an exploration-exploitation strategy, to learn a policy by utilizing execution feedback (e.g., whether a generated SQL satis es the constraint), in order to guide the query generation process towards meeting the constraint.",
                "cite_spans": [],
                "section": "Overview of LearnedSQLGen",
                "sec_num": "3.1"
            },
            {
                "text": "There are three challenges \ud835\udc64 .\ud835\udc5f .\ud835\udc61 . our problem.",
                "cite_spans": [],
                "section": "Overview of LearnedSQLGen",
                "sec_num": "3.1"
            },
            {
                "text": "(1) Generate valid SQL queries by guaranteeing syntactic and semantic correctness. We de ne a nite-state machine (FSM) that incorporates prede ned grammar patterns and semantic restrictions to guarantee the correctness of queries. We will brie y discuss this in Section 3.2 and introduce the details in Section 5.",
                "cite_spans": [],
                "section": "Overview of LearnedSQLGen",
                "sec_num": "3.1"
            },
            {
                "text": "(2) Guide the generation direction to meet the constraints by computing the expectation of SQL queries. We carefully design the reward in the RL framework to guide the generation. For example, generating a query satisfying the constraint will be assigned a high reward, which is the \"exploitation\" strategy that makes the generation close to our expectation (see Section 4 for details).",
                "cite_spans": [],
                "section": "Overview of LearnedSQLGen",
                "sec_num": "3.1"
            },
            {
                "text": "(3) Generate multiple di erent queries satisfying the constraint. Obviously, the user de nitely wants diverse queries rather than almost the same ones. To this end, we use the policy-based RL framework that chooses the actions probabilistically, which can explore more query spaces that possibly meet the query constraint, \ud835\udc56.\ud835\udc52., the \"exploration\" strategy (see Section 4 for details).",
                "cite_spans": [],
                "section": "Overview of LearnedSQLGen",
                "sec_num": "3.1"
            },
            {
                "text": "In a nutshell, leveraging the FSM and the explorationexploitation RL framework, LearnedSQLGen can generate valid and diverse queries that meet user's constraints. As below, we will summarize the overall work ow of LearnedSQLGen. LearnedSQLGen workflow. The LearnedSQLGen framework is shown in Figure 1 . It rst trains an RL model based on the database D and cardinality/cost constraint C. The model takes as input a query (including subquery), \ud835\udc56.\ud835\udc52., state, and computes the optimal token (e.g., reserved words, table/attribute name, predicate value) to be added to the query, \ud835\udc56.\ud835\udc52., action. Then given the model and D, in the inference step, we can generate queries that satisfy the constraint using the model. Next, we will overview the above steps. ",
                "cite_spans": [],
                "section": "Overview of LearnedSQLGen",
                "sec_num": "3.1"
            },
            {
                "text": "We model the query generation problem as a sequential decision making process which can be potentially solved by the RL model. We de ne the basic traits of RL in our system for training as follows.",
                "cite_spans": [],
                "section": "Training",
                "sec_num": "3.2"
            },
            {
                "text": "State is represented as a sequence of tokens of the current generated SQL query. Basically, there are two kinds of queries during generation. (1) Complete generated queries. If a query encounters an EOF token, it is a complete generated query that will not be further extended. Then it will be sent to the environment for execution, and the feedback will be used as the reward to guide the training process. Note that our FSM guarantees that the query is valid and executable. (2) Partial queries. If a query has not met the EOF, it is a partial query that should be further extended by tokens. Note that some partial queries are also executable. In our framework, both partial executable queries and complete queries will be executed for training. All above queries should be encoded as a state. Action is the next token to select, which is classi ed into 5 types: \ud835\udc56). Reserved words in SQL grammar (\ud835\udc52.\ud835\udc54., Select, Where); \ud835\udc56\ud835\udc56). Meta data of the schema (\ud835\udc52.\ud835\udc54., \ud835\udc47 1 , \ud835\udc47 2 ); \ud835\udc56\ud835\udc56\ud835\udc56). Cell values sampled from each table in the database (\ud835\udc52.\ud835\udc54., 95.5, 100); \ud835\udc56\ud835\udc63). The operator (\ud835\udc52.\ud835\udc54., >, =); \ud835\udc63). EOF, denotes the query is completely generated. Hence, given the database D, the action space is xed (denoted by A), but not all actions in the space can be selected considering the query validity, which is controlled in the environment (see Section 4). Environment plays two roles in LearnedSQLGen. On the one hand, based on the current generated query, it uses FSM to prune the action space for query validity. On the other hand, after each action is applied, a query is generated. If it is executable, the environment will return the estimated cardinality, based on which a reward is generated to guide the training process (see Section 5) . Reward is returned by the environment, which is used to update the policy network, so as to guide the generation process towards satisfying the constraint. A high reward denotes that the generated query satis es the constraint C, and vice versa. But during the generation process of each query, if a partial query is not executable, the reward is returned as 0.",
                "cite_spans": [
                    {
                        "start": 1717,
                        "end": 1727,
                        "text": "Section 5)",
                        "ref_id": null
                    }
                ],
                "section": "Training",
                "sec_num": "3.2"
            },
            {
                "text": "Agent considers the current generated SQL (i.e., current state), and chooses an action based on the learned policy \ud835\udf0b \ud835\udf03 . In LearnedSQLGen, our agent leverages the actor-critic method [31] , which consists of an actor network and a critic network. The former is utilized to choose the action based on \ud835\udf0b \ud835\udf03 , and the latter is used to update the policy based on the reward (see Section 4) .",
                "cite_spans": [
                    {
                        "start": 183,
                        "end": 187,
                        "text": "[31]",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 375,
                        "end": 385,
                        "text": "Section 4)",
                        "ref_id": null
                    }
                ],
                "section": "Training",
                "sec_num": "3.2"
            },
            {
                "text": "Next, we show the overall training process in Figure 1 (a), considering the interaction between the above components. Overall training process. Initially, as shown in Algorithm 1, the training process takes as input the constraint C, and database D, based on which the entire action space A is xed. Then the training step starts. We propose to generate queries using the RL model, and leverage these queries associated with their estimated cardinality as the training data to update the model.",
                "cite_spans": [],
                "section": "Training",
                "sec_num": "3.2"
            },
            {
                "text": "Speci cally, each training query is generated from scratch (Line 2) in a token-by-token manner, and here we illustrate our training process from a partial query, \ud835\udc56.\ud835\udc52., Q is represented to a state \ud835\udc60 \ud835\udc58 =('From', 'Score', 'Select', 'ID') (Line 4), where \ud835\udc58 is used to identify di erent states. Next, the agent (\ud835\udc56.\ud835\udc52., the actor network) takes as input \ud835\udc60 \ud835\udc58 , and computes the probability of each action, \ud835\udc56.\ud835\udc52., \ud835\udf0b \ud835\udf03 (\ud835\udc4e|\ud835\udc60) = \ud835\udc5d (\ud835\udc4e|\ud835\udc60, \ud835\udf03 ), \ud835\udc4e \u2208 A. Hopefully, the higher the probability is, the larger long-term reward of the corresponding action is expected to acquire if the action (\ud835\udc56.\ud835\udc52., the next token) is selected, which means that the nally generated query is more likely to satisfy the constraint.",
                "cite_spans": [],
                "section": "Training",
                "sec_num": "3.2"
            },
            {
                "text": "As the action space is large, and most actions in A will lead to an invalid query, so an FSM in the environment helps to prune the action space and guarantee the validity (Line 5). For instance, given Q, the FSM masks the actions like From, Student, etc. Hence, the agent samples from the rest unmasked ones based on the probabilities. Suppose that Where is selected, so we update Q to \" From Score Select ID Where\" (Line 8). Next, since it is not executable, a reward 0 is returned to the critic network of the agent (Line 11). Otherwise, a non-zero reward that re ects how the query satis es the constraint will be returned. The reward is computed by comparing the estimated cardinality (computed by the cost estimator of databases) of the query with the constraint (Line 10). Note that we do not use the real cardinality for the e ciency issue. Then the critic network estimates the long-term reward of the current state (denoted by \ud835\udc49 (\ud835\udc60)), which is together with the returned reward to compute the temporal-di erence error (TD-error), and updates the two networks for optimized action selection (Line 12).",
                "cite_spans": [],
                "section": "Training",
                "sec_num": "3.2"
            },
            {
                "text": "Although the training process can already generate some satis ed queries, if the user requires many more SQL queries, we can directly use the trained model to generate satis ed queries without updating the network, \ud835\udc56.\ud835\udc52., the inference step. Also, the inference step allows the users to call the trained model to generate queries satisfying the constraint C at any time, without retraining the model. In other words, the inference is the forward pass of the actor network. The details is illustrated as below.",
                "cite_spans": [],
                "section": "Inference",
                "sec_num": "3.3"
            },
            {
                "text": "The overall inference process is as shown in Figure 1 (b) and the algorithm of generating queries is shown in Algorithm 2. Each query is generated from scratch token-by-token. Initially, we start from an empty query, which is also regarded as a partial query (Line 1). Given a partial query, it is rst represented as a new state (step 1 \u25cb, Line 3). Then the agent takes as input the state, uses the learned policy to compute a probability for each action in A (step 2 \u25cb, Line 5). Meanwhile, considering the current query, the FSM in the environment masks a number of actions to guarantee the validity (step 3 \u25cb, Line 4). Then, the next action, \ud835\udc56.\ud835\udc52., the next token, is selected by the policy and FSM, and added to the partial query (step 4 \u25cb, Line 7). The above steps iterate until an action with the EOF is selected (step 5 \u25cb), and then a query is generated and output (Line 8). If the user wants to generate \ud835\udc41 queries, we repeat this process for \ud835\udc41 times.",
                "cite_spans": [],
                "section": "Inference",
                "sec_num": "3.3"
            },
            {
                "text": "2. We suppose that From clause is a basic and indispensable constitution part of SQL, LearnedSQLGen starts to generate SQL from it, \ud835\udc56.\ud835\udc52., the rst action (This can be de ned by the FSM, where From can be the start point). Then the agent picks tokens one by one according to well-learned policy \ud835\udf0b \ud835\udf03 . For example, in Figure 1 Add \ud835\udc4e \ud835\udc58 to \ud835\udc44; 7 return \ud835\udc44;",
                "cite_spans": [],
                "section": "E",
                "sec_num": null
            },
            {
                "text": "8",
                "cite_spans": [],
                "section": "E",
                "sec_num": null
            },
            {
                "text": "the second action, the current state \ud835\udc60 = ('From'). Then based on the FSM, the second action can be selected from {'Students','Score' }, which can guarantee a valid query, and the agent selects 'Score'.",
                "cite_spans": [],
                "section": "E",
                "sec_num": null
            },
            {
                "text": "For another instance, for the 8-th action, current state is ('From', 'Score', 'Select', 'ID', 'Where', 'Grade', '<'), and the next token can be selected among cell values sampled from column score(\ud835\udc52.\ud835\udc54., 95, 100) while others are masked by the FSM. According to \ud835\udf0b, the agent picks the token '95' with a high probability. Next, the EOF is selected as the action, and thus the query is completed.",
                "cite_spans": [],
                "section": "E",
                "sec_num": null
            },
            {
                "text": "Note that the inference step can only generate queries satisfying the constraint C. In this case, if a user speci es another di erent constraint, the previous trained model cannot directly work. Hence, in Section 6, we propose a meta-critic network that leverages the historical training experience to make our method generalize to other constraints e ciently.",
                "cite_spans": [],
                "section": "E",
                "sec_num": null
            },
            {
                "text": "Our policy in the agent is implemented by the reinforcement learning model. We rst introduce the model design for the query generation problem, \ud835\udc56.\ud835\udc52., the state representation (Section 4.1), reward design (Section 4.2) and the actor-critic networks (Section 4.3).",
                "cite_spans": [],
                "section": "RL IN LEARNEDSQLGEN",
                "sec_num": "4"
            },
            {
                "text": "To utilize the RL model, we need to represent the state, which is the input of model. In our problem, as discussed in Section 3.2, each state corresponds to a query (probably an intermediate one), which consists of a sequence of tokens (\ud835\udc56.\ud835\udc52., actions). Therefore, we should represent the tokens (actions) rst. Although there exist many types of tokens, we can represent them to support complicated queries. Especially for predicates w.r.t. a large number of distinct cell values, it is hard to represent them. Next, we see how to address the above issues. Token (action) representation. For ease of training and inference, we map di erent types of tokens to the same encoding space. First, we introduce the 5 token types.",
                "cite_spans": [],
                "section": "State Representation",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 Reserved words in the SQL grammar. To be speci c, we support {Select, From, Where, Groupby, Having, Order BY, MAX/MIN, Sum, AVG, Count, Exist, In, and, or, not} \u2022 Meta data of the schema including the table and attribute names. \u2022 Cell values in the data.",
                "cite_spans": [],
                "section": "State Representation",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 The operators. We support {>, =, <, \u2265, \u2264}.",
                "cite_spans": [],
                "section": "State Representation",
                "sec_num": "4.1"
            },
            {
                "text": "\u2022 EOF, indicates that a query is generated completely. All the tokens above constitute the entire action space A. Overall, we map each of the above tokens to a one-hot encoding, \ud835\udc52.\ud835\udc54., \ud835\udc38 (Select) \u2192 00000, \ud835\udc38 (From) \u2192 00001, ..., \ud835\udc38 (Score) \u2192 01000 etc. Then the the second challenge arises, \ud835\udc56.\ud835\udc52., encoding all the cell values (the third type) is sometimes impractical due to the large action space. To this end, we tackle the cell values as follows.",
                "cite_spans": [],
                "section": "State Representation",
                "sec_num": "4.1"
            },
            {
                "text": "Generally, there are three common types of data (cell values) in database: numerical, categorical and string that we can support.",
                "cite_spans": [],
                "section": "State Representation",
                "sec_num": "4.1"
            },
            {
                "text": "For categorical data, like the attribute Gender, we just treat the values the same as the other types because the number of distinct values of categorical data is always not large, \ud835\udc56.\ud835\udc52., \ud835\udc38 (Male) \u2192 00100, \ud835\udc38 (Female) \u2192 00010.",
                "cite_spans": [],
                "section": "State Representation",
                "sec_num": "4.1"
            },
            {
                "text": "However, numerical data may have a large number of distinct values. Hence, to reduce the action space, for each numerical attribute, we randomly sample \ud835\udc58 values from the attribute before training and encode them to a one-hot vector. Then once we generate a value of this attribute, a value among the sampled \ud835\udc58 values will be selected by the agent.",
                "cite_spans": [],
                "section": "State Representation",
                "sec_num": "4.1"
            },
            {
                "text": "For string data, we can sample \ud835\udc58 strings and use them the same as the numerical data, and support {=, >, <} for string data. State (query) representation. The state is naturally represented as a sequence of token (query) representations. To be speci c, we use \ud835\udc60 \ud835\udc61 to denote a state, where the subscribe \ud835\udc61 means that there are \ud835\udc61 tokens in the sequence, \ud835\udc56.\ud835\udc52., the query \ud835\udc44 \ud835\udc61 . For example, the query \ud835\udc44 4 = \"From Score Select ID\" corresponds to the state \ud835\udc60 4 ={\ud835\udc38 (From), \ud835\udc38 (Score), \ud835\udc38 (Select), \ud835\udc38 (ID)}.",
                "cite_spans": [],
                "section": "State Representation",
                "sec_num": "4.1"
            },
            {
                "text": "We present the reward design based on the constraint types (\ud835\udc56.\ud835\udc52., point and range) of the user's input. The essence of the reward is to re ect the di erence between the feedback from the database and given constraint. Intuitively, the smaller the di erence is, the higher reward should be given to the agent, and vice versa. Point constraint is in the form of C : Card = \ud835\udc50 or Cost = \ud835\udc50, where \ud835\udc50 denotes the user requirement. Given a generated query \ud835\udc44 \ud835\udc61 , \ud835\udc52 \ud835\udc61 = 1(0) denotes that the query is (not) executable and \u0109\ud835\udc61 denotes the estimated result of \ud835\udc44 \ud835\udc61 under database D. we use \ud835\udeff \ud835\udc61 = \ud835\udc5a\ud835\udc56\ud835\udc5b( \u0109 \ud835\udc50 , \ud835\udc50 \u0109 ) as the reward. If \ud835\udc50 or \u0109 is zero, we set \ud835\udeff \ud835\udc61 as 0.",
                "cite_spans": [],
                "section": "Reward Design",
                "sec_num": "4.2"
            },
            {
                "text": "\ud835\udc5f \ud835\udc61 = \ud835\udeff \ud835\udc61 \ud835\udc52 \ud835\udc61 = 1 0 \ud835\udc52 \ud835\udc61 = 0 E 3.",
                "cite_spans": [],
                "section": "Reward Design",
                "sec_num": "4.2"
            },
            {
                "text": "Suppose a point constraint, Card = 10, 000, and the agent generates an executable query with estimated cardinality \u0109\ud835\udc61 = 100. Hence a low reward 0.01 is returned to decrease the probability of selecting queries like it again. For another query with the estimated cardinality \u0109\ud835\udc61 = 11, 000, we give a high reward 0.9 to encourage the agent to explore along this direction.",
                "cite_spans": [],
                "section": "Reward Design",
                "sec_num": "4.2"
            },
            {
                "text": "Remark. Although we are ultimately interested in the performance(\ud835\udc56.\ud835\udc52., cardinality or cost) of a completely generated SQL (\ud835\udc56.\ud835\udc52., \ud835\udc4e \ud835\udc47 ='EOF' ), simply awarding the end reward after the 'EOF' while giving zero as intermediate reward results in a sparse training signal for the agent. Therefore, we also give the computed reward if partial queries can be executed. Besides, for all types of queries, we will compute an estimated long-term reward for each of them, which is done by the critic network (see Section 4.3 in detail). Note that the long-term reward is not like \ud835\udc5f that is directly derived from the environment. Range constraint is in the form of C : Card = [\ud835\udc50.\ud835\udc59, \ud835\udc50.\ud835\udc5f ] or Cost = [\ud835\udc50.\ud835\udc59, \ud835\udc50.\ud835\udc5f ], which requests that the cardinalities/costs are in [\ud835\udc50.\ud835\udc59, \ud835\udc50.\ud835\udc5f ]. \ud835\udc52 \ud835\udc61 has the same meaning with the point constraint. Di erent from that, if \u0109\ud835\udc61 \u2208 [\ud835\udc50.\ud835\udc59, \ud835\udc50.\ud835\udc5f ], we assign a positive reward 1. Otherwise, we consider whether \u0109\ud835\udc61 is near to the range, so as to assign a proper reward. To be speci c, we use \ud835\udeff \ud835\udc59 \ud835\udc61 = \ud835\udc5a\ud835\udc56\ud835\udc5b( \u0109 \ud835\udc50.\ud835\udc59 , \ud835\udc50.\ud835\udc59 \u0109 ), \ud835\udeff \ud835\udc5f \ud835\udc61 = \ud835\udc5a\ud835\udc56\ud835\udc5b( \u0109 \ud835\udc50.\ud835\udc5f , \ud835\udc50.\ud835\udc5f \u0109 ) to denote how close is \u0109 to the left and right bound of the range respectively. Hence, \ud835\udc5a\ud835\udc4e\ud835\udc65 (\ud835\udeff \ud835\udc59 \ud835\udc61 , \ud835\udeff \ud835\udc5f \ud835\udc61 ) can be utilized to measure how close is \u0109 to the range. For ease of representation, we introduce a notation \ud835\udc5b \ud835\udc61 = 1 to denote \u0109\ud835\udc61 \u2208 [\ud835\udc50.\ud835\udc59, \ud835\udc50.\ud835\udc5f ]. Naturally, \ud835\udc5b \ud835\udc61 = 0 means that \u0109\ud835\udc61 < \ud835\udc50.\ud835\udc59 or \u0109\ud835\udc61 > \ud835\udc50.\ud835\udc5f .",
                "cite_spans": [],
                "section": "Reward Design",
                "sec_num": "4.2"
            },
            {
                "text": "\ud835\udc5f \ud835\udc61 = \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 1 \ud835\udc52 \ud835\udc61 = 1 & \ud835\udc5b \ud835\udc61 = 1 \ud835\udc5a\ud835\udc4e\ud835\udc65 (\ud835\udeff \ud835\udc59 \ud835\udc61 , \ud835\udeff \ud835\udc5f \ud835\udc61 ) \ud835\udc52 \ud835\udc61 = 1 & \ud835\udc5b \ud835\udc61 = 0 0 \ud835\udc52 \ud835\udc61 = 0 E 4. Suppose a range constraint Card = [1\ud835\udc3e, 2\ud835\udc3e]",
                "cite_spans": [],
                "section": "Reward Design",
                "sec_num": "4.2"
            },
            {
                "text": ", the agent generates a satis ed query with estimated cardinality \u0109\ud835\udc61 = 1.5\ud835\udc3e, and thus the returned reward is 1. For another query with \u0109\ud835\udc61 = 10\ud835\udc58, which is higher than the upper bound of the range, we return the corresponding relatively small reward 0.2.",
                "cite_spans": [],
                "section": "Reward Design",
                "sec_num": "4.2"
            },
            {
                "text": "Given the state representation, the policy in the agent takes as input the state, and infers the optimal action that should be taken in the next step, which is the core part of the RL model. However, the typical policy network cannot achieve good performance because our cumulative rewards are likely to result in high variance among the returned rewards. Hence, we utilize the actor-critic method to alleviate this issue. Moreover, to avoid generating many same queries, we use a entropy regularization technique to adjust the objective function for generating di erent queries.",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "Typical policy-based reinforcement learning method (like the REINFORCE algorithm [55] ) always relies on optimizing the parameterized policy with respect to the expected long-term reward. To be speci c, the objective of the policy network is to maximize \ud835\udc3d (\ud835\udf03 ) de ned as below,",
                "cite_spans": [
                    {
                        "start": 81,
                        "end": 85,
                        "text": "[55]",
                        "ref_id": "BIBREF53"
                    }
                ],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "where \ud835\udf0f = (\ud835\udc60 1 , \ud835\udc4e 1 , .., \ud835\udc60 \ud835\udc47 , \ud835\udc4e \ud835\udc47 ) denotes a trajectory leading to a fully generated query, \ud835\udc56.\ud835\udc52., \ud835\udc4e \ud835\udc47 = EOF. \ud835\udc45(\ud835\udf0f 1:\ud835\udc47 ) = \ud835\udc47 \ud835\udc61 =1 \ud835\udc5f \ud835\udc61 . Intuitively, to maximize \ud835\udc3d (\ud835\udf03 ), given a high reward \ud835\udc45(\ud835\udf0f), we aim to learn a policy to increase the probability of selecting the trajectory \ud835\udf0f, \ud835\udc56.\ud835\udc52., \ud835\udc5d (\ud835\udf0f |\ud835\udf03 ). Given the objective function, the REINFORCE algorithm uses the gradient ascent to update the parameters \ud835\udf03 in the direction of the gradient,",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "Motivation of actor-critic networks. As discussed above, the RE-INFORCE introduces in high variability in cumulative reward values (\ud835\udc45(\ud835\udf0f) = \ud835\udc47 \ud835\udc61 =0 \ud835\udc5f \ud835\udc61 ) because these trajectories during training can deviate from each other at great degrees, which leads to instability and slow convergence [52] . One way to address this issue is to subtract the cumulative reward by a baseline, which intuitively Therefore, the actor-critic network strategy is proposed [31] . The actor network learns the policy distribution to select an action. And for adjusting the cumulative reward, the critic network is to estimate the baseline, which can be regarded as the expected long-term reward under certain state. Next, we rst introduce the forward pass of the actor and critic networks respectively, and then illustrate how to update the networks based on the reward and baseline. The actor network. Since the Long Short-Term Memory(LSTM) [21] is a typical structure to model a sequence, the actor network takes as input the state representation, followed by an LSTM and Softmax layer, and outputs the policy distribution, \ud835\udc56.\ud835\udc52., \ud835\udf0b \ud835\udf03 (\ud835\udc60 \ud835\udc61 ) = Softmax(LSTM(\ud835\udc60 \ud835\udc61 )). Then the probability of each action \ud835\udf0b \ud835\udf03 (\ud835\udc4e|\ud835\udc60 \ud835\udc61 ) can be derived, and the agent samples based on the probability distribution. The critic network estimates the value function, including the state-value (the \ud835\udc49 value) and action-value (the \ud835\udc44 value). To be speci c, the critic network uses a separate LSTM network parameterized by \ud835\udf19, and outputs the \ud835\udc49 value, \ud835\udc56.\ud835\udc52., \ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 ), which is the estimation of long-term reward from the state \ud835\udc60 \ud835\udc61 using the policy \ud835\udf0b. Also, the \ud835\udc44 value can be naturally computed by \ud835\udc44 \ud835\udf19 (\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 ) = \ud835\udc5f \ud835\udc61 + \ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 +1 ) [52] . It denotes the estimation of long-term reward that the action \ud835\udc4e \ud835\udc61 is taken from the state \ud835\udc60 \ud835\udc61 using the policy \ud835\udf0b. Training (updating) the actor-critic networks. Recap that in the REINFORCE, the high variance of cumulative rewards in Eq. 2 leads to unstable and ine cient training. To address this, we use the \ud835\udc49 value as a baseline to be subtracted by the rewards for reducing the variance which is produced by the critic network and it is proved that this does not introduce any bias [52] .",
                "cite_spans": [
                    {
                        "start": 289,
                        "end": 293,
                        "text": "[52]",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 453,
                        "end": 457,
                        "text": "[31]",
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 921,
                        "end": 925,
                        "text": "[21]",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 1687,
                        "end": 1691,
                        "text": "[52]",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 2178,
                        "end": 2182,
                        "text": "[52]",
                        "ref_id": "BIBREF50"
                    }
                ],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "To be speci c, we use \ud835\udc34(\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 ) = \ud835\udc44 (\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 ) -\ud835\udc49 (\ud835\udc60 \ud835\udc61 ) to replace \ud835\udc45 \ud835\udc61 in Eq. 2, because \ud835\udc45 \ud835\udc61 is an estimate of \ud835\udc44 (\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 ) and \ud835\udc49 (\ud835\udc60 \ud835\udc61 ) is the baseline. Hence, the gradient becomes,",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "where \ud835\udc34(\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 ) can be estimated by \ud835\udc5f \ud835\udc61 + \ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 +1 ) -\ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 ), named by temporal-di erence (TD) error. From another perspective, since the baseline, \ud835\udc56.\ud835\udc52., the \ud835\udc49 value, is the expected long-term reward of a state, the TD error re ects the advantages/disadvantages of di erent actions from the state. Then we discuss how to update the critic network. To estimate the \ud835\udc49 value accurately, the di erence between \ud835\udc5f \ud835\udc61 + \ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 +1 ) and \ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 ) should be as small as possible. Hence, we can nd that the TD error can also be used to update the critic. To be speci c, the loss function should be written as L \ud835\udf19 = (\ud835\udc5f \ud835\udc61 + \ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 +1 ) -\ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 )) ",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "= 'T 1 .ID' | 'T1.Course' | 'T 1 .Score' | 'T 2 .ID' | 'T 2 .Name' agg ::= 'max' | 'min' | 'count' | 'sum' | 'avg' operator ::= '<' | '>' | '<=' | '>=' | '<>' table ::= 'Score(T 1 )' | 'Student(T 2 )' Table 1: SQL Grammar.",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "Entropy regularization. We can further improve the diversity of generated queries through adding a regularization term (H (\ud835\udf0b \ud835\udf03 (\u2022|\ud835\udc60 \ud835\udc61 )) to the loss function [39, 56] . It denotes the entropy of the probability distribution of actions given a state. The higher the entropy, with a higher probability that the agent can sample diverse actions rather than keeping to select the most likely one. Speci cally, we can rewrite Eq. 3 as,",
                "cite_spans": [
                    {
                        "start": 158,
                        "end": 162,
                        "text": "[39,",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 163,
                        "end": 166,
                        "text": "56]",
                        "ref_id": "BIBREF54"
                    }
                ],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "\u2207\ud835\udc3d (\ud835\udf03 ) \u2248 \ud835\udc47 \u2211\ufe01 \ud835\udc61 =0 [\u2207 \ud835\udf03 \ud835\udc59\ud835\udc5c\ud835\udc54\ud835\udf0b \ud835\udf03 (\ud835\udc4e \ud835\udc61 |\ud835\udc60 \ud835\udc61 )\ud835\udc34(\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 ) + \ud835\udf06\u2207 \ud835\udf03 H (\ud835\udf0b \ud835\udf03 (\u2022|\ud835\udc60 \ud835\udc61 ))] (4)",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "where \ud835\udf06 controls the strength of the entropy regularization term.",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "Overall training algorithm Algorithm 3 summarizes the above proposed process. LearnedSQLGen rst initializes the parameters (Line 1). In each iteration (Line 2-7), LearnedSQLGen generates a batch of queries using the learned policy (Line 3). Then it computes the gradient for each trajectories (Line 4) to update the parameter (Line 6-7). Finally, it outputs a well-trained actor-critic network.",
                "cite_spans": [],
                "section": "LearnedSQLGen via Actor-Critic",
                "sec_num": "4.3"
            },
            {
                "text": "We introduce the designed nite-state machine (FSM) in the environment, which is utilized to mask some possible actions, and thereby the validity of queries is guaranteed. The FSM is built from the typical SQL grammar and can be extended exibly by the users, so as to generate various types of queries. D 2. (Finite-state machine in LearnedSQLGen). Given a database D with \ud835\udc51 relations, an FSM in LearnedSQLGen can be de ned as a directed acyclic graph (DAG) G D , which is utilized to describe the generation scope of each token on a query, and guarantee the validity. In G D , each node (edge) is represented as an FSM-state (FSM-action). Speci cally, each intermediate query during the generation process corresponds to an FSM-state, and each possible token to be added to an intermediate query corresponds to an FSM-action.",
                "cite_spans": [],
                "section": "FSM IN THE ENVIRONMENT",
                "sec_num": "5"
            },
            {
                "text": "Student (T 2 ) from \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 agg where group by \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 EOF EOF \u2022\u2022\u2022 n 2 n 3 n 4 n 5 n 6 n 7 n 8 T 1 . ID T 1 . score Score (T 1 ) join n 1 T 1 T 2 into into select values \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 where T 1 T 2 set set \u2022\u2022\u2022 \u2022\u2022\u2022 \u2022\u2022\u2022 T 1 T 2 from",
                "cite_spans": [],
                "section": "FSM IN THE ENVIRONMENT",
                "sec_num": "5"
            },
            {
                "text": "To distinguish the FSM-state (action) from the state (action) in RL (Section 4), we use the node (edge) to denote FSM-state (action) for ease of representation. Next, we illustrate how to build the FSM. SQL grammar to FSM. Actually, our FSM (Figure 2 ) can be easily built and extended from the SQL grammar, which are categorized into several cases for ease of representation.",
                "cite_spans": [],
                "section": "FSM IN THE ENVIRONMENT",
                "sec_num": "5"
            },
            {
                "text": "[Case 1: SPJ Query.] This case describes the commonly-used Select-Project-Join query. The FSM in Figure 1 is a summarization of the one in Figure 2 , where each node in Figure 1 corresponds to a more detailed SQL structure described by the grammar.",
                "cite_spans": [],
                "section": "FSM IN THE ENVIRONMENT",
                "sec_num": "5"
            },
            {
                "text": "For example, after the From, we consider two categories: (1) query from a table, and (2) query from multiple tables with join. More concretely, the From clause is related to the blue nodes of Figure 2 , where \ud835\udc5b 1 \u2192 \ud835\udc5b 2 \u2192 \ud835\udc5b 5 (query from the single table Score) and \ud835\udc5b 1 \u2192 \ud835\udc5b 3 \u2192 \ud835\udc5b 7 (query from Student) are built based on the rst category. The second category, \ud835\udc56.\ud835\udc52., \ud835\udc5b 1 \u2192 (\ud835\udc5b 2 \ud835\udc5c\ud835\udc5f \ud835\udc5b 3 ) \u2192 \ud835\udc5b 6 refers to joining the two tables. Note that the corresponding join keys will be automatically added. Then, we come to the Select clause, which is associated with the green nodes \ud835\udc5b 5 , \ud835\udc5b 6 and \ud835\udc5b 7 . The contents are speci ed by the selectTerm+ in the grammar, including the columns to be projected de ned in Case * , \ud835\udc52.\ud835\udc54., T 1 .ID.",
                "cite_spans": [],
                "section": "FSM IN THE ENVIRONMENT",
                "sec_num": "5"
            },
            {
                "text": "[Case 2: Nested Query.] As shown in Table 1 , we support nested queries by adding QUERY in the Where or From clause. Then, ideally, subqueries can be generated recursively. Consequently, in the FSM, we add another branch starting with Select \u2192 \ud835\udc5b 14 \u2192 From \u2192 \u2022 \u2022 \u2022 . [Case 3: Aggregation Query.] We also support aggregation queries by adding the Groupby and Having clauses, which are also integrated into the FSM.",
                "cite_spans": [],
                "section": "FSM IN THE ENVIRONMENT",
                "sec_num": "5"
            },
            {
                "text": "[Case 4&5&6: Insert/Update/Delete Query.] Our FSM can support di erent query types including insert, update and delete. Syntactic and Semantic Checking. Our method can support syntactic and semantic correctness checking by integrating rules into FSM. First, syntactic correctness checking veri es that reserved words, object names (table/column), operators, delimiters, and so on are placed correctly in an SQL query. This guarantees to generate valid SQL queries. Second, semantic correctness checking veri es that references to database objects and variables are valid and the datatypes are correct. For example, nonexistent columns/tables cannot be used; only numerical attributes can be included in average/sum/max/min aggregation operations; columns with di erent datatypes cannot be joined, e.g., ID and Name. Meaningful Checking. It is rather hard to support meaningful checking because it relies on domain knowledge. Our current version supports rule-based meaningful checking. For example, if a user de nes a rule \"two columns can join, only if they have Primarykey-Foreign-key relations or user-speci ed join relations\", then two columns satisfying this rule can be joined. We leave supporting more general meaningful checking as a future work. Dynamic FSM construction. The FSM may be large. To address this, in fact, we can build it as the query generation process goes on the y. For example, as shown in Figure 2 , after reaching \ud835\udc5b 1 , if the agent selects Score rather than Student, \ud835\udc5b 2 is produced and \ud835\udc5b 3 does not need to appear, and thus many branches can be pruned. Hence, given an intermediate query, we generate the edges based on the SQL grammar and some semantic rules. After the agent selects an edge, we produce a new node while pruning the rest edges. We repeat the above step until the EOF is selected. E 5. Given D with two relations (Score and Student in Figure 1 ), we can build an FSM as shown in Fig 2 , which guides the generation of a query. To be speci c, it starts from a Start node, corresponding to a vacant query. Then the From edge is necessary in a query, leading to the node \ud835\udc5b 1 . Then there are two ways to go, \ud835\udc56.\ud835\udc52., either selecting Score or Student, leading to \ud835\udc5b 2 or \ud835\udc5b 3 . The selection is done by the agent in the RL framework (see Figure 1 ). Finally, when we reach the EOF node, a query is fully generated. Supported and Unsupported SQL Syntax. Our current version supports the following SQL syntax: Insert/Delete/Update/Select, Selection, Projection, Join, Aggregation, Group by, Having, Nested Queries. Like is not yet supported. A possible way to support Like is incorporating the keyword \"Like\" into the FSM and sampling substrings from the values of a column as \"values\", and we leave the details of this as a future work.",
                "cite_spans": [],
                "section": "FSM IN THE ENVIRONMENT",
                "sec_num": "5"
            },
            {
                "text": "In the previous sections, given a user-speci ed constraint, we can train a model to generate queries satisfying the constraint. However, if users want to generate queries with another constraint, a bruteforce method is to retrain a new model. However, it is prohibitively expensive to train a number of models from scratch when there are queries to be generated with various constraints, which is a common phenomenon in reality. To address this goal, a natural solution is to ne-tune trained model corresponding to a distinct range or point constraint, but there exist in nite number of ranges or points in the cardinality/cost domain, and thus we cannot train and store so many models. Hence, inspired by the meta-critic network [51] , we propose to just train a single model on a relatively large cardinality/cost domain. Then given a task with a new constraint, we can e ciently generalize the model to support the new constraint. Next, we introduce the motivation of the meta-critic network, and show how to conduct the training and inference steps of the network. Motivation of the meta-critic network: meta-critic is a metalearning method with good generalization ability, which is studied based on the actor-critic network as discussed in Section 4. Specifically, recap that the actor-critic network jointly trains a pair of networks where the actor learns to provide the solution, and the critic learns how to e ectively supervise the actor. Di erent with conventional actor-critic model, the key idea is to learn a metacritic: a state-value function(\ud835\udc56.\ud835\udc52., V) neural network that learns to criticize any actor trying to solve any speci ed task. Intuitively, with multiple actors trains with one shared meta-critic, it learns the transferable knowledge among these actors and tasks that allow actors to be trained e ciently and e ectively on a new problem. Bridging the meta-critic network to our problem: To improve the generalization ability of our method, we will apply the metacritic network to our problem. Note that the meta-critic network takes as input di erent but related tasks. In our problem, although the number of possible range/point constraints is in nite, but we can assume a cardinality/cost domain, say [0, 10K], for the queries to be generated, given the database D. Then we can divide the douniformly into \ud835\udc3e subranges, each of which corresponds to a constraint, \ud835\udc56.\ud835\udc52., a task, and thereby we have multiple tasks. We use the notation C to denote the set of constraints. Suppose \ud835\udc3e = 5, and the",
                "cite_spans": [
                    {
                        "start": 730,
                        "end": 734,
                        "text": "[51]",
                        "ref_id": "BIBREF49"
                    }
                ],
                "section": "PRE-TRAINING FOR DIFFERENT CONSTRAINTS",
                "sec_num": "6"
            },
            {
                "text": "C = {[0, 2K], [2K, 4K], [4K, 6K], [6K, 8K], [8K, 10K]}.",
                "cite_spans": [],
                "section": "PRE-TRAINING FOR DIFFERENT CONSTRAINTS",
                "sec_num": "6"
            },
            {
                "text": "Next, we can train with these tasks (actors) together to obtain a meta-critic network. When it comes to a new task with a constraint (within the domain [0, 10K]), we can leverage the knowledge obtained from the previous \ud835\udc3e tasks to better train the new task.",
                "cite_spans": [],
                "section": "PRE-TRAINING FOR DIFFERENT CONSTRAINTS",
                "sec_num": "6"
            },
            {
                "text": "Next, we show the concrete mechanisms of the training and inference steps mainly for range constraints. For the point constraint, the method is similar and we will discuss it at the end of this section. Meta-critic training: In this part, given the database D and the constraint set C (produced from the domain), we focus on how to train a meta-critic network and reveal its intrinsic characteristic that can help to generalize to a new task e ciently and e ectively. To this end, in the actor-critic framework, it is signi cant for the critic network to estimate the long-term reward, \ud835\udc56.\ud835\udc52., the \ud835\udc49 value accurately, which guides the actor to generate proper queries. Hence, the goal of the meta-critic network is to make the new task estimate an accurate \ud835\udc49 value in few trials e ciently.",
                "cite_spans": [],
                "section": "PRE-TRAINING FOR DIFFERENT CONSTRAINTS",
                "sec_num": "6"
            },
            {
                "text": "To achieve this, the meta-critic network incorporates multiple actors, each of which corresponds to a constraint (task) in C. Another key factor is that it adds a constraint encoder, which potentially embeds the information w.r.t. di erent tasks. Hence, the meta-critic network has captured the relationship between di erent tasks and their corresponding \ud835\udc49 values, given some generated queries. Once a new task arrives, the meta-critic can capture the feature of the new task through the constraint encoder, and leverage the learned knowledge of previous tasks that have close relationships with the new one to generalize quickly. Moreover, the meta-critic keeps learning to criticize actors from new tasks, it accumulates transferable knowledge and never gets 'out of date'.",
                "cite_spans": [],
                "section": "PRE-TRAINING FOR DIFFERENT CONSTRAINTS",
                "sec_num": "6"
            },
            {
                "text": "As shown in Figure 3 , initially given the domain [0, 10K], we divide it to 5 tasks (actors) with 5 successive range constraints. Then the training process begins. First, these actors one-by-one generate SQL queries served as the training data. For each task, the query generation way is the same as discussed in Section 3.3. For example, the rst task in Figure 3 aims to generate queries with cardinality in [0, 2K]. Second, for the actor-critic network in the previous section, the generated query is sent to the environment for execution, and the returned reward is utilized to update both networks. Di erent from that, the meta-critic framework adds a constraint encoder, which embeds the current state (\ud835\udc56.\ud835\udc52., the query), selected action (\ud835\udc56.\ud835\udc52., the token) and the returned reward by the environment, denoted by a triple (\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 , \ud835\udc5f \ud835\udc61 ). Then the outputs of the constraint encoder, denoted by \ud835\udc67 \ud835\udc61 , can potentially describe the task, because the task directly determines the reward, given the query and selected token. Third, the meta-value network takes as input (\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 , \ud835\udc67 \ud835\udc61 ), and estimates the long-term reward, \ud835\udc56.\ud835\udc52., the \ud835\udc49 value. Di erent from the critic network in basic actor-critic model, the meta-value network estimates the long-term reward based on both the generated queries and constraints, which considers the historical training experience of di erent constraints.",
                "cite_spans": [],
                "section": "PRE-TRAINING FOR DIFFERENT CONSTRAINTS",
                "sec_num": "6"
            },
            {
                "text": "Next formally, with the estimated \ud835\udc49 value, the actor is trained by",
                "cite_spans": [],
                "section": "PRE-TRAINING FOR DIFFERENT CONSTRAINTS",
                "sec_num": "6"
            },
            {
                "text": "\u2207\ud835\udc3d (\ud835\udf03 ) = E \ud835\udf0b \ud835\udf03 ( \ud835\udc47 \ud835\udc61 =0 \u2207 \ud835\udf03 \ud835\udc59\ud835\udc5c\ud835\udc54\ud835\udf0b \ud835\udf03 (\ud835\udc4e \ud835\udc61 |\ud835\udc60 \ud835\udc61 )\ud835\udc34(\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 , \ud835\udc67 \ud835\udc61 ))",
                "cite_spans": [],
                "section": "PRE-TRAINING FOR DIFFERENT CONSTRAINTS",
                "sec_num": "6"
            },
            {
                "text": ", where the critic can give relatively accurate estimation of \ud835\udc34(\ud835\udc60 \ud835\udc61 , \ud835\udc4e \ud835\udc61 , \ud835\udc67 \ud835\udc61 ) (based on the \ud835\udc49 value) and e ciently guide the actor to nd proper queries. Similar to Section 4, we then update both the meta-value network and constraint encoder based on the loss function, L \ud835\udf19 = (\ud835\udc5f \ud835\udc61 + \ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 +1 , \ud835\udc67 \ud835\udc61 ) -\ud835\udc49 \ud835\udf19 (\ud835\udc60 \ud835\udc61 , \ud835\udc67 \ud835\udc61 )) 2 , which approximates the distance from the actual long-term reward under the new constraint. Meta-critic generalization: As discussed before, given a new task, if the meta-value network can estimate the \ud835\udc49 value accurately and e ciently, the actor can quickly adjust its policy to generate queries satisfy the new constraint. Recap that the meta-value network in the meta-critic framework can capture the feature of di erent tasks (incorporated by the constraint encoder), the queries(\ud835\udc56.\ud835\udc52., state) and output the \ud835\udc49 value. Hence, for a new task, leveraging the learned meta-critic framework, one can identify the new task's feature and use the previously learned knowledge to quickly estimate an accurate \ud835\udc49 value, which leads to e cient actor training. For example, given a new task of generating SQL queries satisfying a constraint [1k, 2.5k], we can mostly leverage the learned knowledge from pre-trained similar tasks, \ud835\udc56.\ud835\udc52., the constraints [0\ud835\udc58, 2\ud835\udc58] and [2\ud835\udc58, 4\ud835\udc58], to quickly train the new task. Furthermore, after the new task is trained, the knowledge of the task is also incorporated into the meta-critic network, and thus the network will become more and more powerful. Remark for the point constraint. We can sample some points in the domain to pre-train the meta-critic network. For example, we can sample a set of cardinality points C = {10 1 , 10 2 , 10 3 , 10 4 , 10 5 } with di erent magnitude and train a meta-critic network. Then, given a new task of Card = 2K, the meta-critic e ciently learn the task potentially leveraging the knowledge of the previous tasks.",
                "cite_spans": [],
                "section": "PRE-TRAINING FOR DIFFERENT CONSTRAINTS",
                "sec_num": "6"
            },
            {
                "text": "We have conducted extensive experiments to show the superiority of our proposed LearnedSQLGen framework.",
                "cite_spans": [],
                "section": "EXPERIMENTS",
                "sec_num": "7"
            },
            {
                "text": "Datasets. We used three benchmark datasets which are widely used in our database community. (1) TPC-H [2] is a popular benchmark that contains 8 relational tables (We produce the data with size of 33 GB in total). Given these tables, LearnedSQLGen can generate SQL queries that can be executed over them. (2) JOB [1] is another widelyused benchmark (uses a real-world dataset IMDB) that consists of 21 tables (with size of 14 GB in total). ( 3) XueTang [3] is a real-world OLTP benchmark of the online education, which contains 14 tables (with size of 24 GB in total). Baselines. We compared with two baselines in the paper.",
                "cite_spans": [
                    {
                        "start": 102,
                        "end": 105,
                        "text": "[2]",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 453,
                        "end": 456,
                        "text": "[3]",
                        "ref_id": "BIBREF1"
                    }
                ],
                "section": "Experiment Setting",
                "sec_num": "7.1"
            },
            {
                "text": "(1) SQLSmith [47] randomly generated SQLs based on a parse tree, from which we picked the queries satis ed the constraints.",
                "cite_spans": [
                    {
                        "start": 13,
                        "end": 17,
                        "text": "[47]",
                        "ref_id": "BIBREF45"
                    }
                ],
                "section": "Experiment Setting",
                "sec_num": "7.1"
            },
            {
                "text": "(2) Template [10] generated satis ed SQL queries by greedily tweaking the predicate values in the given SQL templates. The query templates are constructed from the provided templates of the three benchmarks by reassembling the predicates (e.g., adding or removing a predicate). Hyper-parameter Se ings. The actor network consists of an input layer, followed by a 2-layer LSTM network and an output layer. Note that the number of layers is chosen by balancing e ciency and accuracy. A more complex model is likely to achieve better results but may sacri ce e ciency, and thus we can take it as a hyperparameter tuning problem. Here we use 2-layer. The dimension of the input/output layer is equal to the size of the action space of each dataset. Here, we have the dimension 1962 (TPC-H), 3940 (JOB) and 4280 (XueTang) respectively. We set the sampled numbers of values in each numerical attribute as 100, \ud835\udc56.\ud835\udc52., \ud835\udc58 = 100. The 2-layer LSTM networks have 30 cell units respectively and the second one is connected to the output layer. The structure of the critic network is similar to the actor, but the only di erence is that the output layer dimension is 1 for outputting the \ud835\udc49 value. Dropout [50] is used to avoid over-tting in both the actor and critic networks and it is set to 0.3. We set \ud835\udf06 = 0.01 to prevent the actor from generating a lot of same queries. In the training process, the learning rate is 0.001 for the actor and 0.003 for the critic network. Target Constraints. We evaluated two types of target constraints. (1) Cost denotes the execution expense of an SQL and (2) Cardinality denotes the size of the result of an SQL. We directly used the estimated cardinality/cost by the database estimator to compute the reward. Furthermore, we respectively tested the two types of constraints in forms of points and ranges.",
                "cite_spans": [
                    {
                        "start": 13,
                        "end": 17,
                        "text": "[10]",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 1190,
                        "end": 1194,
                        "text": "[50]",
                        "ref_id": "BIBREF48"
                    }
                ],
                "section": "Experiment Setting",
                "sec_num": "7.1"
            },
            {
                "text": "Evaluation Metrics. We evaluated LearnedSQLGen using two metrics, \ud835\udc56.\ud835\udc52., generation accuracy and generation time.",
                "cite_spans": [],
                "section": "Experiment Setting",
                "sec_num": "7.1"
            },
            {
                "text": "(1) Generation accuracy (\ud835\udc4e\ud835\udc50\ud835\udc50) represents the ratio of the number of satis ed queries (denoted by \ud835\udc5b \ud835\udc60 ) to the total number of generated queries (denoted by \ud835\udc5b). Then \ud835\udc4e\ud835\udc50\ud835\udc50 = \ud835\udc5b \ud835\udc60 \ud835\udc5b . A higher accuracy re ects that the method is more powerful in generating satis ed SQLs. For the point constraint, it is hard for the cardinality/cost \ud835\udc50 to be a value exactly, so a small error bound \ud835\udf0f is set, which means that if the cardinality/cost of a generated query is within [\ud835\udc50 -\ud835\udf0f, \ud835\udc50 + \ud835\udf0f], we regard it as a satis ed query. To be speci c, we set \ud835\udf0f as 0.1 * \ud835\udc50, which is reasonable because a 10% deviation from \ud835\udc50 is acceptable. Hence, \ud835\udc5b \ud835\udc60 denotes the number of such queries. For the range constraint, \ud835\udc5b \ud835\udc60 just denotes the number of queries in the range.",
                "cite_spans": [],
                "section": "Experiment Setting",
                "sec_num": "7.1"
            },
            {
                "text": "(2) Generation time represents the time of generating a xed number (\ud835\udc52.\ud835\udc54., 1K) of satis ed SQLs including the training and inference phases. A lower generation time indicates that the generation method is more e cient. Environment. All experiments were implemented in Python, performed on a Ubuntu Server with an Intel (R) Xeon (R) Silver 4110 2.10GHz CPU having 32 cores, a Nvidia Geforce 2080ti GPU, and 128GB DDR4 main memory without SSD.",
                "cite_spans": [],
                "section": "Experiment Setting",
                "sec_num": "7.1"
            },
            {
                "text": "In this subsection, we compared the accuracy and e ciency of LearnedSQLGen with the random-based method (SQLSmith) and template-based heuristic method (Template).",
                "cite_spans": [],
                "section": "Overall Evaluation",
                "sec_num": "7.2"
            },
            {
                "text": "We rst evaluated the accuracy for cardinality constraint and then the cost. Varying the Cardinality. As shown in Figure 4 , we generated 1K queries on three datasets, and tested the accuracy of di erent point and range cardinality constraints and the results showed that LearnedSQLGen outperformed the baselines. For example, in the \ud835\udc65-axis of Figure 4 (a), Cardinality = 10 2 denotes that we aim to generate queries with cardinality as close to 10 2 as possible, \ud835\udc56.\ud835\udc52., queries with cardinality between 90 and 110 are satis ed ones. On TPC-H, LearnedSQLGen achieved an accuracy of 54.33%, while SQLSmith and Template had 0.02% and 18.98% respectively. Thus, LearnedSQLGen outperformed SQLSmith because SQLSmith generated queries randomly without considering the constraints, but LearnedSQLGen incorporated the constraints and the execution feedback from the database into reward computation in the design of our reinforcement learning model. Hence, we can capture the relationship between the SQL query and its cardinality/cost, and thus the generation direction is guided by the model. In Figure 4 (a), SQLSmith gained the highest accuracy (\ud835\udc56.\ud835\udc52., 0.53%) at Cardinality = 10 6 mainly because, on this dataset, the cardinality of random generated queries is close to 10 6 than other point constraints, but it is still much lower than that of LearnedSQLGen. LearnedSQLGen outperformed Template because the templates in Template were not guaranteed to be high-quality (\ud835\udc56.\ud835\udc52., can be adjusted to meet the given constraint), and thus some of them cannot produce the satis ed queries. As shown in Figures 4(c, e ), LearnedSQLGen still outperformed the two baselines. For example, in Figure 4 (c), when the cardinality was Cardinality = 10 4 , LearnedSQLGen achieved an accuracy of 59.30%, while SQLSmith and Template were 0.05% and 24.94% respectively. We also tested the accuracy for di erent range constraints. For example, as shown in Figure 4 (b), Cardinality \u2208 [1K, 2K] denotes that we aim to generate queries with cardinality within this range. On TPC-H, LearnedSQLGen still outperformed the baselines for similar reasons. LearnedSQLGen achieved an accuracy of 54.12%, while SQLSmith and Template had 0.064% and 17.16% respectively. We can see that as the range gets wider, the accuracy of all the three methods is generally higher. For example, for LearnedSQLGen, compared with Cardinality \u2208 [1K, 2K] (54.12%), the accuracy is 66.23% when Cardinality \u2208 [1K, 8K]. This is because there will be naturally more queries satisfying a wider range constraint. Varying the Cost. Our LearnedSQLGen can also support the cost constraint, as shown in Figure 5 . Due to the similar reasons, LearnedSQLGen still outperforms the baselines. For example, for the point constraint on XueTang dataset, when Cost = 10 6 , LearnedSQLGen achieves an accuracy of 53.66%, which is much better than that of SQLSmith (0.24%) and Template (18.11%). For the range constraint on JOB dataset, Cost \u2208 [1K, 8K], LearnedSQLGen achieves an accuracy of 51.37%, while SQLSmith and Template are 2.17% and 20.15% respectively. 7.2.2 E iciency of the query generation. We tested the e ciency of LearnedSQLGen to generate satis ed queries. Varying the Cardinality. In Figure 6 , we evaluated the e ciency of di erent cardinality constraints on three datasets. Overall, we can see that our method outperformed all the baselines. For example, as shown in Figure 6 (a), on TPC-H dataset, if we want to generate queries close to 10 8 , LearnedSQLGen only consumed 0.63 hours, but SQLSmith and Template had to spend 11 hours and 2.72 hours respectively. The reason is that SQLSmith just randomly generated queries, and thus it took a longer time to generate 1K satis ed queries. Template took a longer time because some templates cannot produce satis ed queries by just exploring operands in predicates but keeping template structures xed. This wasted a lot of time on the given templates, so it performed even worse than SQLSmith. For example, when Template aimed to generate queries satisfying the constraint Cardinality = 10 8 on TPC-H, Template took as input a template Select * From Customer Where Customer.c_custkey < x but it can never reach 10 8 by adjust parameter x because the total number of rows in the table Customer is less than 10 8 . From this perspective, LearnedSQLGen is more e ective as it explores both the query structures (\ud835\udc56.\ud835\udc52., templates) and the parameters. For range constraints, we have similar observations. For example, as shown in Figure 6 Varying the Cost. We also tested the e ciency of di erent methods with respect to the cost constraint. As shown in Figure 7 . We can observe that LearnedSQLGen outperformed the baselines. For example, for the point constraint on TPC-H dataset, when Cost = 10 ",
                "cite_spans": [],
                "section": "Accuracy of generated queries.",
                "sec_num": "7.2.1"
            },
            {
                "text": "We evaluated the e ciency of the actor-critic (AC) algorithm in LearnedSQLGen by comparing with the simple reinforcement learning algorithm (REINFORCE) mentioned in Section 4.3 on solving constraint-aware query generation problem. We had three observations. First, we can observe that, by leveraging the actor-critic network, we can perform better than using the REINFORCE algorithm on accuracy. Speci cally, as shown in Figure 8 (a), on JOB dataset, given the constraint Cardinality \u2208 [1K, 4K], LearnedSQLGen achieved an accuracy of 65.43%, which is 9.2% higher than that of REINFORCE. The reason is that our method can reduce the variance of the returned rewards and keeps policy gradient update steadily, which, to some extent, prevents the network from converging to the local optimum. Second, as shown in Figure 8 (b), our method is more e cient than the REINFORCE algorithm. For example, when Cardinality \u2208 [1K, 4K], LearnedSQLGen spent 0.51 hours to acquire 1K satis ed queries while REINFORCE took 2.2 hours. The reason is that LearnedSQLGen converged faster and was more accurate than REINFORCE, such that it took less time to acquire the same number of satis ed queries. Third, in Figure 8 (c), we showed the training process of REINFORCE and LearnedSQLGen.",
                "cite_spans": [],
                "section": "Evaluation of the actor-critic network",
                "sec_num": "7.3"
            },
            {
                "text": "It illustrated that with the number of training epochs increasing, the returned reward of LearnedSQLGen was much higher than that of REINFORCE. This indicated that our method converged more steadily and achieved a higher performance.",
                "cite_spans": [],
                "section": "Evaluation of the actor-critic network",
                "sec_num": "7.3"
            },
            {
                "text": "We evaluated our meta-critic network that can generalize our model to di erent constraints. We compared with three strategies.",
                "cite_spans": [],
                "section": "Meta-critic Network Evaluation",
                "sec_num": "7.4"
            },
            {
                "text": "(1) Given a new constraint, we trained LearnedSQLGen from scratch (Scrach); (2) We used the pre-trained meta-critic network to quickly generalize to the new constraint (MetaCritic).",
                "cite_spans": [],
                "section": "Meta-critic Network Evaluation",
                "sec_num": "7.4"
            },
            {
                "text": "(3) We directly encoded multiple constraints to the state without using the meta-critic, AC-extend. Speci cally, we tested the point constraint for cardinality. Overall, we made three observations. First, MetaCritic significantly reduced the query generation time, because MetaCritic learned from historical training experience, provided relatively accurate long-term reward, and e ciently guided the agent to select proper tokens to generate SQLs. Instead, Scrach needed to learn the estimation of long-term reward from scratch, and thus took much longer time. Compared with AC-extend, our meta-critic method also encoded the constraints, but in a more ne-grained way. More concretely, we potentially speci ed the constraints based on the triple (state, action, reward) because the state and action can specify a query (subquery), and its reward had a close relation with the constraint. Then, using the triple as the constraint encoder captured more transferrable knowledge among di erent tasks, and thus leaded to good generalization ability. However, AC-extend cannot generalize well because it is hard to capture the relationships among tasks by purely encoding the tasks. Second, as shown in Figure 9 (a), all the three baselines can achieve high accuracy, because they can nally converge to a relatively optimal generation policy. However, MetaCritic had a slightly higher accuracy than Scrach and AC-extend because it considered both the historical experience and the new constraint, which was captured automatically by the triple (state, action, reward). But Scrach purely learned from newly generated query samples and AC-extend captured the constraint by simply feeding into the neural network. Third, as shown in Figure 9 (c), although these baselines had similar performance at initial epochs, as the number of training epochs grew, MetaCritic quickly generated satis ed queries guided by more accurate long-term rewards, while Scrach and AC-extend took more time to estimate the long-term rewards.",
                "cite_spans": [],
                "section": "Meta-critic Network Evaluation",
                "sec_num": "7.4"
            },
            {
                "text": "We evaluate the diversity and complexity of the generated queries, and report the query distributions from di erent perspectives, including predicate numbers, aggregation keywords, nested queries, join queries, SQL types, and number of SQL tokens. In Figure 10 (a), the satis ed queries are likely associated with multi-join tables. We can see the ratio of queries with multi-join is over half of total generated queries. In Figure 10 (b) and (c), we can see that complicated structures, \ud835\udc52.\ud835\udc54., nested (47%) and aggregation (34.9%) queries, can be generated. In Figure 10 For the low cardinality range in [1k, 8k], the satis ed queries usually contain multiple predicates (\ud835\udc52.\ud835\udc54.,, many \"and\") to reduce the cardinality. Hence, in Figure 10 (d), we can see that there are various number of predicates in the generated queries. Also, because of the entropy regularization techniques and our extendable FSM, our method can support various query types as shown in Figure 10(e) . At last, Figure 10 (f) shows the SQL length distribution, where the \ud835\udc65-axis denotes the number of tokens and the \ud835\udc66-axis denotes the frequency. We can observe that LearnedSQLGen can generate various lengths of queries, which veri es that we can generate diverse and complicated queries.",
                "cite_spans": [],
                "section": "Case Study of Generated Queries",
                "sec_num": "7.5"
            },
            {
                "text": "We have added experiments to evaluate the performance of generating complicated queries in Figure 11 , where the \ud835\udc65-axis denotes the number of di erent types of generated complex queries (including nested, insert, delete queries), and the \ud835\udc66-axis denotes the time spent to generate these nested queries that satisfy the constraint (speci ed by the legend, \ud835\udc52.\ud835\udc54., Cost=10 2 ). From the results, we can observe that LearnedSQLGen can generate various types of queries by extending the FSM. Thus our method is applicable to generate various of complicated SQL queries.",
                "cite_spans": [],
                "section": "Complicated Queries Generation",
                "sec_num": "7.6"
            },
            {
                "text": "We evaluate the impact of di erent sampled sizes of numerical values in Figure 12 . The \ud835\udc65-axis is the sample ratio \ud835\udf02 which is the ratio of the sample size to the total number of distinct values in a column. We evaluate both the point and range constraints in this experiment. For accuracy, we can see from Figure 12 (a) that with the sample size becoming larger, the accuracy becomes higher because more actions can be chosen. Moreover, the accuracy keeps stable after a number of data have been sampled, because a certain number of samples can cover a very large search space and it is enough to cover the queries satisfying the user-speci ed constraints. Therefore, our framework is not much sensitive to the sample size. For e ciency, we can observe that with \ud835\udf02 becoming larger, the spent time decreases at the beginning and then increases. This is because SQL generation time includes training time and inference time, and increasing the sample size makes training slow (a larger search space) but accelerates inference (higher SQL coverage). Thus at the beginning, it slightly increases the training time but signi cantly decreases the inference time, and thus the total time is smaller; but later, it signi cantly increases the training time, and thus the total time becomes larger.",
                "cite_spans": [],
                "section": "Evaluation on Sample Sizes",
                "sec_num": "7.7"
            },
            {
                "text": "In this paper, we have studied SQL queries generation by considering the target constraints including cardinality and cost. We designed an RL framework to conduct query generation, where an exploration-exploitation strategy was applied to exploit the optimal generation direction and explore multiple possible directions. In addition, we adopted an FSM to guarantee that we can generate valid queries. Moreover, to improve generalization ability, we proposed a meta-critic network that learned from historic and used the model to directly generate queries for a new constraint. Experimental results showed that our method signi cantly outperformed baselines in terms of both accuracy and e ciency.",
                "cite_spans": [],
                "section": "CONCLUSION",
                "sec_num": "8"
            },
            {
                "text": "This paper was supported by NSF of China (61925205, 61632016, 62102215), Huawei, TAL education, and Beijing National Research Center for Information Science and Technology (BNRist). Chengliang Chai is supported by China National Postdoctoral Program for Innovative Talents (BX2021155), Postdoctoral Foundation (2021M691784), Tsinghua Shuimu Scholar and Zhejiang Lab's International Fund for Young Professionals.",
                "cite_spans": [],
                "section": "ACKNOWLEDGEMENT",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "Tpch benchmark",
                "authors": [],
                "dblp_id": null,
                "year": null,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tpch benchmark. http://www.tpc.org.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Xuetang dataset",
                "authors": [],
                "dblp_id": null,
                "year": null,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Xuetang dataset. https://www.xuetangx.com/.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Automated generation of materialized views in oracle",
                "authors": [
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Ahmed",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [
                            "G"
                        ],
                        "last": "Bello",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Witkowski",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Kumar",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2020,
                "venue": "Proc. VLDB Endow",
                "volume": "13",
                "issue": "12",
                "pages": "3046--3058",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "R. Ahmed, R. G. Bello, A. Witkowski, and P. Kumar. Automated generation of materialized views in oracle. Proc. VLDB Endow., 13(12):3046-3058, 2020.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Learning-based query performance modeling and prediction",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Akdere",
                        "suffix": ""
                    },
                    {
                        "first": "U",
                        "middle": [],
                        "last": "\u00c7etintemel",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Riondato",
                        "suffix": ""
                    },
                    {
                        "first": "E",
                        "middle": [],
                        "last": "Upfal",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [
                            "B"
                        ],
                        "last": "Zdonik",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/icde/AkdereCRUZ12",
                "year": 2012,
                "venue": "ICDE",
                "volume": "",
                "issue": "",
                "pages": "390--401",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "M. Akdere, U. \u00c7etintemel, M. Riondato, E. Upfal, and S. B. Zdonik. Learning-based query performance modeling and prediction. In ICDE, pages 390-401, 2012.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "An inquiry into machine learning-based automatic con guration tuning services on real-world database management systems",
                "authors": [
                    {
                        "first": "D",
                        "middle": [
                            "V"
                        ],
                        "last": "Aken",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Brillard",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Fiorino",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Billian",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Pavlo",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2021,
                "venue": "Proc. VLDB Endow",
                "volume": "14",
                "issue": "7",
                "pages": "1241--1253",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "D. V. Aken, D. Yang, S. Brillard, A. Fiorino, B. Zhang, C. Billian, and A. Pavlo. An inquiry into machine learning-based automatic con guration tuning services on real-world database management systems. Proc. VLDB Endow., 14(7):1241-1253, 2021.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "An actor-critic algorithm for sequence prediction",
                "authors": [
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Bahdanau",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Brakel",
                        "suffix": ""
                    },
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Goyal",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Lowe",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Pineau",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [
                            "C"
                        ],
                        "last": "Courville",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/iclr/BahdanauBXGLPCB17",
                "year": 2017,
                "venue": "ICLR. OpenReview.net",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "D. Bahdanau, P. Brakel, K. Xu, A. Goyal, R. Lowe, J. Pineau, A. C. Courville, and Y. Bengio. An actor-critic algorithm for sequence prediction. In ICLR. OpenReview.net, 2017.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "A genetic approach for random testing of database systems",
                "authors": [
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Bati",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Giakoumakis",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Herbert",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Surna",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/vldb/BatiGHS07",
                "year": 2007,
                "venue": "VLDB, VLDB '07",
                "volume": "",
                "issue": "",
                "pages": "1243--1251",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "H. Bati, L. Giakoumakis, S. Herbert, and A. Surna. A genetic approach for random testing of database systems. In VLDB, VLDB '07, page 1243-1251. VLDB Endowment, 2007.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Database benchmarking for supporting real-time interactive querying of large data",
                "authors": [
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Battle",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Eichmann",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Angelini",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Catarci",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Santucci",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Binnig",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Fekete",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Moritz",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/BattleEACSZBFM20",
                "year": 2020,
                "venue": "SIGMOD",
                "volume": "",
                "issue": "",
                "pages": "1571--1587",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "L. Battle, P. Eichmann, M. Angelini, T. Catarci, G. Santucci, Y. Zheng, C. Bin- nig, J. Fekete, and D. Moritz. Database benchmarking for supporting real-time interactive querying of large data. In SIGMOD, pages 1571-1587, 2020.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "Generating queries with cardinality constraints for dbms testing",
                "authors": [
                    {
                        "first": "N",
                        "middle": [],
                        "last": "Bruno",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Chaudhuri",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Thomas",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2006,
                "venue": "",
                "volume": "18",
                "issue": "",
                "pages": "1721--1725",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "N. Bruno, S. Chaudhuri, and D. Thomas. Generating queries with cardinality constraints for dbms testing. volume 18, pages 1721-1725, 2006.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Human-in-the-loop outlier detection",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Luo",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Madden",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/ChaiC00LM20",
                "year": 2020,
                "venue": "SIGMOD 2020",
                "volume": "",
                "issue": "",
                "pages": "19--33",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. Chai, L. Cao, G. Li, J. Li, Y. Luo, and S. Madden. Human-in-the-loop outlier detection. In SIGMOD 2020, pages 19-33. ACM, 2020.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "Human-in-the-loop techniques in machine learning",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2020,
                "venue": "IEEE Data Eng. Bull",
                "volume": "43",
                "issue": "3",
                "pages": "37--52",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. Chai and G. Li. Human-in-the-loop techniques in machine learning. IEEE Data Eng. Bull., 43(3):37-52, 2020.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Selective data acquisition in the wild for model charging",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "N",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Luo",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": null,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. Chai, J. Liu, N. Tang, G. Li, and Y. Luo. Selective data acquisition in the wild for model charging.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Data management for machine learning: A survey",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Luo",
                        "suffix": ""
                    },
                    {
                        "first": "Z",
                        "middle": [],
                        "last": "Niu",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2022,
                "venue": "TKDE",
                "volume": "",
                "issue": "",
                "pages": "1--1",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. Chai, J. Wang, Y. Luo, Z. Niu, and G. Li. Data management for machine learning: A survey. TKDE, pages 1-1, 2022.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "End-to-end entity resolution for big data: A survey",
                "authors": [
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Christophides",
                        "suffix": ""
                    },
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Efthymiou",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Palpanas",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Papadakis",
                        "suffix": ""
                    },
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Stefanidis",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "V. Christophides, V. Efthymiou, T. Palpanas, G. Papadakis, and K. Stefanidis. End-to-end entity resolution for big data: A survey. CoRR, abs/1905.06397, 2019.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "DSB: A decision support benchmark for workload-driven and traditional database systems",
                "authors": [
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Ding",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Chaudhuri",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Gehrke",
                        "suffix": ""
                    },
                    {
                        "first": "V",
                        "middle": [
                            "R"
                        ],
                        "last": "Narasayya",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2021,
                "venue": "Proc. VLDB Endow",
                "volume": "14",
                "issue": "13",
                "pages": "3376--3388",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "B. Ding, S. Chaudhuri, J. Gehrke, and V. R. Narasayya. DSB: A decision support benchmark for workload-driven and traditional database systems. Proc. VLDB Endow., 14(13):3376-3388, 2021.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "ALEX: an updatable adaptive learned index",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Ding",
                        "suffix": ""
                    },
                    {
                        "first": "U",
                        "middle": [
                            "F"
                        ],
                        "last": "Minhas",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/DingMYWDLZCGKLK20",
                "year": 2020,
                "venue": "SIGMOD",
                "volume": "",
                "issue": "",
                "pages": "969--984",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Ding, U. F. Minhas, J. Yu, and et al. ALEX: an updatable adaptive learned index. In SIGMOD, pages 969-984. ACM, 2020.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "Sqlcheck: Automated detection and diagnosis of SQL anti-patterns",
                "authors": [
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Dintyala",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Narechania",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Arulraj",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/DintyalaNA20",
                "year": 2020,
                "venue": "SIGMOD",
                "volume": "",
                "issue": "",
                "pages": "2331--2345",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "P. Dintyala, A. Narechania, and J. Arulraj. Sqlcheck: Automated detection and diagnosis of SQL anti-patterns. In SIGMOD, pages 2331-2345, 2020.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Diametrics: Benchmarking query engines at scale",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Gruenheid",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Deep",
                        "suffix": ""
                    },
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Nagaraj",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Naito",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "F"
                        ],
                        "last": "Naughton",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Viglas",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2020,
                "venue": "Proc. VLDB Endow",
                "volume": "13",
                "issue": "12",
                "pages": "3285--3298",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Gruenheid, S. Deep, K. Nagaraj, H. Naito, J. F. Naughton, and S. Viglas. Diamet- rics: Benchmarking query engines at scale. Proc. VLDB Endow., 13(12):3285-3298, 2020.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "Cardinality estimation in dbms: A comprehensive benchmark evaluation",
                "authors": [
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    },
                    {
                        "first": "Z",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [
                            "W"
                        ],
                        "last": "Tan",
                        "suffix": ""
                    },
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Zeng",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Cong",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Pfadler",
                        "suffix": ""
                    },
                    {
                        "first": "Z",
                        "middle": [],
                        "last": "Qian",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Cui",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2022,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Y. Han, Z. Wu, P. Wu, R. Zhu, J. Yang, L. W. Tan, K. Zeng, G. Cong, Y. Qin, A. Pfadler, Z. Qian, J. Zhou, J. Li, and B. Cui. Cardinality estimation in dbms: A comprehensive benchmark evaluation, 2022.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Long short-term memory",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Hochreiter",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Schmidhuber",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 1997,
                "venue": "Neural Computation",
                "volume": "9",
                "issue": "8",
                "pages": "1735--1780",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735-1780, 1997.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "A deep-learning prediction model for imbalanced time series data forecasting",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Hou",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2021,
                "venue": "Big Data Min. Anal",
                "volume": "4",
                "issue": "4",
                "pages": "266--278",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. Hou, J. Wu, B. Cao, and J. Fan. A deep-learning prediction model for imbalanced time series data forecasting. Big Data Min. Anal., 4(4):266-278, 2021.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Design continuums and the path toward selfdesigning key-value stores that know and learn",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Idreos",
                        "suffix": ""
                    },
                    {
                        "first": "N",
                        "middle": [],
                        "last": "Dayan",
                        "suffix": ""
                    },
                    {
                        "first": "W",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Akmanalp",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Hilgard",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Ross",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Lennon",
                        "suffix": ""
                    },
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Jain",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Gupta",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Z",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/cidr/IdreosDQAHRLJGL19",
                "year": 2019,
                "venue": "CIDR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Idreos, N. Dayan, W. Qin, M. Akmanalp, S. Hilgard, A. Ross, J. Lennon, V. Jain, H. Gupta, D. Li, and Z. Zhu. Design continuums and the path toward self- designing key-value stores that know and learn. In CIDR, 2019.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "Dynamic context selection for documentlevel neural machine translation via reinforcement learning",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Kang",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Zong",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/emnlp/KangZZZ20",
                "year": 2020,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "2242--2254",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X. Kang, Y. Zhao, J. Zhang, and C. Zong. Dynamic context selection for document- level neural machine translation via reinforcement learning. In EMNLP, pages 2242-2254. Association for Computational Linguistics, 2020.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "A survey on advancing the DBMS query optimizer: Cardinality estimation, cost model, and plan enumeration",
                "authors": [
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Lan",
                        "suffix": ""
                    },
                    {
                        "first": "Z",
                        "middle": [],
                        "last": "Bao",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2021,
                "venue": "Data Sci. Eng",
                "volume": "6",
                "issue": "1",
                "pages": "86--101",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "H. Lan, Z. Bao, and Y. Peng. A survey on advancing the DBMS query optimizer: Cardinality estimation, cost model, and plan enumeration. Data Sci. Eng., 6(1):86- 101, 2021.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "AI meets database: AI4DB and DB4AI",
                "authors": [
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/0001ZC21",
                "year": 2021,
                "venue": "SIGMOD",
                "volume": "",
                "issue": "",
                "pages": "2859--2866",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G. Li, X. Zhou, and L. Cao. AI meets database: AI4DB and DB4AI. In SIGMOD, pages 2859-2866, 2021.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "Machine learning for databases",
                "authors": [
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/aiml2/LiZC21",
                "year": 2021,
                "venue": "Proc. VLDB Endow",
                "volume": "14",
                "issue": "12",
                "pages": "3190--3193",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G. Li, X. Zhou, and L. Cao. Machine learning for databases. Proc. VLDB Endow., 14(12):3190-3193, 2021.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Qtune: A query-aware database tuning system with deep reinforcement learning",
                "authors": [
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2019,
                "venue": "PVLDB",
                "volume": "12",
                "issue": "12",
                "pages": "2118--2130",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "G. Li, X. Zhou, S. Li, and B. Gao. Qtune: A query-aware database tuning system with deep reinforcement learning. PVLDB, 12(12):2118-2130, 2019.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Robust estimation of resource consumption for sql queries using statistical techniques",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [
                            "C"
                        ],
                        "last": "Konig",
                        "suffix": ""
                    },
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Narasayya",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Chaudhuri",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2012,
                "venue": "PVLDB",
                "volume": "5",
                "issue": "11",
                "pages": "1555--1566",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Li, A. C. Konig, V. Narasayya, and S. Chaudhuri. Robust estimation of resource consumption for sql queries using statistical techniques. PVLDB, 5(11):1555-1566, 2012.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Rethinking supervised learning and reinforcement learning in task-oriented dialogue systems",
                "authors": [
                    {
                        "first": "Z",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Kiseleva",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "De Rijke",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/emnlp/0001KR20",
                "year": 2020,
                "venue": "EMNLP, Findings of ACL",
                "volume": "",
                "issue": "",
                "pages": "3537--3546",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Z. Li, J. Kiseleva, and M. de Rijke. Rethinking supervised learning and reinforce- ment learning in task-oriented dialogue systems. In EMNLP, Findings of ACL, pages 3537-3546, 2020.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Continuous control with deep reinforcement learning",
                "authors": [
                    {
                        "first": "T",
                        "middle": [
                            "P"
                        ],
                        "last": "Lillicrap",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "J H"
                        ],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "dblp_id": "journals/corr/LillicrapHPHETS15",
                "year": 2016,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "T. P. Lillicrap and J. J. H. et al. Continuous control with deep reinforcement learning. In ICLR, 2016.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "In ICDM",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Kong",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Chiang",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2018,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "1140--1145",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X. Liu, X. Kong, L. Liu, and K. Chiang. In ICDM, pages 1140-1145, 2018.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Steerable self-driving data visualization",
                "authors": [
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Luo",
                        "suffix": ""
                    },
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "N",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "W",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2022,
                "venue": "TKDE",
                "volume": "34",
                "issue": "1",
                "pages": "475--490",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Y. Luo, X. Qin, C. Chai, N. Tang, G. Li, and W. Li. Steerable self-driving data visualization. TKDE, 34(1):475-490, 2022.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "MB2: decomposed behavior modeling for self-driving database management systems",
                "authors": [
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "W",
                        "middle": [
                            "Z"
                        ],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/0006ZJWBLMP21",
                "year": 2021,
                "venue": "SIGMOD",
                "volume": "",
                "issue": "",
                "pages": "1248--1261",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "L. Ma and W. Z. et al. MB2: decomposed behavior modeling for self-driving database management systems. In SIGMOD, pages 1248-1261, 2021.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Learned approximate query processing: Make it light, accurate and fast",
                "authors": [
                    {
                        "first": "Q",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [
                            "M"
                        ],
                        "last": "Shanghooshabad",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Almasi",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Kurmanji",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Trianta",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/cidr/MaSAKT21",
                "year": 2021,
                "venue": "CIDR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Q. Ma, A. M. Shanghooshabad, M. Almasi, M. Kurmanji, and P. Trianta llou. Learned approximate query processing: Make it light, accurate and fast. In CIDR, 2021.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "Learning to steer query optimizers",
                "authors": [
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Marcus",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Negi",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Mao",
                        "suffix": ""
                    },
                    {
                        "first": "N",
                        "middle": [],
                        "last": "Tatbul",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Alizadeh",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Kraska",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Bao",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "R. Marcus, P. Negi, H. Mao, N. Tatbul, M. Alizadeh, and T. Kraska. Bao: Learning to steer query optimizers. CoRR, abs/2004.03814, 2020.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Deep reinforcement learning for join order enumeration",
                "authors": [
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Marcus",
                        "suffix": ""
                    },
                    {
                        "first": "O",
                        "middle": [],
                        "last": "Papaemmanouil",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/MarcusP18",
                "year": 2018,
                "venue": "aiDM@SIGMOD",
                "volume": "3",
                "issue": "",
                "pages": "1--3",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "R. Marcus and O. Papaemmanouil. Deep reinforcement learning for join order enumeration. In aiDM@SIGMOD, pages 3:1-3:4. ACM, 2018.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "Generating targeted queries for database testing",
                "authors": [
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Mishra",
                        "suffix": ""
                    },
                    {
                        "first": "N",
                        "middle": [],
                        "last": "Koudas",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Zuzarte",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/MishraKZ08",
                "year": 2008,
                "venue": "SIGMOD",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "C. Mishra, N. Koudas, and C. Zuzarte. Generating targeted queries for database testing. In SIGMOD, 2008.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "Asynchronous methods for deep reinforcement learning",
                "authors": [
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Mnih",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/icml/MnihBMGLHSK16",
                "year": 2016,
                "venue": "Proceedings of Machine Learning Research",
                "volume": "48",
                "issue": "",
                "pages": "1928--1937",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "V. Mnih and B. et al. Asynchronous methods for deep reinforcement learning. In ICML, volume 48 of Proceedings of Machine Learning Research, pages 1928-1937, 2016.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Deep learning for entity matching: A design space exploration",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Mudgal",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [
                            "L"
                        ],
                        "last": "",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/MudgalLRDPKDAR18",
                "year": 2018,
                "venue": "SIGMOD",
                "volume": "",
                "issue": "",
                "pages": "19--34",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Mudgal and H. L. et al. Deep learning for entity matching: A design space exploration. In SIGMOD, pages 19-34, 2018.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Learning multi-dimensional indexes",
                "authors": [
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Nathan",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Ding",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Alizadeh",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Kraska",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/NathanDAK20",
                "year": 2020,
                "venue": "SIGMOD",
                "volume": "",
                "issue": "",
                "pages": "985--1000",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "V. Nathan, J. Ding, M. Alizadeh, and T. Kraska. Learning multi-dimensional indexes. In SIGMOD, pages 985-1000, 2020.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Reinforcement learning for bandit neural machine translation with simulated human feedback",
                "authors": [
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Nguyen",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [
                            "D"
                        ],
                        "last": "Iii",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "L"
                        ],
                        "last": "Boyd-Graber",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/emnlp/NguyenDB17",
                "year": 2017,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "1464--1474",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "K. Nguyen, H. D. III, and J. L. Boyd-Graber. Reinforcement learning for bandit neural machine translation with simulated human feedback. In EMNLP, pages 1464-1474, 2017.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "Graph learning for combinatorial optimization: A survey of state-of-the-art",
                "authors": [
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Choi",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2021,
                "venue": "Data Sci. Eng",
                "volume": "6",
                "issue": "2",
                "pages": "119--141",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Y. Peng, B. Choi, and J. Xu. Graph learning for combinatorial optimization: A survey of state-of-the-art. Data Sci. Eng., 6(2):119-141, 2021.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Sequence level training with recurrent neural networks",
                "authors": [
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Ranzato",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Chopra",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Auli",
                        "suffix": ""
                    },
                    {
                        "first": "W",
                        "middle": [],
                        "last": "Zaremba",
                        "suffix": ""
                    }
                ],
                "dblp_id": "journals/corr/RanzatoCAZ15",
                "year": 2016,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "M. Ranzato, S. Chopra, M. Auli, and W. Zaremba. Sequence level training with recurrent neural networks. In ICLR, 2016.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "What makes my queries slow?: Subgroup discovery for SQL workload analysis",
                "authors": [
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Remil",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Bendimerad",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Mathonat",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Chaleat",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Kaytoue",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/kbse/RemilBMCK21",
                "year": 2021,
                "venue": "ASE",
                "volume": "",
                "issue": "",
                "pages": "642--652",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Y. Remil, A. Bendimerad, R. Mathonat, P. Chaleat, and M. Kaytoue. What makes my queries slow?: Subgroup discovery for SQL workload analysis. In ASE, pages 642-652, 2021.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "ML-AQP: query-driven approximate query processing based on machine learning",
                "authors": [
                    {
                        "first": "F",
                        "middle": [],
                        "last": "Savva",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Anagnostopoulos",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Trianta",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "F. Savva, C. Anagnostopoulos, and P. Trianta llou. ML-AQP: query-driven approximate query processing based on machine learning. CoRR, abs/2003.06613, 2020.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "Sqlsmith",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Seltenreich",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Seltenreich. Sqlsmith, 2020. https://github.com/anse1/sqlsmith.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "Reinforcement learning for spoken dialogue systems",
                "authors": [
                    {
                        "first": "S",
                        "middle": [
                            "P"
                        ],
                        "last": "Singh",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [
                            "J"
                        ],
                        "last": "Kearns",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [
                            "J"
                        ],
                        "last": "Litman",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [
                            "A"
                        ],
                        "last": "Walker",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/nips/SinghKLW99",
                "year": 1999,
                "venue": "NIPS",
                "volume": "",
                "issue": "",
                "pages": "956--962",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. P. Singh, M. J. Kearns, D. J. Litman, and M. A. Walker. Reinforcement learning for spoken dialogue systems. In NIPS, pages 956-962. The MIT Press, 1999.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Massive stochastic testing of sql",
                "authors": [
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Slutz",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/vldb/Slutz98",
                "year": 1998,
                "venue": "VLDB",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "D. Slutz. Massive stochastic testing of sql. In VLDB, 1998.",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "b48",
                "title": "Dropout: a simple way to prevent neural networks from over tting",
                "authors": [
                    {
                        "first": "N",
                        "middle": [],
                        "last": "Srivastava",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Hinton",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Krizhevsky",
                        "suffix": ""
                    },
                    {
                        "first": "I",
                        "middle": [],
                        "last": "Sutskever",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Salakhutdinov",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2014,
                "venue": "The journal of machine learning research",
                "volume": "15",
                "issue": "1",
                "pages": "1929--1958",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: a simple way to prevent neural networks from over tting. The journal of machine learning research, 15(1):1929-1958, 2014.",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "b49",
                "title": "Learning to learn: Meta-critic networks for sample e cient learning",
                "authors": [
                    {
                        "first": "F",
                        "middle": [],
                        "last": "Sung",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Xiang",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [
                            "M"
                        ],
                        "last": "Hospedales",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "F. Sung, L. Zhang, T. Xiang, T. M. Hospedales, and Y. Yang. Learning to learn: Meta-critic networks for sample e cient learning. CoRR, abs/1706.09529, 2017.",
                "links": null
            },
            "BIBREF50": {
                "ref_id": "b50",
                "title": "Reinforcement learning: An introduction",
                "authors": [
                    {
                        "first": "R",
                        "middle": [
                            "S"
                        ],
                        "last": "Sutton",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [
                            "G"
                        ],
                        "last": "Barto",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2018,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction. MIT press, 2018.",
                "links": null
            },
            "BIBREF51": {
                "ref_id": "b51",
                "title": "Deep reinforcement learning-based approach to tackle topic-aware in uence maximization",
                "authors": [
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Tian",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Mo",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Z",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2020,
                "venue": "Data Science and Engineering",
                "volume": "5",
                "issue": "1",
                "pages": "1--11",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "S. Tian, S. Mo, L. Wang, and Z. Peng. Deep reinforcement learning-based approach to tackle topic-aware in uence maximization. Data Science and Engineering, 5(1):1-11, 2020.",
                "links": null
            },
            "BIBREF52": {
                "ref_id": "b52",
                "title": "FACE: A normalizing ow based cardinality estimator",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2021,
                "venue": "Proc. VLDB Endow",
                "volume": "15",
                "issue": "1",
                "pages": "72--84",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Wang, C. Chai, J. Liu, and G. Li. FACE: A normalizing ow based cardinality estimator. Proc. VLDB Endow., 15(1):72-84, 2021.",
                "links": null
            },
            "BIBREF53": {
                "ref_id": "b53",
                "title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning",
                "authors": [
                    {
                        "first": "R",
                        "middle": [
                            "J"
                        ],
                        "last": "Williams",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 1992,
                "venue": "Machine Learning",
                "volume": "8",
                "issue": "3-4",
                "pages": "229--256",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "R. J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, 8(3-4):229-256, 1992.",
                "links": null
            },
            "BIBREF54": {
                "ref_id": "b54",
                "title": "Function optimization using connectionist reinforcement learning algorithms",
                "authors": [
                    {
                        "first": "R",
                        "middle": [
                            "J"
                        ],
                        "last": "Williams",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 1991,
                "venue": "Connection Science",
                "volume": "3",
                "issue": "3",
                "pages": "241--268",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "R. J. Williams and J. Peng. Function optimization using connectionist reinforce- ment learning algorithms. Connection Science, 3(3):241-268, 1991.",
                "links": null
            },
            "BIBREF55": {
                "ref_id": "b55",
                "title": "A study of reinforcement learning for neural machine translation",
                "authors": [
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "F",
                        "middle": [],
                        "last": "Tian",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Lai",
                        "suffix": ""
                    },
                    {
                        "first": "T",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/emnlp/WuTQLL18",
                "year": 2018,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "3612--3621",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "L. Wu, F. Tian, T. Qin, J. Lai, and T. Liu. A study of reinforcement learning for neural machine translation. In EMNLP, pages 3612-3621. Association for Computational Linguistics, 2018.",
                "links": null
            },
            "BIBREF56": {
                "ref_id": "b56",
                "title": "Predicting query execution time: Are optimizer cost models really unusable?",
                "authors": [
                    {
                        "first": "W",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Chi",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Tatemura",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Hacig\u00fcm\u00fcs",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "F"
                        ],
                        "last": "Naughton",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/icde/WuCZTHN13",
                "year": 2013,
                "venue": "ICDE",
                "volume": "",
                "issue": "",
                "pages": "1081--1092",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "W. Wu, Y. Chi, S. Zhu, J. Tatemura, H. Hacig\u00fcm\u00fcs, and J. F. Naughton. Predicting query execution time: Are optimizer cost models really unusable? In ICDE, pages 1081-1092, 2013.",
                "links": null
            },
            "BIBREF57": {
                "ref_id": "b57",
                "title": "Reinforcement learning with tree-lstm for join order selection",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "N",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/icde/Yu0C020",
                "year": 2020,
                "venue": "ICDE",
                "volume": "",
                "issue": "",
                "pages": "1297--1308",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X. Yu, G. Li, C. Chai, and N. Tang. Reinforcement learning with tree-lstm for join order selection. In ICDE, pages 1297-1308. IEEE, 2020.",
                "links": null
            },
            "BIBREF58": {
                "ref_id": "b58",
                "title": "Automatic view generation with deep learning and reinforcement learning",
                "authors": [
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/icde/Yuan0FSH20",
                "year": 2020,
                "venue": "ICDE",
                "volume": "",
                "issue": "",
                "pages": "1501--1512",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "H. Yuan, G. Li, L. Feng, and et al. Automatic view generation with deep learning and reinforcement learning. In ICDE, pages 1501-1512, 2020.",
                "links": null
            },
            "BIBREF59": {
                "ref_id": "b59",
                "title": "An end-to-end automatic cloud database tuning system using deep reinforcement learning",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "K",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/sigmod/ZhangLZLXCXWCLR19",
                "year": 2019,
                "venue": "SIGMOD",
                "volume": "",
                "issue": "",
                "pages": "415--432",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J. Zhang, Y. Liu, K. Zhou, and G. Li. An end-to-end automatic cloud database tuning system using deep reinforcement learning. In SIGMOD, pages 415-432, 2019.",
                "links": null
            },
            "BIBREF60": {
                "ref_id": "b60",
                "title": "SQUIRREL: testing database management systems with language validity and coverage feedback",
                "authors": [
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Zhong",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "W",
                        "middle": [],
                        "last": "Lee",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/ccs/ZhongC0ZLW20",
                "year": 2020,
                "venue": "CCS",
                "volume": "",
                "issue": "",
                "pages": "955--970",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "R. Zhong, Y. Chen, H. Hu, H. Zhang, W. Lee, and D. Wu. SQUIRREL: testing database management systems with language validity and coverage feedback. In CCS, pages 955-970, 2020.",
                "links": null
            },
            "BIBREF61": {
                "ref_id": "b61",
                "title": "Database meets arti cial intelligence: A survey",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2020,
                "venue": "TKDE",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X. Zhou, C. Chai, G. Li, and J. Sun. Database meets arti cial intelligence: A survey. TKDE, 2020.",
                "links": null
            },
            "BIBREF62": {
                "ref_id": "b62",
                "title": "Dbmind: A self-driving platform in opengauss",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Jin",
                        "suffix": ""
                    },
                    {
                        "first": "S",
                        "middle": [],
                        "last": "Ji",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2021,
                "venue": "Proc. VLDB Endow",
                "volume": "14",
                "issue": "12",
                "pages": "2743--2746",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X. Zhou, L. Jin, S. Ji, and et al. Dbmind: A self-driving platform in opengauss. Proc. VLDB Endow., 14(12):2743-2746, 2021.",
                "links": null
            },
            "BIBREF63": {
                "ref_id": "b63",
                "title": "A learned query rewrite system using monte carlo tree search",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "C",
                        "middle": [],
                        "last": "Chai",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2022,
                "venue": "PVLDB",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X. Zhou, G. Li, C. Chai, and J. Feng. A learned query rewrite system using monte carlo tree search. PVLDB, 2022.",
                "links": null
            },
            "BIBREF64": {
                "ref_id": "b64",
                "title": "Autoindex: An incremental index management system for dynamic workloads",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "W",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "dblp_id": "conf/icde/ZhouLLJLWF22",
                "year": 2022,
                "venue": "ICDE",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X. Zhou, L. Liu, W. Li, and et al. Autoindex: An incremental index management system for dynamic workloads. In ICDE, 2022.",
                "links": null
            },
            "BIBREF65": {
                "ref_id": "b65",
                "title": "Query performance prediction for concurrent queries using graph embedding",
                "authors": [
                    {
                        "first": "X",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    }
                ],
                "dblp_id": null,
                "year": 2020,
                "venue": "Proc. VLDB Endow",
                "volume": "13",
                "issue": "9",
                "pages": "1416--1428",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "X. Zhou, J. Sun, G. Li, and J. Feng. Query performance prediction for concurrent queries using graph embedding. Proc. VLDB Endow., 13(9):1416-1428, 2020.",
                "links": null
            }
        }
    }
}