{"title": ["Unsupervised Representation Learning of Player Behavioral Data with Confidence Guided Masking", "Clustering of ualitative Time Series for 3D Printing Quality Management", "A Chatbot-Server Framework for Scalable Machine Learning Education through Crowdsourced Data", "Application of edge computing in intelligent security system", "Teaching Data Management Concepts for Data in Files", "A Novel Efficient Coupling Algorithm for Adaptive Fiber Coupling", "Megha: Decentralized Federated Scheduling for Data Center Workloads", "Cybersecurity Education in the Age of AI: Integrating AI Learning into Cybersecurity High School Curricula", "Fast Blocking of Malicious Traffic by Excluding Benign Flow Monitoring in IDS/SDN Cooperative Firewall Systems", "Using Augmented Reality (AR) to Educate the Student: Bridging the Communication for Internet Addiction", "Learning Web Programming: Identifying Complex Topics from Student Discussion Forums and Lecture Slides", "Development of a Voice Virtual Assistant for the Geospatial Data Visualization Application on the Web", "Blockchain Based Cloud Computing: Architecture and Research Challenges", "A Study on the Optimization of the CNNs for Adversarial Attacks", "Development of high-speed fiber-optic communication lines for transferring large amounts of information", "Clutter Environment Perception Based on Prototypical Network", "Research on Network Architecture Design Based on Artificial Intelligence Application Technology", "A Network Security Test Evaluation Model of Automobile Digital Key", "NHAM: An NFV High Availability Architecture for Building Fault-Tolerant Stateful Virtual Functions and Services", "Design of Bare Metal Network Architecture Based on Smart NIC", "Hybrid Adaptation of Named Entity Recognition for Statistical Machine Translation", "Application of artificial intelligence in the construction of computer big data security technology platform", "The CubeSat Radiometer Radio Frequency Interference Technology (CubeRRT) Validation Mission: Performance and Development of the Digital Backend Technology", "A Study of Grammar-concept Understanding Problems for Web-client Programming", "Satellite Spoofing from A to Z: On the Requirements of Satellite Downlink Overshadowing Attacks", "Low-code from frontend to backend: Connecting conversational user interfaces to backend services via a low-code IoT platform", "Visual Analytics in Software Maintenance: A Systematic Literature Review", "NV-SQL: Boosting OLTP Performance with Non-Volatile DIMMs", "Combination of Models for Denial-Of-Service Classification over Different Networks", "Scheduling Internet of Things requests to minimize latency in hybrid Fog-Cloud computing", "Database Querying Optimization via Genetic Algorithm for Biomedical Research", "Experience: Large-scale Cellular Localization for Pickup Position Recommendation at Black-hole", "Analyzing Maintenance Activities of Software Libraries", "An Empirical Study of Web Services Topics in Web Developer Discussions on Stack Overflow", "Evaluating the Impact of No-Code/Low-Code Backend Services on API Development and Implementation: A Case Study Approach", "Dynamic Intrusion Detection Framework for UAVCAN Protocol Using AI", "Backend Development of Online Marketplace for Male Beauty Care Services", "Performance Analysis of Mimic Defense based SDN Security Policy", "Explainable Intrusion Detection System in IoT Scenarios: A Cross-Device Model Training and Evaluation for Traffic Classification", "Locality Matters! Traffic Demand Modeling in Datacenter Networks", "Network Architecture and Use Cases for FTTR in Business Scenarios", "SQL: A Trojan Horse Hiding a Decathlon of Complexities", "A Discussion on Computer Security Technology and Security Preventive Measures", "Training Bachelor Students to Design Better Quality Web Apps: Preliminary Results from a Prospective Empirical Investigation", "Long-Term Analysis of the Dependability of Cloud-based NISQ Quantum Computers", "A Game of Dark Paterns: Designing Healthy, Highly-Engaging Mobile Games", "IoT Malware Data Augmentation using a Generative Adversarial Network", "Survey of Software Maintenance Metrics: A Systematic Literature Review", "Research on fast extraction algorithm of big data information based on machine learning", "A Compact Design of Ultra-Wideband Microstrip-Slot Six-Port Network for Wireless Communication Applications", "SQL Injection Detection in Cloud Computing with Machine Learning Algorithms", "Pushing the Limits of Video Game Performance: A Performance Engineering Perspective", "Component generator for the development of RESTful APIs", "Near Optimal Learning-Driven Mechanisms for Stable NFV Markets in Multitier Cloud Networks", "Resumability-A New Primitive for Developing Web Applications", "A Mock Server for ECHONET Lite Web API Application Development and Testing", "FEDERATED ADVERSARIAL DOMAIN ADAPTATION", "All-in-One Print: Designing and 3D Printing Dynamic Objects Using Kinematic Mechanism Without Assembly", "Artificial Intelligence, Robotics and Fundamental Rights *", "Understanding Inconsistency in Azure Cosmos DB with TLA+", "A Practical Intrusion Detection System Trained on Ambiguously Labeled Data for Enhancing IIoT Security", "Front-end deep learning web apps development and deployment: a review", "Towards Greener Data Centers via Programmable Data Plane", "MACTA: A MULTI-AGENT REINFORCEMENT LEARNING APPROACH FOR CACHE TIMING ATTACKS AND DETECTION", "ScienceBenchmark: A Complex Real-World Benchmark for Evaluating Natural Language to SQL Systems", "Developing Incident Response-Focused Cybersecurity Undergraduate Curricula *", "Cloud Computing Resources Impacts on Heavy-Load Parallel Processing Approaches", "Design of a hybrid fiber optic coaxial transmission medium", "Information Intelligence System Solution Based on Big Data Flink Technology", "Intrusion Detection and Tolerance for Microservice Applications", "Design of Geospatial Big Data Cloud Platform for Land Resources", "A Consensus Approach for SDN Controllers based on Blockchain", "Research on Multi-network Data Paths for 5G Mobile Multimedia", "Evaluation of Current Java Technologies for Telecom Backend Platform Design", "Demonstrating OmniCells: A Resilient Indoor Localization System to Devices' Diversity", "Experience Track", "Evaluating Performance of Intrusion Detection Systems under Different Configurations in SDN", "The Application and Practice of Computer Network Security Technology in Electronic Information Engineering", "Smile Recognition Based on Comprehensive Dataset Construction and Bayesian Neural Architecture Search", "", "A Novel Resource Sharing Scheme for Full Duplex D2D Communication Underlaying Cellular Network", "Cerberus", "Design and Implementation of a Game Session Plugin based on Unreal Engine", "Pre-Overload Migration Scheme for NFV-based Fog Computing", "Assessing Peer Correction of SQL and NoSQL Queries", "Research on Urban Smart Tourism System based on Computer Big Data Platform", "Driving Digital Services with Big Data Analytics", "Designing a Sustainable Material for 3D Printing with Spent Cofee Grounds", "FileScale", "Application of Multiple Design Patterns in Virtual Reality Game Development", "BULB: Lightweight and Automated Load Balancing for Fast Datacenter Networks", "A Microservice-based SaaS Deployment in a Data Center Considering Computational Server and Network Energy Consumption", "Web Development and performance comparison of Web Development Technologies in Node.js and Python", "Harmonizing Privacy Regarding Data Retention and Purging", "Speech Emotion Recognition Based on Multi-feature Fusion and DCNN", "Unified Holistic Memory Management Supporting Multiple Big Data Processing Frameworks over Hybrid Memories", "dNextG: A Zero-Trust Decentralized Mobile Network User Plane", "Scaling a Declarative Cluster Manager Architecture with Query Optimization Techniques", "Research on lightweight core network solutions for 5G private networks", "National Cybersecurity Crisis Management: International Experience, Analytical Framework and Path Selection", "Mining SQL Problem Solving Patterns using Advanced Sequence Processing Algorithms", "Research on Security Technologies for Open Reconfigurable Routing and Switching Platforms", "Detecting DDoS Attacks in Software Defined Networks (SDNs) with Random Forests", "A Survey on the Current Trends and Applications of Design Optimization for Compliant and Soft Robotics", "Technical Perspective: Conjunctive Queries with Comparisons", "Deep Learning Approaches for Cyber Threat Detection and Mitigation This manuscript discusses the application of deep learning approaches in the cybersecurity field", "", "Design and Implementation of an IoT-Based Surveillance System using Raspberry Pi, Camera, and Motion Sensor", "Carbon Dependencies in Datacenter Design and Management", "System of Research Suppliers on Big Data Technology", "Research and application on retrieval of typhoon from fully polarized microwave radiometer", "Fiber Recognition Algorithm Based on Improved Mask RCNN", "Research on the Application of Big Data Technology in Enterprise Financial Decision Making", "Influence of 3D Printing Filling Density on Vibration Characteristics of Robot Structure", "Adapting Datacenter Capacity for Greener Datacenters and Grid", "The Study on Emergence and Optimization of SDN Cooperation Subnet", "Sof Robotics and Programmable Materials for Human-Computer Interaction", "TwinArk: A Unified Framework for Digital Twins based on Micro-frontends, Micro-Services, and Web 3D", "Education Cybersecurity: Learning Management System, Data and Tools", "CORESET OF HYPERSPECTRAL IMAGES ON A SMALL QUANTUM COMPUTER", "LearnedSQLGen: Constraint-aware SQL Generation using Reinforcement Learning", "Development of Big Data-Analysis Pipeline for Mobile Phone Data with Mobipack and Spatial Enhancement", "Knowledge Graphs Querying", "Anomaly and Novelty detection for Satellite and Drone systems (ANSD '23)", "Controlling Air Pollution in Data Centers using Green Data Centers", "Designing a No SQL -Non Traditional Databases Course * Conference Tutorial", "A Survey on Edge and Edge-Cloud Computing Assisted Cyber-Physical Systems", "QLSFC: An Intelligent Security Function Chain with Q-Learning in SDN/NFV Network", "Data mining techniques for feature selection in blood cell recognition", "Satellite-based DBF ADS-B Payload with Amplitude-phase Mismatch Calibration", "A Study of Worked Examples for SQL Programming", "SDN Defense: Detection and mitigation of DDoS attack via IoT Network", "A lightweight API recommendation method for App development based on multi-objective evolutionary algorithm", "Energy-Saving Strategies for Mobile Web Apps and their Measurement: Results from a Decade of Research", "Research on Network Dynamic Security Policy Model Based on Neural Network", "GreenNFV: Energy-Efficient Network Function Virtualization with Service Level Agreement Constraints", "Front-end deep learning web apps development and deployment: a review", "Fiber Optic Sensing Signal Monitoring System Based on FPGA", "Enhancing Intrusion Detection and Explanations for Imbalanced Vehicle CAN Network Data", "A Review on Big Data Utilization in Metaverse World", "Fog-Assisted Dynamic IoT Device Access Management Using Attribute-Based Encryption", "Overview of Network Security Defense Technologies for Power Systems", "Structure and Key Technologies of Nuclear Power Plant Network Security Situational Awareness Platform", "Demo: Scalable Digital Twin System for Mobile Networks with Generative AI", "Cyber Security in Internet of Things using Optimization algorithms: A Systematic Mapping of Literature", "JoinBoost: Grow Trees Over Normalized Data Using Only SQL", "CGD: A Cloud Gaming Dataset with Gameplay Video and Network Recordings", "", "Games and the Metaverse", "Towards the Design of a Gamified Application to Increase Tuberculosis Treatment Adherence in Vietnam", "Adversarial Machine Learning Attacks on Multiclass Classification of IoT Network Traffic", "Quantum Computer Architecture for Quantum Error Correction with Distributing Process to Multiple Temperature Layers", "Characterizing Mobile Service Demands at Indoor Cellular Networks", "Maximizing Bigdata Retrieval: Block as a Value for NoSQL over SQL", "Tensor Network Quantum Virtual Machine for Simulating Quantum Circuits at Exascale", "Automated Tool for NoSQL to SQL Migration", "Scalable, High-Quality Scheduling of Data Center Workloads", "A Novel Image Encryption Algorithm Based on Cellular Automata and Chaotic System", "Backend Database Systems", "Research on Network Architecture Based on Improved MPLS Protocol and SDN Technology", "ESBMC-solidity", "Security Framework for Non-public 5G Network Deployments", "Multicast Routing and Virtual Network Function Placement in NFV-SDN Networks: A Genetic Algorithms Approach", "Cost-optimized Task Scheduling with Improved Deep Q-Learning in Green Data Centers", "Cross-Level Network Security Element Fusion Extraction Method Based on Deep Learning", "", "Development of NodeJS based Backend System with Multiple Storefronts for Batik Online Store", "Cybersecurity of Industrial Cyber-Physical Systems: A Review", "Analyzing the Communication Clusters in Datacenters *"], "abstract": ["Players of online games generate rich behavioral data during gaming. Based on these data, game developers can build a range of data science applications, such as bot detection and social recommendation, to improve the gaming experience. However, the development of such applications requires data cleansing, training sample labeling, feature engineering, and model development, which makes the use of such applications in small and medium-sized game studios still uncommon. While acquiring supervised learning data is costly, unlabeled behavioral logs are often continuously and automatically generated in games. Thus we resort to unsupervised representation learning of player behavioral data to optimize intelligent services in games. Behavioral data has many unique properties, including semantic complexity, excessive length, etc. A worth noting property within raw player behavioral data is that a lot of it is task-irrelevant. For these data characteristics, we introduce a BPE-enhanced compression method and propose a novel adaptive masking strategy called Masking by Token Confidence (MTC) for the Masked Language Modeling (MLM) pre-training task. MTC is designed to increase the masking probabilities of task-relevant tokens. Experiments on four downstream tasks and successful deployment in a world-renowned Massively Multiplayer Online Role-Playing Game (MMORPG) prove the effectiveness of the MTC strategy 1 .", "In this research, we are attempting to extract relevant knowledge from sensor data of 3D printers. This is in continuation of our previous work to characterize the operational status of 3D printers using Bootstrap-CURE technique, including the post-processing techniques oriented to understand and conceptualize the clusters. Four clusters were identified regarding normal successful printing and abnormal situations due to different reasons like insufficient operating conditions, sensor failure, imbalance in internal temperature, etc. In the current work, the representation of data moves from punctual sensor readings to a vectorial description of a printing job in terms of the sequence of operational status over time. By representing a job by its sequence of clusters, it can be analyzed which sequential patterns are associated with successful or failing jobs. This opens the door to identifying trends and anticipating failures that are crucial to improving 3D printers' control and management. To cluster qualitative time series, specific qualitative distances are required, like \u03c7 2 -distance. One of the main challenges in clustering a time series dataset is to similarities among various time series rows. However, when the irregular length of the series and highly skewed series appear, special representation methods are required to avoid biases in results and the curse of dimensionality effects. The paper proposes to overcome these limitations.", "In this paper, we propose a novel chatbot-server computer programming framework for students to learn Artificial Intelligence (AI) by creating game AI chatbot applications, whilst conforming to a distributed frontend-backend application structure (e.g., clientserver model). The chatbot interface allows students to share their work over online social networks and invite other human players to test-drive the game AI and to collect data for training of machine learning models by crowdsourcing. We introduce a few test cases based on this framework to facilitate the online learning of AI and full-stack software engineering knowledge, thus enabling a progressive learning of machine learning education using crowdsourcing.", "The rise and development of edge computing technology have solved the problem of massive data in the era of big data, and provided a new direction for the development of intelligent security systems. Edge computing analyzes, calculates and stores the data at the edge near the data source, which reduces network transmission burden and the computing pressure of the cloud center and improves the efficiency of the whole system. In order to solve the problem of massive data in intelligent security system, a feasible architecture of intelligent security system based on edge computing is proposed, which is divided into four parts: perception layer, edge layer, transport layer and application layer. The intelligent security system based on edge computing can take full advantages of edge computing in terms of computing ability, real-time and security, and better meet the needs of real-time monitoring, risk assessment, early warning and intelligent decision-making services, so as to promote the comprehensive improvement of security level.", "A database management system offers mechanisms that support data management, such as access control, integrity preservation, schema documentation, durability, etc. When datasets are stored in files, as is common in many data science projects, these functionalities need to be done directly by the data owner. This paper proposes ways to teach data management principles for such filebased settings, and we report on some of the challenges students have faced.\u2022 Social and professional", "The high-speed free space optical communication systems based on the fiber techniques play more and more important roles nowadays, the laser beam propagating in the free space should be coupled into the single-mode fiber (SMF) at the input of the receiver. However, propagation through the atmospheric turbulence degrades the laser beam's spatial coherence and the jitters of the launch platform also decrease the convergent efficiency. Based on the existing adaptive coupling system, this paper studies the coupling algorithm based on the gradient descent (GD). We propose a novel algorithm that estimating the gradient through the simultaneous perturbation stochastic approximation (SPSA) and combining it with some traditional deep learning algorithms. Besides, we compare the coupling efficiency and speed of these algorithms. The simulation results demonstrate that the new algorithm combining the SPSA and the iteration point update strategy of Adagrad (SP-Adagrad) algorithm has a great advantage in coupling performance and is robust compared with other traditional algorithms, which improves the performance of the adaptive fiber coupling system in coupling speed and stability.", "Increasing scale and heterogeneity in data centers have led to the development of federated clusters such as KubeFed, Hydra, and Pigeon, that federate individual data center clusters. In our work, we introduce Megha, a novel decentralized resource management framework for such federated clusters. Megha employs flexible logical partitioning of clusters to distribute its scheduling load, ensuring that the requirements of the workload are satisfied with very low scheduling overheads. It uses a distributed global scheduler that does not rely on a centralized data store but, instead, works with eventual consistency, unlike other schedulers that use a tiered architecture or rely on centralized databases. Our experiments with Megha show that it can schedule tasks taking into resource requirements and placement constraints with low resource allocation times -in the order of tens of milliseconds.", "Artificial Intelligence (AI) and cybersecurity are becoming increasingly intertwined, with AI and Machine Learning (AI/ML) being leveraged for cybersecurity, and cybersecurity helping address issues caused by AI. The goal in our exploratory curricular initiative is to dovetail the need to teach these two critical, emerging topics in highschool, and create a suite of novel activities, 'AI & Cybersecurity for Teens' (ACT) that introduces AI/ML in the context of cybersecurity and prepares high school teachers to integrate them in their cybersecurity curricula. Additionally, ACT activities are designed such that teachers (and students) build a deeper understanding of how ML works and how the machine actually \"learns\". Such understanding will aid more meaningful interrogation of critical issues such as AI ethics and bias. ACT introduces core ML topics contextualized in cybersecurity topics through a range of programming activities and pre-programmed games in NetsBlox, an easy-to-use block-based programming environment. We conducted 2 pilot workshops with 12 high school cybersecurity teachers focused on ACT activities. Teachers' feedback was positive and encouraging but also highlighted potential challenges in implementing ACT in the classroom. This paper reports on our approach and activities design, and teachers' experiences and feedback on integrating AI into high school cybersecurity curricula.", "Intrusion Detection System (IDS) / Software Defined Networking (SDN) cooperative firewall systems attract much attention recently because they have many advantages such as dynamic network configuration with SDN and scalable IDS hosts. In IDS/SDN cooperative firewall systems, an SDN switch relays traffic between external and internal networks and mirrors the traffic to an IDS host. The IDS host monitors mirrored traffic and tells the SDN controller to block malicious traffic according to attack detection. Therefore, when the IDS hosts are overloaded, it causes a large delay between attack detection by the IDS host and malicious traffic blocking in the SDN switch, which increases the amount of malicious traffic reaching the server. In this paper, we propose a configuration to reduce the loads on the IDS hosts by excluding benign flows from packet monitoring. By using the proposed configuration, IDS hosts reduce the long delay in blocking because the proposed configuration mitigates the performance degradation in IDS hosts due to monitoring of all traffic, including known benign flows. We implemented the proposed configuration on our IDS/SDN cooperative firewall systems using real devices. Then we evaluated the effectiveness of delay reduction with and without excluding benign flows when varying the number of IDS hosts and the notification method used for blocking malicious traffic, namely using Syslog messages and using REST API. As a result, we confirm that the proposed configuration reduces the delay time in all cases investigated. Furthermore, we confirmed that Syslog notifications are faster than REST API notifications in all cases.", "Internet gaming addiction is now recognized as a mental health condition that can have a significant impact on an individual's wellbeing. Over the last decade, studies have accumulated showing that overuse of the Internet can lead to the development of behavioral addiction. Meanwhile, technological advances have introduced virtual and augmented environment, which allows developer to reduce the time and cost of product development iterations while improving the quality of final products, of course bringing user with richness and immersiveness with large scale environment. It opens up new media and approaches to the gaming experience and online browsing activities. The implications means that immersive technology promises higher design fidelity, resulting in higher quality final products at a lower cost than traditional prototyping technology can offer. Thus, this study want to explore in the qualitative approach on how the design in term of augmented reality product influence the student's behavior in the educational purposes.", "Designing and delivering web application courses for computing undergraduates is a challenging task. Lack of understanding of web concepts affects the students' interest in web application development. Therefore, faculty employ several traditional strategies including hands on exercises and labs as well as innovative strategies such as videos and discussion forums. However, due to the volume of the posts in the forums, the instructors find it challenging to attend to the students' challenges and focus on more challenging topics across the classroom. In this paper, we propose a text mining based solution to extract the questions and complex topics. We evaluated the solution on the year 2 Web Application course offered to the computing undergraduates. Our experiments show that logistic regression model performs better in classifying question posts and cosine similarity performs better in assigning the topic label to the posts. The findings are visually depicted and are useful to the faculty to identify the topics that requires more attention to improve students' learning.", "Voice assistants can elevate interaction in geospatial data web platforms. This research introduces a voice assistant in the BStreams platform and focuses on understanding user commands in the geospatial domain. We developed a specialised geospatial discourse framework through structured prototyping. A survey with 66 participants revealed prevalent English geospatial terminologies. Using ChatGPT, we found the term suggestions aligned with survey results, with a notable correlation (r = 0.81, p < 0.01) between the NPL model's probability scores and term prevalence in survey data. Our study also incorporated usability tests on the application, which uses tools like Web Speech API, Leaflet, and Mapbox geocoding. Results from these tests reaffirm the potential of voice assistants in enhancing geospatial data visualisation, though challenges persist in areas like language understanding and domain knowledge. The paper advocates for further research to refine the integration of voice technology in this domain.", "Blockchain technology is a distributed ledger with records of data containing all details of the transactions carried out and distributed among the nodes present in the network. All the transactions carried out in the system are confirmed by consensus mechanisms, and the data once stored cannot be altered. Blockchain technology is the necessary technology behind Bitcoin, which is a popular digital Cryptocurrency. ''Cloud computing is a practice of using a network of remote servers hosted on the internet to store, manage, and process data, rather than a local server or a personal computer.'' It is still facing many challenges like data security, data management, compliance, reliability. In this article, we have mentioned some of the significant challenges faced by the cloud and proposed solutions by integrating it with blockchain technology. We tend to investigate a brief survey on earlier studies focused on blockchain integrating with the cloud to depict their supremacy. In this survey, we have also developed architecture integrating blockchain with cloud revealing the communication between blockchain and cloud.", "Convolutional Neural Networks (CNNs) have shown high accuracy in image classification tasks, including on popular datasets like MNIST and ImageNet. However, these models can be easily fooled by small perturbations added to the input image. To address this issue, the VOneBlock architecture was proposed, which can be added to the frontend of a CNN-based model to improve its robustness to adversarial attacks. In this paper, we compare the performance of CNN models with and without VOneBlock when fine-tuning on adversarial datasets, and show how the inclusion of VOneBlock affects the model's robustness. Additionally, we investigate how the number of Gabor filter kernels used in VOneBlock affects its performance. Through our experiments, we present an optimal way to enhance the robustness of CNN models to adversarial attacks using VOneBlock. Finally, we evaluate whether the classification model with VOneBlock performs well in classifying real-world attacked images, as well as adversarial attacked images. While VOneBlock was developed to improve robustness to small perturbations, we find that the neural network with VOneBlock performs slightly better in classifying real-world attacked images.", "In this article, the mode composition of the microstructured optical fiber was calculated. The values of the effective (waveguide) refractive index of the first six spatial modes, the propagation of which are supported by an optical fiber, are calculated. The structures of microstructured fiber have been manufactured and presented. An experimental study of the distribution of optical radiation at the exit from the manufactured microstructured fiber has been carried out. The results of the research are presented.", "Clutter environment perception is the basic function of the cognitive radar system, which provides prior information for the subsequent transmitted waveform optimization and adaptive processing of the received signal. In a typical airborne or missile-borne platform, in order to respond quickly to the environment of the highvalue target to be detected, the radar only has a short observation window length and cannot obtain enough data for clutter environment perception, leading to a problem of clutter environment perception under the condition of few data. Aiming at the problem of insufficient clutter environment data, this paper proposed a clutter environment perception method based on prototypical network. It employed the High-Resolution Range Profile of wideband radar as the recognition data, and first used data in the training set to calculate the prototypes corresponding to different clutter environment features. Then, the distances between the features of data in the testing set and the different prototypes was used to realize the perception of the clutter environment. The measured data on microwave anechoic chamber showed that the methods used in this paper can obtain effective perception results for the three typical natural environments of grassland, cement, and asphalt.", "With the continuous development of AI technology, the training of massive data and the emergence of large-scale models have made stand-alone model training increasingly unable to meet the needs of AI applications. Distributed machine learning technologies (such as data parallelism and model parallelism) have appeared at historic moments and will have extreme large-scale application scenarios. At present, the training speed of distributed machine learning models is slow, and the scale of model parameters is still the main problem in this field. From the perspective of model parallelism, this article aims to design the optimal division method for different models under model parallelism by analyzing the structure of the existing AI application model. According to the framework structure of artificial intelligence application model, design the model optimization partition strategy and model based on parallelism. A network architecture suitable for accelerating AI application training, focusing on solving technical problems, such as network architecture design based on AI applications and model optimization and partitioning under model parallelization.", "As a product of the development of automobile networking, automotive digital keys not only bring convenience to users, but also bring some network security risks. At present, it is still in the initial stage of mass application of digital keys in automobiles, and the focus of each digital key product is still in the stage of functional realization, and there is a general lack of threat protection and risk assessment in network security. This paper mainly combines the existing network security standards to refine the network security threat scenarios of digital keys, and proposes test methods and evaluation models. According to the network security threats found by a large number of tests on the existing digital key scheme, a targeted test scheme is proposed to evaluate the network security of the digital key system in all aspects, so as to solve the problem of the lack of digital key test evaluation method. This paper proposes a network security test and evaluation model for automotive digital keys, which can support automobile manufacturers to complete the digital key system part of the threat analysis and risk assessment, and carry out functional design, test verification and other work.", "Despite the many advantages of Network Function Virtualization (NFV) technology, the dependability of virtual services must be carefully addressed so that NFV can meet the requirements of commercial carriers. In particular, it is essential to provide mechanisms to ensure their correct and continuous operation. In this work we propose NHAM: an NFV High Availability Module designed within the NFV-MANO (NFV Management and Orchestration) reference model. NHAM allows the creation and management of faulttolerant virtual network services consisting of stateful VNFs (Virtualized Network Functions) and SFCs (Service Function Chains). The proposed architecture provides fault management, including a choice of recovery mechanisms that can be applied depending on the specific needs of each service. The solution is holistic in the sense that it does not require any modifications of the source code of VNFs/SFCs to make them fault-tolerant. The strategy is based on SFC buffer management coupled with VNF checkpoint/restore, providing high availability in a transparent way. A prototype was implemented and experimental results are presented.", "Currently, traditional virtualized servers in the cloud computing space suffer from excessive network stack overhead and insufficient CPU resources available for virtual machines. The article proposes a bare metal network architecture design based on smart NICs, by which carrying traffic loads and implements virtual NIC transmissions through Virtio technology to provide a data communication path from bare metal servers to smart NICs. Furthermore, OVS and DPDK technologies are used inside the smart NIC to offload the control forwarding process of network messages, which makes the smart NIC handle traffic data directly and greatly shorten the forwarding path of messages. Through experimental verification, this bare-metal network architecture can significantly reduce the utilization of network services on the server CPU and provide resiliency for the bare-metal server, further enhancing the overall performance of the system.", "Appropriate Named Entity handling is important for Statistical Machine Translation. In this work we address the challenging issues of generalization and sparsity of NEs in the context of SMT. Our approach uses the source NE Recognition (NER) system to generalize the training data by replacing the recognized Named Entities with place-holders, thus allowing a Phrase-Based Statistical Machine Translation (PBMT) system to learn more general patterns. At translation time, the recognized Named Entities are handled through a specifically adapted translation model, which improves the quality of their translation. We add a post-processing step to a standard NER system in order to make it more suitable for integration with SMT and we also learn a prediction model for deciding between options for translating the Named Entities, based on their context and on their impact on the translation of the entire sentence. We show important improvements in terms of BLEU and TER scores already after integration of NER into SMT, but especially after applying the SMT-adapted post-processing step to the NER component.", "To understand the application of big data security technology platform construction, a research on the application of artificial intelligence in the construction of computer big data security technology platform has been proposed. This article first analyzes the overview of big data and artificial intelligence, the advantages of artificial intelligence in computer networks, the specific application of artificial intelligence in computer network technology, and the future development direction of artificial intelligence. Secondly, in order to further demonstrate the actual effectiveness of AI based computer big data security technology platforms, a comparative analysis is conducted on the differences between AI based computer big data security technology platforms and traditional computer big data security technology platforms. The experimental results show that compared with traditional computer big data security technology platforms, AI based computer big data security technology platforms have significant advantages in security level, which can better protect user information and maximize user information security.", "In this paper we discuss the design and development of the Radiometer Digital Backend (RDB) of the CubeSat Radiometer Radio Frequency Interference Technology (CubeRRT) validation mission. We present a brief introduction of the mission and the Radio Frequency Interference (RFI) detection and mitigation algorithm. The digital backend developed for the CubeSat is presented. The digital backend has unique capabilities of taking in wide bandwidths of up to 1GHz and can perform on-board complex operations to detect and filter out RFI in realtime. We present a few initial results of the backend spectrometer leading to full-system integration and test.", "Web-client Programming with HTML, CSS, and JavaScript has evolved into an essential aspect of contemporary web application development. If students are equipped with the knowledge and expertise of web-client programming, they will have promising career prospects in the industry. In this paper, we propose the concept of Grammar-concept Understanding Problem (GUP) for web-client programming. GUP tasks students with answering questions related to fundamental grammar concepts in the provided source code. The correctness of the answer is evaluated through string matching against the correct solution.To evaluate the efficacy of GUP, we generated 15 GUP instances and assigned them to 27 master students in Okayama University. Their solution results confirm the validity of the proposal, demonstrating that the generated GUP instances are well-suited for novice students.", "Satellite communications are increasingly crucial for telecommunications, navigation, and Earth observation. However, many widely used satellites do not cryptographically secure the downlink, opening the door for radio spoofing attacks. Recent developments in software-defined radio hardware have enabled attacks on wireless systems including GNSS, which can be effectively spoofed using only cheap hardware available off the shelf. However, these conclusions do not generalize well to other satellite systems such as high data rate backhauls or satellite-to-customer connections, where the spoofing requirements are currently unknown.In this paper, we present a systematic review of spoofing attacks against satellite downlink communications systems. We establish a threat model linking attack feasibility and impact to required budget through real-world experiments and channel simulations. Our results show that nearly all evaluated satellite systems were overshadowable at a distance of 1 km in the worst case, for a budget of ~2000 USD or less.We evaluate how key challenges surrounding modulation schemes, antenna directionality, and legitimate satellite signal strength can be overcome in practice through antenna sidelobe targeting, overshadowing, and automatic gain control takeover. We also show that, surprisingly, protocols designed to be more robust against channel noise are significantly less robust against an overshadowing attacker. We conclude with a discussion of physical-layer countermeasures specifically applicable to satellite systems which can not be cryptographically upgraded.\u2022 Security and privacy \u2192 Spoofing attacks;", "Current chatbot development platforms and frameworks facilitate setting up the language and dialog part of chatbots, while connecting it to backend services and business functions requires substantial manual coding effort and programming skills. This paper proposes an approach to overcome this situation. It proposes an architecture with a chatbot as frontend using an IoT (Internet of Things) platform as a middleware for connections to backend services. Specifically, it elaborates and demonstrates how to combine a chatbot developed on the open source development platform Rasa with the open source platform Node-RED, allowing low-code or nocode development of a transactional conversational user interface from frontend to backend.", "The research on visual analytics for software maintenance has noticeabily advanced in the past few years. For many software projects, software maintenance needs an effective and efficient path from data to decision. Visual analytics (VA) creates such a path that enables the user to extract insights by interacting with the relevant information. This paper focuses on VA in software maintenance and has the following goals: investigate the VA adoption and suggest important implications for practice, and identify current research trends, open problems, and areas for improvement. To achieve these goals we conducted a systematic literature review with three research questions and assessed 51 studies published in the past two decades. The results indicate that there is a lack of collaboration between academic researchers and industry practitioners. This impedes the credibility of the proposed tools and methods due to lack of confidence in industry adoption. Furthermore, in this study we identified the need to expand VA support to other programming languages and software maintenance tasks.", "When running OLTP workloads, relational DBMSs with flash SSDs still suffer from the durability overhead. Heavy writes to SSD not only limit the performance but also shorten the storage lifespan. To mitigate the durability overhead, this paper proposes a new database architecture, NV-SQL. NV-SQL aims at absorbing a large fraction of writes written from DRAM to SSD by introducing NVDIMM into the memory hierarchy as a durable write cache. On the new architecture, NV-SQL makes two technical contributions. First, it proposes the re-update interval-based admission policy that determines which write-hot pages qualify for being cached in NVDIMM. It is novel in that the page hotness is based solely on pages' LSN. Second, this study finds that NVDIMM-resident pages can violate the page action consistency upon crash and proposes how to detect inconsistent pages using per-page in-update flag and how to rectify them using the redo log. NV-SQL demonstrates how the ARIES-like logging and recovery techniques can be elegantly extended to support the caching and recovery for NVDIMM data. Additionally, by placing write-intensive redo buffer and DWB in NVDIMM, NV-SQL eliminates the log-force-at-commit and WAL protocols and further halves the writes to the storage. Our NV-SQL prototype running with a real NVDIMM device outperforms the same-priced vanilla MySQL with larger DRAM by several folds in terms of transaction throughput for write-intensive OLTP benchmarks. This confirms that NV-SQL is a cost-performance efficient solution to the durability problem.", "Due to the recent increase in the number of devices connected to different networks, information traffic has increased significantly. As a result of this, the number of threats has also increased. Thus, other works proposed intrusion detection systems (IDS) to protect sensitive user data. IDS are responsible for identifying malicious data flows and reporting possible attacks. However, the first IDS have based on detecting attacks on signatures. Therefore, IDS cannot keep up with the constant evolution of existing attacks. Hence, techniques such as Machine Learning (ML) have become allies of this system type to ensure its effectiveness. The use of ML represents a significant advance in the development of IDS, but there are still open questions about the ability to detect attacks on different isolated networks. Therefore, the present work proposes a Federated Learning (FL) scheme with sampling and attribute selection methods for Distributed Denial-Of-Service (DDoS) classification.Furthermore, we propose to combine the FL scheme with the Energy-based Flow Classifier (EFC) algorithm building an ensemble model capable of identifying malicious agents. We evaluated whether using an ensemble can extract different types of information during the ML process. This work represents ongoing research with results under development.", "Delivering services for Internet of Things (IoT) applications that demand real-time and predictable latency is a challenge. Several IoT applications require stringent latency requirements due to the interaction between the IoT devices and the physical environment through sensing and actuation. The limited capabilities of IoT devices require applications to be integrated in Cloud and Fog computing paradigms. Fog computing significantly improves on the service latency as it brings resources closer to the edge. The characteristics of both Fog and Cloud computing will enable the integration and interoperation of a large number of IoT devices and services in different domains.This work models the scheduling of IoT service requests as an optimization problem using integer programming in order to minimize the overall service request latency. The scheduling problem by nature is NP-hard, and hence, exact optimization solutions are inadequate for large size problems. This work introduces a customized implementation of the genetic algorithm (GA) as a heuristic approach to schedule the IoT requests to achieve the objective of minimizing the overall latency. The GA is tested in a simulation environment that considers the dynamic nature of the environment. The performance of the GA is evaluated and compared to the performance of waited-fair queuing (WFQ), priority-strict queuing (PSQ), and round robin (RR) techniques. The results show that the overall latency for the proposed approach is 21.9% to 46.6% better than the other algorithms. The proposed approach also showed significant improvement in meeting the requests deadlines by up to 31%.", "Thanks to the skyscraping development of hardware and software technologies, the data solutions have become an urgent trend to deal with vast amount of data, especially in biomedical research, human genome and healthcare systems. The healthcare research has always demanded close association with biomedical data to produce personalized medicine and deliver suitable cure and treatments. Nevertheless, coping with huge amount of information from biomedical data requires bulky solutions. In the light of data science, the solution for this issue can change from a theoretical approach to a data-driven approach. Database stores a huge amount of information and particular sets of data can be accessed via queries which are written in specific interface language. In order to manage this amount of data, database optimization is implemented to maximize the speed and efficiency with data retrieval or reduce database system response time. Query optimization is one of the major functionalities in database management systems. The purpose of the query optimization is to determine the most efficient and effective way to execute a particular query by considering several query plans. In this article, genetic algorithm (GA) strategy is utilized for biomedical database systems to execute the query plan. Genetic algorithms are extensively using to solve constrained and unconstrained optimization problems. Based on three main types of rules of GA such as selection, crossover and mutation, the querying can be optimized for solving database problem.", "Location awareness is the basis for enabling pickup service at ride-hailing platforms. In contrast to the almost pervasive coverage outdoors, indoor localization availability is still sporadic in industry since it largely relies on RF signatures from certain IT infrastructure, e.g., WiFi access points. Based on our 2-year observations at DiDi ride-hailing platform in China, there are 68\ud835\udc58 orders everyday created at black-hole, i.e., where only cellular signals exist. In this paper, we present the design, development, and deployment of TransparentLoc, a large-scale cellular localization system for pickup position recommendation, and share our 2-year experience with 50 million orders across 13 million devices in 4541 cities to address practical challenges including sparse cell towers, unbalanced user fingerprints, and temporal variations. Our system outperforms the iOS built-in cellular localization system in terms of four major service metrics, regardless of environmental changes, smartphone brands/models, time, and cellular providers.", "Industrial applications heavily integrate open-source software libraries nowadays. Beyond the benefits that libraries bring, they can also impose a real threat in case a library is affected by a vulnerability but its community is not active in creating a fixing release. Therefore, I want to introduce an automatic monitoring approach for industrial applications to identify open-source dependencies that show negative signs regarding their current or future maintenance activities. Since most research in this field is limited due to lack of features, labels, and transitive links, and thus is not applicable in industry, my approach aims to close this gap by capturing the impact of direct and transitive dependencies in terms of their maintenance activities. Automatically monitoring the maintenance activities of dependencies reduces the manual effort of application maintainers and supports application security by continuously having well-maintained dependencies.", "Web Services (WSs) are gaining worldwide popularity due to reliable and fast intercommunication services for the development of web and mobile applications. WSs are provided to client application developers through web Application Programming Interfaces (APIs), such as YouTube API, Twitter API, Facebook API, etc. Due to the popularity of WSs, the developers frequently discuss various WSs-based application' issues on online forums, such as Stack Overflow (SO). This study aims to highlight the problems faced by client developers in the development process of WSs-based applications using the dataset of SO. The comprehension of developers' conversations on SO can give insight into the frequency, difficulty, and popularity of different WSs-related problems of developers. We downloaded 12,746 posts from SO relevant to WSs-related issues for this article. We used the topic modeling technique (LDA) to extract various topics from the SO dataset. The topics are labeled and organized into categories and sub-categories according to relationships among them. The difficulty and popularity of each topic have been analyzed. Our investigation yield several findings. First, developers focus on six topics related to WSs on SO: Client APIs development, Data Processing, Web services Authorization, Framework Support, Web APIs, and Mobile Applications. Secondly, the advantages and disadvantages of web applications topic (Fused_Popularity=0.39), from the Clients APIs development category have the highest prevalence, followed by Database (DB) and Data Processing in Applications topic (Fused_Popularity=0.38) from the Data Processing category. Third, most WSs-related topics in all categories are evolving promptly on SO, i.e., new questions are added daily about WSs development, deployment, and authorization. Fourth, the questions of type ''how'' are primarily asked in Framework support, Client APIs development, and Web APIs categories. Although, many questions in other categories are of the kind ''What''. It is also observed that WSs developers not only used SO to ask How and What types of questions but they also used SO to ask information-seeking questions (i.e., in Data processing and Client APIs development categories). Fifth, the topics relevant to Web APIs (Fused_Popularity=10.8) and Client API Development ((Fused_Popularity=9.35) categories of WSs are very popular on SO. Sixth, the questions relevant to the Web APIs (Fused_Difficulty =3) & Client APIs development (Fused_Difficulty=2.25) categories are more difficult than the other four categories. The results of our research may be helpful for the following WSs stakeholders: WSs Client application developers, WSs Educators, and WSs researchers. The WSs Educators and investigators can get more knowledge of new methods and discover novel techniques to make challenging WSs topics easy to understand. WSs framework developers can utilize our extracted WSs topics and categories to know the preferences of WSs developers that may support them in upgrading existing frameworks or developing new ones.", "Backend development requires a lot of boilerplates, and technical terms are difficult for everyone to understand. We are developing a platform where users can easily establish their backend endpoints and publish their code in order to address this issue. The goal of this project is to assist those who lack technical expertise yet desire to develop a backend for their projects, products, etc. A user can easily create their own backend logic with the use of a simple user interface, such as Scratch (a simple learning tool to assist people to learn to program). Using a drag-and-drop interface, the author is creating a backend service. These services offer pre-built blocks, templates, or drag-and-drop interfaces for users to utilize in order to create their own backend services, such as APIs, without having to write any code.", "Industry 4.0 is going through a transitional period via the radically automotive transformations. In particular, unmanned aerial vehicles have significantly contributed to the development of intelligent and connected transportation systems. Thus, the continuous development using diverse technologies to achieve a variety of high-performance services raised the security concerns regarding communicating entities. Thus, being managed by networked controllers, UAVs uses controller area networks (CAN) protocol to broadcast information in a bus. However, this protocol is used as a de facto standard which does not have sufficient security features that raise the security risks. This issue caught the attention of the automotive industry researchers and several studies have attempted to improve the security of the CAN protocol attack detection. However, the proposed studies established general perspective solution and did not pay attention to UAVCAN attack detection. To alleviate these concerns, this paper proposed a dynamic intrusion detection frameworks (DIDF) for UAVCAN. The proposed UAVCAN DIDF scheme adopts an artificial intelligence (AI) based model to achieve high detection performance. We performed experiments using public UAVCAN dataset to evaluate our detection system. The experimental results demonstrate that UAVCAN DIDF has significantly reached a high detection rate with a high true positive and a low false negative rate. The simulation results are encouraging and demonstrate the effectiveness of UAVCAN DIDF.", "Online marketplace is a medium for connecting sellers and buyers. Besides that, it is currently more focus on selling products rather than selling services. Usually, if there are products and services in the same platform, the transaction systems will be automatically separated. The purpose of this research is to create an information system that can combine services and product which focuses on beauty for men. The platform can facilitate customers and vendor to buy and sell products and services easily. This research is more focus on the back-end system which uses Node JS as REST-API and MySQL as the database system. Furthermore, in the development phase, the scalability of the system is measured using Apache J Meter to find how many capacities that can be handled by the system. As a result, the system is able to accommodate up to 1500 requests. It is quite good result due to NodeJS has advantages in its features, which is nonblocking to process the data faster.", "With the rapid popularization and development of computers and mobile devices, the corresponding modern network devices and network structures have become more advanced and more complex. SDN has the advantages of centralized control, open interface, network virtualiza-tion, etc. and has been applied in various modern network management. However, because the SDN network has the characteristics of central-ized control, the SDN controller will also become a key target of the attack. This article combines mimic defense with SDN technology, focus-es on quantitative analysis of mimic defense in SDN applications, the impact of different defense strategies on the security of the entire system, shows the influence of different conditions on system security, and solves the optimal configuration policy. Finally, experiments are performed to demonstrate the effectiveness of different mimicry defense strategies, which confirms our theoretical strategies.", "The proliferation of Internet of Things (IoT) devices in our daily lives has raised concerns about the security of transmitted data. Due to their limited resources, IoT devices are vulnerable to malware attacks and cyber threats. Detecting and classifying these attacks is crucial to mitigate their impact. Various intrusion detection techniques have been proposed for IoT, including approaches based on Machine Learning (ML) and Artificial Intelligence (AI). Most of the ML/AI-based intrusion detection techniques, though effective, often lack transparency and trustworthiness. To address these aspects, eXplainable Artificial Intelligence (XAI) has emerged as a promising solution, providing insights on AI model decisions. In this work, we describe an explainable Intrusion Detection System (IDS) in IoT networks which embeds a multi-way Fuzzy Decision Tree (FDT) as an XAI model for traffic classification. We propose a Cross-Device training and evaluation approach in which we evaluate the generalization capability of the IDS when new devices are connected to the IoT network without retraining the FDT.", "Understanding and modeling traffic demand characteristics in datacenter networks is of great importance for datacenter network optimization. However, prior traffic models are over-simplified and insufficient in capturing the complex locality properties of traffic demand. We analyze real-world traffic traces and discover strong dependency between the spatial attributes (source, destination) and non-spatial attributes (interarrival time, flow size) of traffic demand. We propose Lomas to model the joint distribution of multi-dimensional traffic demand attributes and generate synthetic traces. Lomas is a novel extension of hierarchical Bayes model that can represent the relationships among these attributes as a dependency graph. We validate Lomas by showing its ability to recreate the flow-level traffic demand patterns of real-world traffic traces. Our approach can be easily adapted to different datacenters with heterogeneous traffic demand patterns, making it a convenient tool for practitioners to utilize.\u2022", "In recent years, with the continuous development of fibre-to-theroom (FTTR) technology and wide deployment of FTTR network, the application scenario of FTTR is gradually extended from home to small businesses such as offices, schools, and industry. In this paper, full-optics enterprise FTTR architecture is introduced, which is constructed by enterprise gateway, sub gateway, internal optical distribution network (ODN) and management platform. For FTTR use cases, the scenarios of small offices and service halls are introduced. A full-optics network is proposed to deploy for small offices and service halls, supporting higher bandwidth efficiency, more connections of terminations, larger split ratio, unified and high-quality network management, and future network evolution. Besides, requirements such as infrastructure lifecycle, connections and line rate, priority-based bandwidth assignment are specified as well.", "Figure 1: An image of a Trojan horse, original generated with DALL\u2022E with the prompt \"a realistic painting of a Trojan horse at the gates of Troy, with silhouettes of people in awe\"ABSTRACT Despite its age, SQL is still a widely sought skill among software developers and data engineers, which makes learning SQL a tempting prospect. Several online courses and tutorials may even inspire learners by stating that SQL is a simple and easy language to learn. This impression might also be strengthened by looking at simple SQL statements that read close to English, in contrast to most programming languages. In this paper, I will present ten complexities hiding behind SQL's initial appeal, and my experiences and possible solutions in mitigating these complexities in data systems education.", "Along with the development of the Internet, the network plays an increasingly important role in people's work and life. Moreover, the increasing popularity of smart devices has prompted people to get used to storing various information and data on mobile phones, tablets, computers, clouds and other network media or devices. Nevertheless, the security problem of network information is still serious, and economic losses caused by information theft due to illegal network intrusion are common. Therefore, in this paper, based on the research of computer network security protection technology and consulting a large amount of data, firstly the security problems existing in computer network were discussed, then the importance of computer network security protection technology in computer network operation was expounded, and next the design scheme of computer network security protection system and computer network security protection strategies were put forward, providing theoretical reference for further application of computer network security protection technology.", "Background: There are a number of academic courses in the Bachelor Program in Computer Science (CS) on the design of Web apps. Often the internal and external quality of the developed Web apps is not adequately taken into account. Aim: We aimed to (i) estimate the quality of Web apps developed by bachelor CS students in a Software Technologies for the Web (STW) course (a.y. 2021-22) and (ii) define a training plan (on the base of the results of the first step) for the students enrolled to this course for the a.y. 2022-23 to let them design and implement better Web apps, and (iii) experimenting the training plan by comparing the quality of Web apps developed in a.y. 2021-22 and a.y. 2022-23. Method: We designed a prospective empirical investigation to study STW with respect to the training of bachelor students with respect to the quality (internal and external) of the developed Web apps. Results: We observed that quality concerns are widespread in the code of the Web apps the STW students developed in the a.y. 2021-22. Therefore, we plan to ask the students of the a.y. 2022-23 to use in their development pipeline a Static Analysis Tool (SAT) to detect quality concerns in the developed Web apps and deal with them. This second step represents an ongoing stage of our research. Conclusions: Our preliminary outcomes suggest that students must be aware that quality is of primary relevance for the development of Web apps and prepared to use SAT in the development pipeline.", "Numerous public cloud infrastructure providers today allow for access to Noisy Intermediate-Scale Quantum (NISQ) computers. Changes in the environment or the machine configuration may affect their dependability. Through analysis of real quantum computer calibration data, this work demonstrates that quantum computers available from IBM Quantum experience periods of fluctuation or abrupt qubit frequency changes. This work further analyzes the correlation between the frequency change events, decoherence times, gate errors, and machine maintenance or offline periods. The results highlight that the properties of NISQ computers change over time, affecting their dependability, but not all of the changes can be explained with publicly available data.", "Gaming is a more accessible, engaging and popular past-time than ever before. Recent research highlights games as strikingly efective means of capturing and holding our attention -so efective, some argue, to the point of deleterious efect. An impassioned CHI2021 panel discussion directed these eforts towards the ethics and adoption of dark patterns. And yet, we know little as to how dark patterns are perceived and arise in the design, development and use of games. This paper seeks to address this knowledge gap by recounting fndings from a design-led inquiry comprising interviews and workshops conducted with mobile game players, designers, developers, and business developers. We contribute an understanding of how dark patterns arise in the development, use and commercialisation of mobile games, their efects on players and industry professionals, and means for the consideration, negotiation and navigation of these strategies for gamer-engagement by designin support of healthier, highly-engaging game experiences.", "Behavioral malware detection has been shown to be an effective method for detecting malware running on computing hosts. Machine learning (ML) models are often used for this task, which use representative behavioral data from a device to make a classification as to whether an observation is malware or not. Although these models can perform well, machine learning models in security are often trained on imbalanced training datasets that yield poor real-world efficacy, as they favor the overrepresented class. Thus, we need a way to augment the underrepresented class. Some common data augmentation techniques include SMOTE, data resampling/upsampling, or using generative algorithms. In this work, we explore using generative algorithms for this task, and show how those results compare to results obtained using SMOTE and upsampling. Specifically, we feed the less-represented class of data into a Generative Adversarial Network (GAN) to create enough realistic synthetic data to balance the dataset. In this work, we show how using a GAN to balance a dataset that favors benign data helps a shallow Neural Network achieve a higher Area Under the Receiver Operating Characteristic Curve (AUC) and a lower False Positive Rate (FPR).", "The software maintenance area is one of the oldest in software engineering, which is a fundamental role in all development, ensuring the final product quality and stability in the market. However, the control of software maintenance metrics becomes a difficult task, as there are no consistent applicability normalization for these metrics, and it is up to the software maintenance teams to decide which metrics to apply. In order to identify the main metrics used in the software maintenance area, we carried out a systematic review of the literature on the relevant studies published in the period between 1990-2020 into the main search engines in the area of software engineering. According to the keywords and inclusion and exclusion criteria, 44 out of 2145 articles were selected on the IEEE, ACM Digital Library, ScienceDirect, SCOPUS and Wiley Interscience. Thus, the software maintenance metrics were identified in the product, process and resource perspectives more widely directed towards the product, as well as the application validation of these metrics are made through technical experimentation of the measurement, that is, validations in a controlled environment that often do not match the reality of the software maintenance environment. Therefore, it is highlighted that the analysis of software maintenance metrics is a promising area for new researches targeting distinct perspectives, including in a real software maintenance environment.", "With the development of the information industry, people are faced with an increasing amount of data. In order to obtain the intrinsic relationship and implicit information from these large-scale data, data mining as an important method has been paid more and more attention by people, and cluster analysis is an important research direction of data mining. In the era of big data, massive multimodal data exists widely. How to mine the huge hidden value of data through complementary learning between modal data is the main problem of big data research at this stage, and it is also the task of big data and traditional data learning. Mixed attribute datasets are the most common type of datasets in the real world, especially in commercial financial databases, but there are very few clustering algorithms suitable for such datasets. The method used in this paper is machine learning, which enables computers to simulate human learning behavior, automatically acquire knowledge and skills through learning, continuously improve performance, and achieve self-improvement.", "There is a lot of interest in the research and development related to ultra-wideband (UWB) systems because of the increasing demands on applications with low power, low cost, and low interference. Thus, to cope with these demands, various kinds of research are required for the development of a wireless communication transceiver front-end, which includes a six-port network as an alternative to a mixer-based design. Hence, this article presents a compact design for the UWB six-port network that uses two 3-dB couplers, an in-phase power divider, and a 90\u00b0power divider. The proposed network is developed using the microstrip-slot technique, which guarantees satisfactory operation across the UWB frequency range with compact dimensions. The design is performed via the use of CST Microwave Studio and realized using Rogers TMM4 with a conductor coating of 35 \ud835\udf07m, a thickness of 0.508 mm, and a dielectric constant of 4.5. The developed prototype of the proposed design is verified by measurement using a vector network analyzer (VNA). Performance analysis concerns transmission and reflection coefficients, phase characteristics, and q-points. The presented UWB performance of the proposed six-port network is expected can be implemented for quadrature phase shift keying (QPSK) and quadrature amplitude modulation (QAM) modulator and demodulator applications in various wireless communication transceivers such as fifth generation (5G), and wireless fidelity (Wi-Fi).", "Due to the coronavirus crisis, a lot of companies all over the world started a fast digitalization of their business and became more comfortable with the digital world. In this way, a lot of people in the digital domain, including net developers and system engineers, are exposed to different types of risks that they may not completely know or understand. SQL injection is one such vulnerability that can be exploited by attackers to inject malicious data into a database via an application programming interface (API) call request that uses SQL syntax. Cloud computing (IaaS) and network as a service (Naas) provide companies with a wide range of advantages. However, the same advantages can also pose certain vulnerabilities to the organization. In this paper we will focus on SQL injection attacks and make a comparison between different Machine learning algorithms that can be used to detect SQL injection attacks, such as \"Naive Bayes\" and \"K-NN\", SVN, and decision tree, we will also use a deep learning algorithm CNN, this comparison will show the potential that machine learning algorithms can offer in terms of cloud security.\u2022 Security and privacy \u2192", "Ubisoft constantly pushes the boundaries of game development to create immersive worlds that capture the imagination of millions of players worldwide. To achieve this, performance engineering plays a crucial role in ensuring that games run smoothly on various platforms and devices.In this talk, we will explore the latest advancements in the field of performance engineering for video games, focusing on runtime performance, network optimization, backend and database optimization, and cloud gaming. We will discuss how machine learning techniques enhance classical profiling and optimize game engine scheduling.Additionally, we will address the challenges of deterministic replication of assets between clients and optimizing microservices for cloud gaming experiences. Lastly, we will touch on the importance of performance engineering for non-code aspects of game development, such as animation, textures, props, and assets.\u2022 Software and its engineering~Software verification and validation \u2022 Software and its engineering~Software testing and debugging", "Automating repetitive steps in the development process of any product is an engineering desideratum. Every software product has an early development stage consisting of creating components that allow the use of a set of predefined resources. We show that this stage can be automated, with a positive impact on implementation time and the prevention of possible logical or operational errors due to the human factor.We consider that by simply describing the entities (resources) that are to be used in the development process in a technical way, the whole source code with the implementations of CRUD operations on the previously defined resources will be obtained. The source code can be used as a starting point, reducing the time spent on repetitive details, which are usually standardized but rarely automated.The solution is to streamline the development process of RESTful APIs, and the method chosen to make this possible is automatic generation of software components. The proposed method is based on template-based code generation (TBCG) -creating templates that involve aggregating the code to be generated (static parts) with a high-level language (dynamic parts) that allows various operations, such as decision making, statement repetition and data transformation.", "More and more 5G and AI applications demand flexible and low-cost processing of their traffic through diverse virtualized network functions (VNFs) to meet their security and privacy requirements. As such, the Network Function Virtualization (NFV) market has been emerged as a major service market that allows network service providers to trade their network services among customers. Since each service market usually involves complex interplays among players with different roles, efficient mechanisms that guarantee stable and efficient operations of the NFV market are urgently needed. One fundamental problem in the NFV market is how to maximize the social welfare of all players so that all players have incentives to participate in the activities of the market. In this paper, we first formulate a novel social welfare maximization problem in an NFV market of a multi-tier edge cloud network, with the aim to maximize the total revenue collected from all players, and we implement VNF services on Virtual Machines (VMs) leased by service providers to fulfill customers with service requests, where the edge cloud network consists of both cloudlets in edge networks and remote data centers in the core network. We then design an efficient incentive-compatible mechanism for the problem, and analyze the existence of a Nash equilibrium of the mechanism. Also, we consider an online social welfare maximization problem with", "World Wide Web was originally meant as a global information exchange but it has since then morphed into the largest available application platform. Especially during the past decade, mobile usage has been rising while the size of websites and applications has been steadily rising therefore making size an important target for optimization. In this article, we look into a new primitive called resumability. Resumability allows developers to avoid caveats of earlier approaches, such as hydration, by embedding some of the required data straight into HTML markup delivered to the client. Then the client resumes execution as an application becomes interactive. The technique allows frameworks to apply well-known techniques, such as code-splitting, automatically therefore reducing developer effort. By considering past developments and a couple of concrete examples, we propose resumability as a new primitive for web application development. Furthermore, we also discuss potential research directions for those wanting to understand the topic in greater detail.INDEX TERMS Hydration, JavaScript, multi-page applications, page size, resumability, single page applications, software architecture, web application development, web performance, world wide web.1 This is particularly true within a mobile environment when JavaScript payloads are big enough [5] .", "In this paper, we propose and implement a mock server that utilizes the latest ECHONET Lite Web API guideline to support the development of applications and services for smart homes in Japan. From the Device Description, this mock server supports a mechanism to generate virtual devices whose property-value pairs are configurable based on developers' needs. As a result, developers can develop and test their ECHONET Lite Web API implementations without actual devices. More importantly, they can verify their solution's robustness in extreme cases that are hard to achieve with actual devices. This mock server is the first to support the latest ECHONET Lite Web API guideline fully and its usability has been proven.", "Federated learning improves data privacy and efficiency in machine learning performed over networks of distributed devices, such as mobile phones, IoT and wearable devices, etc. Yet models trained with federated learning can still fail to generalize to new devices due to the problem of domain shift. Domain shift occurs when the labeled data collected by source nodes statistically differs from the target node's unlabeled data. In this work, we present a principled approach to the problem of federated domain adaptation, which aims to align the representations learned among the different nodes with the data distribution of the target node. Our approach extends adversarial adaptation techniques to the constraints of the federated setting. In addition, we devise a dynamic attention mechanism and leverage feature disentanglement to enhance knowledge transfer. Empirically, we perform extensive experiments on several image and text classification tasks and show promising results under unsupervised federated domain adaptation setting.", "into printable kinematic models as G-Code for FDM3DP. To expand the design space, we investigate a series of motion structures (e.g., rotate, slide, and screw) with multi-stabilities and develop a design tool to help users quickly design such dynamic objects. We also demonstrate various application cases, including physical interfaces, toys with interactive aesthetics and daily items with internalized functions.", "This paper aims to describe and motivate the author's perspective on the issues posed by robotics, specifically Artificial Intelligence, exploring the significance of the Fundamental Rights approach to AI. The author believes both aspects are essential to understanding robotics, work empowerment and the environment. The Fundamental Rights approach helps concentrate the attention on the issue of the environment, which will be intended as the social environment, which is strictly linked to legal sustainability.", "Beyond implementation correctness of a distributed system, it is equally important to understand exactly what users should expect to see from that system. Even if the system itself works as designed, insufficient understanding of its user-observable semantics can cause bugs in its dependencies. By focusing a formal specification effort on precisely defining the expected user-observable behaviors of the Azure Cosmos DB service at Microsoft, we were able to write a formal specification of the database that was significantly smaller and conceptually simpler than any other specification of Cosmos DB, while representing a wider range of valid user-observable behaviors than existing more detailed specifications. Many of the additional behaviors we documented were previously poorly understood outside of the Cosmos DB development team, even informally, leading to data consistency errors in Microsoft products that depend on it. Using this specification, we were able to raise two key issues in Cosmos DB's public-facing documentation, which have since been addressed. We were also able to offer a fundamental solution to a previous high-impact outage within another Azure service that depends on Cosmos DB.", "As a special class of the Internet-of-Things (IoT), Industrial Internetof-Things (IIoT) enhance the efficiency of manufacturing and industrial processes by utilizing smart components and new technologies in industrial sectors. With the increasing maturity and affordability of IIoT, more and more industrial control systems and cyberphysical systems have been transformed to adopt the IIoT paradigm. The large amount of security-critical and privacy-sensitive data captured by IIoT systems are lucrative targets of, and vulnerable to, cyber-attacks, hence demanding effective protection and security control. As one of the most important tools in the detective security regime, intrusion detection systems (IDS) are thus valuable for protecting IIoT infrastructure. Many machine-learning (ML) techniques have been studied extensively to develop efficient and intelligent IDSs. Despite their popularity, most current ML-based intrusion detection systems encounter difficulties when put into practice in real industrial settings. These difficulties include the high cost of continuously obtaining accurate labels under the big data background and unsatisfactory detection results on imbalanced data sets. Hence, this paper proposes a novel method that explores the possibility of applying partial label learning (PLL) techniques jointly with data resampling algorithms to develop a practical intrusion detection system for enhancing IIoT security. Extensive experimental results on five publicly available IDS evaluation datasets clearly show the effectiveness of the proposed approach and its ability to mitigate the impact of ambiguous labels and data imbalance problems in ML-based IIoT attack detection tasks.", "Machine learning and deep learning models are commonly developed using programming languages such as Python, C++, or R and deployed as web apps delivered from a back-end server or as mobile apps installed from an app store. However, recently front-end technologies and JavaScript libraries, such as TensorFlow.js, have been introduced to make machine learning more accessible to researchers and end-users. Using JavaScript, TensorFlow.js can define, train, and run new or existing, pre-trained machine learning models entirely in the browser from the client-side, which improves the user experience through interaction while preserving privacy. Deep learning models deployed on front-end browsers must be small, have fast inference, and ideally be interactive in real-time. Therefore, the emphasis on development and deployment is different. This paper aims to review the development and deployment of these deep-learning web apps to raise awareness of the recent advancements and encourage more researchers to take advantage of this technology for their own work. First, the rationale behind the deployment stack (front-end, JavaScript, and TensorFlow.js) is discussed. Then, the development approach for obtaining deep learning models that are optimized and suitable for front-end deployment is then described. The article also provides current web applications divided into seven categories to show deep learning potential on the front end. These include web apps for deep learning playground, pose detection and gesture tracking, music and art creation, expression detection and facial recognition, video segmentation, image and signal analysis, healthcare diagnosis, recognition, and identification.", "The energy demands of data centers are increasing and are expected to grow exponentially. Reducing the energy consumption of data centers decreases operational expenses, as well as their carbon footprint. We design techniques to reduce data center power consumption by leveraging Software-Defined Networking (SDN) and programmable data plane concepts. Relying solely on in-data plane registers, our proposed system P4Green consolidates traffic in the least number of network switches and shifts workloads to the servers with the available renewable energy. Unlike existing SDN-based solutions, P4Green's operation does not depend on a centralized controller, making the system scalable and failure-resistant. Our proof-ofconcept simulations show that traffic consolidation can reduce data centers' aggregation switch usage by 36% compared to standard data center load balancing techniques, while workload control can boost renewable energy consumption for 46% of the daily traffic.", "Security vulnerabilities in computer systems raise serious concerns as computers process an unprecedented amount of private and sensitive data today. Cachetiming attacks (CTA) pose an important practical threat as they can effectively breach many protection mechanisms in today's systems. However, the current detection techniques for cache timing attacks heavily rely on heuristics and expert knowledge, which can lead to brittleness and the inability to adapt to new attacks. To mitigate the CTA threat, we propose using MACTA, a multi-agent reinforcement learning (MARL) approach that leverages population-based training to train both attackers and detectors. Following best practices, we develop a realistic simulated MARL environment, MA-AUTOCAT, which enables training and evaluation of cache-timing attackers and detectors. Our empirical results suggest that MACTA is an effective solution without any manual input from security experts. MACTA detectors can generalize to a heuristic attack not exposed in training with a 97.8% detection rate and reduce the attack bandwidth of RL-based attackers by 20% on average. In the meantime, MACTA attackers are qualitatively more effective than other attacks studied, and the average evasion rate of MACTA attackers against an unseen state-of-the-art detector can reach up to 99%. Furthermore, we found that agents equipped with a Transformer encoder can learn effective policies in situations when agents with multi-layer perceptron encoders do not in this environment, suggesting the potential of Transformer structures in CTA problems.", "Natural Language to SQL systems (NL-to-SQL) have recently shown improved accuracy (exceeding 80%) for natural language to SQL query translation due to the emergence of transformer-based language models, and the popularity of the Spider benchmark. However, Spider mainly contains simple databases with few tables, columns, and entries, which do not reflect a realistic setting. Moreover, complex real-world databases with domain-specific content have little to no training data available in the form of NL/SQL-pairs leading to poor performance of existing NL-to-SQL systems.In this paper, we introduce ScienceBenchmark, a new complex NL-to-SQL benchmark for three real-world, highly domain-specific databases. For this new benchmark, SQL experts and domain experts created high-quality NL/SQL-pairs for each domain. To garner more data, we extended the small amount of human-generated data with synthetic data generated using GPT-3. We show that our benchmark is highly challenging, as the top performing systems on Spider achieve a very low performance on our benchmark. Thus, the challenge is many-fold: creating NL-to-SQL systems for highly complex domains with a small amount of hand-made training data augmented with synthetic data. To our knowledge, ScienceBenchmark is the first NL-to-SQL benchmark designed with complex real-world scientific databases, containing challenging training and test data carefully validated by domain experts.", "Increasing cybersecurity incidents call for a competitive cybersecurity workforce more than ever. We create new comprehensive cybersecurity university curricula in a metro undergraduate-focused regional university. Our program is distinguished from other programs by specializing in incident response, which addresses the analysis of attack trails and damages followed by infrastructure hardening including software, systems, and policies to prevent future attacks. This special theme requires practical strength such as certifiable deep knowledge, hands-on skills, and research-involved cybersecurity activities. We present the design and implementation of the cybersecurity curricula in our institution.", "One of the most important subject which many researchers depending on it by applying many algorithms and methods is Cloud Computing. Some of these methods were used to enhance performance, speed, and advantage of task level parallelism and some of these methods used to deal with big data and scheduling. Many others decrease the computation's quantity in the process of implementation; specially decrease the space of the memory. Parallel data processing is one of the common applications of infrastructure, which is classified as a service in cloud computing. The purpose of this paper is to review parallel processing in cloud. However, the results and methods are inconsistent; therefore, the scheduling concepts give easy method to use the resources and process the data in parallel and decreasing the overall implementation time of processing algorithms. Overall, this review give us and open new doors for using the suitable technique in parallel data processing filed. As a result our work show according to many factors which strategies is better.", "The present work shows the design and optimization of a means of hybrid coaxial transmission with optical fiber, perfected to reduce conductive losses at high frequencies. It is a work based on the RV 719 \"Hybrid high-speed transmission medium of more coaxial fiber\", the RV 1071 \"N-Male connector for hybrid transmission medium with optical fiber\" and the RV 1096 \"N-Female connector for hybrid transmission medium with optical fiber\", INDECOPI, 2020. It contains in its internal structure an optical fiber for the transmission of data in parallel of high speed by both means. The design and calculation of the parameters was carried out and correlated with their common market peers where the improvement in the design characteristics was demonstrated, the versatility of the proposed design allows the future to unify equipment and technologies.", "Purpose/Significance] This paper aims to discuss how to use big data Flink technology to develop information intelligence system, and provides a reference case for developing information intelligence system using big data real-time streaming technology. [Design/Methodology] This paper briefly introduces the basic concepts of big data, batch processing, stream processing, Flink technology and its superiority in real-time stream processing. And then, according to the thinking mode of big data, complete a set of technical framework for processing information intelligence system [Findings/Conclusion] Compared with some other big data processing technologies such as Spark , Storm, Flink technology has obvious performance advantages in processing real-time stream information. [Originality/Value] Based on the big data thinking mode and the general process of big data processing, the research team creatively proposed an information intelligence processing system solution based on big data Flink technology. The solution takes Flink streaming technology as the processing center, Kafka as the message transmission queue, Elasticsearch as the real-time search engine, Kibana as the front-end display and Mysql as the database storage system. Experiments show that this solution can effectively process big data real-time streaming data and has good practical reference value in the field of information intelligence processing based on big data real-time streaming data.", "Security is of paramount importance in the development of computer systems within our increasingly interconnected and computational world. This paper addresses the security challenges posed by microservices, a popular technology for developing computer systems. Microservices offer numerous advantages but also introduce new security concerns, given their greater attack surface and complex network activity. To address these challenges, the research explores the potential of Machine Learning (ML) techniques for intrusion detection and intrusion tolerance in microservice architectures. The main objective is to propose more effective approaches to secure microservice architectures using ML techniques for intrusion detection and intrusion tolerance. The research evaluates how ML techniques, particularly anomaly detection, can be tailored to detect intrusions in microservices-based systems and minimize false alarms. The contributions of this Ph.D. work include proposing MLbased intrusion detection approaches, providing design guidelines for intrusion detection systems, devising pre and post-processing techniques for efficiency, and researching intrusion tolerance solutions to overcome microservice challenges.", "This platform aims to fully support the \"cloud + end \" land resources geospatial big data business, integrate land resources, connect provincial and municipal big data centers, and form a smart city refined governance database. To build a geospatial big data service engine for land resources that integrates data collection, product processing, mining analysis, and storage services to achieve a unified business layout of data integration, direct connectivity, and a backup function of core backup, remote dual-action. According to the business architecture of \"cloud + end \" and integration of data and algorithms of the big data cloud platform, we designed a geospatial big data cloud platform for land and resources which will support the cloud management of land resources geospatial big data storage resources, algorithm and application component management, the integration of data, algorithm and storage and the construction of land resources business system.", "SDN has been proposed to realize flexible network management. Due to the network becomes more complex, multiple controllers are required in SDN. It brings cooperative operation problem among multiple SDN controllers. To solve this problem, common method is to set up a central SDN controller management platform, which increases the construction and operation costs. In this paper, we propose a consensus approach for SDN controllers based on blockchain. Blockchain is a decentralized distributed data management technology. Using this feature, we select the mater controller which has the most abundant resources. The master node completes the production and entry of the block, while the ordinary node accepts the block produced by the master one. To realize this approach, we propose a resource data model of the SDN controller first and a consensus method based on blockchain and this data model.", "With the development of mobile network technology, 5G mobile multimedia has greatly increased the application and popularity of mobile networks. In particular, the emergence of video, shopping and numerous mobile applications has facilitated the development of 5G mobile multimedia. At the same time, network users continue to pursue a better user experience and put forward better requirements for mobile network communications. 5G mobile communication networks have emerged to meet the needs of users and are an inevitable result and trend in the development of mobile communication networks. This paper introduces the definition of 5G network and multimedia technology, and provides a detailed introduction to multimedia technology, then introduces the multinetwork data path of 5G multimedia, focusing on the exploration of the multi-network data path of 5G multimedia, reflecting the great impact of 5G technology on the development of science and technology. Explore the multi-network data path of 5G mobile multimedia for an effective path to seek a better development space.", "The Java programming language and more specifically the J2EE platform has evolved towards the most important software framework for designing and implementing business logic on a telecom backend platform. However, the real time aspects of J2EE based telecom applications are often questioned. In 2004, a new Java-based application server technology, JAIN SLEE, has been standardized which seems a promising candidate for the development of (soft) real time telecom applications. A functional comparison of J2EE and JAIN SLEE and the concepts they are built on is presented.Java, and JAIN SLEE in particular, has been subject to a performance evaluation study evaluating the real time aspects of both the application server and the Virtual Machine. The evaluation procedure and obtained evaluation results are detailed. Moreover, the influence of the Java Virtual Machine tuning parameters for the Garbage Collector has been investigated and will be reported upon.", "In this paper, we demonstrate OmniCells: a cellular-based indoor localization system designed to combat the device heterogeneity problem. OmniCells is a deep learning-based system that leverages cellular measurements from one or more training devices to provide consistent performance across unseen tracking phones. In this demo, we show the effect of device heterogeneity on the received cellular signals and how this leads to performance deterioration of traditional localization systems. In particular, we show how OmniCells and its novel feature extraction methods enable learning a rich and device-invariant representation without making any assumptions about the source or target devices. The system also includes other modules to increase the deep model's generalization and resilience to unseen scenarios.", "We describe our experience with Fathom, a system for identifying the network performance bottlenecks of any service running in the Google fleet. Fathom passively samples RPCs, the principal unit of work for services. It segments the overall latency into host and network components with kernel and RPC stack instrumentation. It records these detailed latency metrics, along with detailed transport connection state, for every sampled RPC. This lets us determine if the completion is constrained by the client, network or server. To scale while enabling analysis, we also aggregate samples into distributions that retain multi-dimensional breakdowns. This provides us with a macroscopic view of individual services. Fathom runs globally in our datacenters for all production traffic, where it monitors billions of TCP connections 24x7. For five years Fathom has been our primary tool for troubleshooting service network issues and assessing network infrastructure changes. We present case studies to show how it has helped us improve our production services.", "Software Defined Networks (SDN) have been proposed as a possible development for next generation networking technology. In a SDN, Virtual Network Functions (VNFs) are used to replace the functions of traditional middleboxes. All of these VNFs can be controlled from a centralized controller, which comes with its own security concerns. However, there are many benefits that come from having a centralized controller as traffic can be easily controlled from a single point. This makes it interesting to further study security when it concerns SDN. This work looks to test intrusion detection system (IDS) performance under different configurations in a SDN in order to make security in SDN more robust. In this work, we take two IDSs, Snort and Suricata, and test their performance under different configurations and traffic loads. We test four different configurations: single, chain, parallel, and cross. Our findings seem to suggest that the cross configuration has the best performance of these IDS configurations.", "Along with the rapid development of science and technology, electronic information engineering has become ever more remarkable for its precise and convenient data processing and wide application fields. Its widespread application has not only change the way people obtain, store and manage information to a large extent, but also provide more new ways for people's convenient life. At the same time, with the broadening of data and information transmission channels, the security problems faced are becoming ever more prominent. The leakage of data and information in electronic information engineering, malicious tampering of the system, implantation of computer Trojan horse virus and other problems in the field of security occur frequently. And computer network security technology, as an important branch of computer network technology, takes an active part in protecting data and information security. Therefore, to ensure the security of electronic information engineering construction and application issues needs computer network security technology to achieve. In this paper, computer network security technology is used as a research tool, and two key technologies for network security, neural network of deep learning and convolutional operation, are applied. The convolutional neural network model trained and optimized by deep learning algorithm performs data information security assessment and analysis, identifies feature vectors and obtains feature element value results, and then realizes the process of analysis, prompting and early warning of information security in electronic information engineering. In addition, combined with the practical application of the model in electronic information engineering data transmission, it further reflects the importance of combining artificial intelligence-related technologies to improve the application scope of computer network security technology.", "Smile recognition is a very important topic in image processing and deep learning, and has a certain practical significance. At present, existing datasets tend to have simple backgrounds or imbalanced ethnicities. And researchers need to build convolutional neural networks empirically. To address these problems, we first construct a comprehensive dataset which contains 10,392 images of four major races (i.e., White, Asian, American Native or Pacific Islander, and Black or African American) in complex backgrounds. Our dataset exhibits larger variations in background, illumination, and ethnicity. And then, we apply Bayesian neural architecture search algorithm to automatically build the optimal convolutional network architecture and perform model training. The network architecture can be repeatedly searched and optimized through Bayesian optimizer in the specified time. Through the comparisons of experimental data, the performance of our network is better than those of the classical networks.", "Industrial robots significantly contributed to the increase of quality and productivity in the industry. Still, their deployment and use remain complex and expensive, limiting their main market to mass production in large factories. This article introduces an intelligent robotics framework intended to solve this issue. It relies on a four-layer modular architecture associating a components-agnostic orchestrator coordinating software modules accessed through a standard middleware, and different hardware running the required functions. This architecture is implemented for performing various tasks in autonomy or in collaboration with a human operator, the different components being turned on and adapted on-demand according to the use-case requirements. We illustrate the proposed concept on four robotic sequences: the assembly of a representative gear unit with one arm, the same application with two robots, the Robothon\u00ae Grand Challenge and the insertion of deformable objects in a rail.", "In this paper, we propose a novel resource sharing scheme for full duplex device-to-device (D2D) communication underlaying cellular network. In the considered scenario, two D2D users share the downlink spectrum resource with two cellular users. When the two D2D users transmit signals to each other, they also act as relays between the base station (BS) and the cellular users so that the cellular users can leverage the redundant capacity of the two full duplex D2D users. To optimize the performance of the scheme, the power allocation is optimized by considering the impact of residual self-interference at full duplex radios and the quality of services (QoS) requirement for both cellular users and D2D users. The simulation results show that, compared to the existing research scheme, the proposed scheme can achieve larger sum channel capacity for the transmission of cellular users, and it can also achieve larger average system throughput at high signal to interference plus noise ratio (SINR) region.", "The bandwidth and latency requirements of modern datacenter applications have led researchers to propose various topology designs using static, dynamic demand-oblivious (rotor), and/or dynamic demand-aware switches. However, given the diverse nature of datacenter traffic, there is little consensus about how these designs would fare against each other. In this work, we analyze the throughput of existing topology designs under different traffic patterns and study their unique advantages and potential costs in terms of bandwidth and latency \"tax\". To overcome the identified inefficiencies, we propose Cerberus, a unified, two-layer leaf-spine optical datacenter design with three topology types. Cerberus systematically matches different traffic patterns with their most suitable topology type: e.g., latency-sensitive flows are transmitted via a static topology, all-to-all traffic via a rotor topology, and elephant flows via a demand-aware topology. We show analytically and in simulations that Cerberus can improve throughput significantly compared to alternative approaches and operate datacenters at higher loads while being throughput-proportional.", "With the rise in popularity of multiplayer online games, efficient game network communication has become increasingly vital. This research paper presents a comprehensive design and implementation of a network session plug-in, focusing on framework construction, data module integration, intermediate module development, and plug-in functionality testing. The primary objective of the plugin is to enhance the convenience and efficiency of game network communication. Extensive testing, including performance evaluation, stress testing, and functional testing, has been conducted to validate the effectiveness and feasibility of the plug-in. The results showcase the successful development of a robust network session plug-in for multiplayer online games, offering valuable insights for future plug-in advancements. This research contributes significantly to the enhancement of game network technology, ultimately improving the overall player experience in multiplayer online gaming environments.", "Network function virtualization (NFV) -based fog computing paradigms support delay-sensitive applications with flexible deployment of virtual network functions (VNFs). However, the limited resources at the fog nodes result in overload at high traffic volumes, thus impacting capacity and quality of service. Hence, this paper proposes a pre-overload migration scheme that copies mapped VNFs from a host node to neighboring target nodes before a saturation event. Once the latter occurs, requests are rerouted to a backup path to resume service with minimal migration iterations and service downtime as compared to a reactive post-overload migration scheme.", "Students in database courses often make varied syntax and semantic mistakes in writing SQL and NoSQL queries. We report on a study where we designed two styles of multiple-choice questions based on students' mistakes in midterms and used the questions in the final exam to assess student's capabilities in identifying and correcting other students' mistakes. The study found that (1) students had similar performance on both styles of the questions; (2) the average accuracy rate of students in peer correction was about 83%; (3) over 80% of the students thought it was helpful to see and correct others' mistakes; and (4) students' performance in peer correction was moderately correlated with their overall performance. This study is the first to address students' mistakes in writing NoSQL queries and assess peer correction of both SQL and NoSQL queries.", "Based on the current situation and requirements of urban smart tourism development, B/S architecture and database technology are used to build a city-oriented smart tourism management system from three aspects: system architecture, system functions and system implementation, in order to lay a solid foundation for urban tourism management intelligence and information. The basis for the comprehensive implementation of management. After operation, the system can meet the corresponding standards of smart tourism cities, integrate most tourism resources, and effectively promote the development of pilot cities' tourism informatization and urban tourism intelligence.", "This paper examines how to drive digital services with big data analytics. More specifically, it addresses why big data analytics matters digital services and what is the state of the art of digital services. It reviews big data analytics and presents a business processing flow approach to big data analytics. It explores big data analytics services as a digital service and proposes a question-oriented approach to driving digital services with big data analytics. The proposed approach in this paper might facilitate the research and development of big data, business analytics, e-business, e-services, digital services, and digital-society.", "Figure 1 : Design Process Overview. We investigated spent cofee grounds-a commonly wasted natural material-as a sustainable material for 3D printing (A). We experimented with diferent food-based binders and adjusted material composition to make the material self-supporting with hand-extrusion (B). We tuned 3D printing parameters for quality and reliability (C). We then explored how our material could enable sustainable prototyping workfows and creating objects like biodegradable espresso cups and planter pots (D).", "File systems that store metadata on a single machine or via a shared-disk abstraction face scalability challenges, especially in contexts demanding the management of billions of files. Recent work has shown that employing shared-nothing, distributed database system (DDBMS) for metadata storage can alleviate these scalability challenges without compromising on high availability guarantees. However, for low-scale deployments -where metadata can fit in memory on a single machine -these DDBMS-based systems typically perform an order of magnitude worse than systems that store metadata in memory on a single machine. This has limited the impact of these distributed database approaches, since they are only currently applicable to file systems of extreme scale.This paper describes FileScale, a three-tier architecture that incorporates a DDBMS as part of a comprehensive approach to file system metadata management. In contrast to previous approaches, FileScale performs comparably to the single-machine architecture at a small scale, while enabling linear scalability as the file system metadata increases 1 .", "With the continuous evolution of VR technology, VR devices have become more accessible to the general public. The immersive and realistic experience provided by VR makes the gaming domain a popular direction for its application. However, game development requires a strong ability to organize code effectively, whether for beginners or developers with years of experience in game companies. Design patterns, which are built upon object-oriented design principles, offer a software development approach that can effectively address these challenges. To this end, this paper takes our team's independently developed VR game -Knight's Adventureas an example. It covers various aspects from game introduction and requirement analysis to overall framework design. Furthermore, it provides detailed explanations of several typical design patterns employed in the game, demonstrating their implementation methods. This article elucidates the application of multiple design patterns in VR game development and offers solutions to common issues and requirements faced by game developers during practical development.", "Load balancing is essential for datacenter networks. However, prior solutions have significant limitations: they either are oblivious to congestion or involve a daunting and time-consuming parametertunning task over their heuristics for achieving good performance. Thus, we ask: is it possible to learn to balance datacenter traffic? While deep reinforcement learning (DRL) sounds like a good answer, we observe that it is too heavyweight due to the long decisionmaking latency. Therefore, we introduce BULB, a lightweight and automated datacenter load balancer. BULB learns link weights to guide the end-hosts to spread traffic, so as to free the central agent from quick flow-level decision-making. BULB offline trains a DRL agent for optimizing link weights but employs an imitation learning based approach to faithfully translate this agent's DNN to a decision tree for online deployment. We implement a BULB prototype with a popular machine learning framework and evaluate it extensively in ns-3. The results show that BULB achieves up to 36.6%/56.4%, 19.9%/42.5%, 35.9%/54.8%, and 45.1%/67.7% better average/tail flow completion time than ECMP, CONGA, LetFlow, and Hermes, respectively. Moreover, BULB reduces the decision latency by 175 times while incurring only 2% performance loss after converting the DNN into a decision tree.", "In a data center, deploying a microservice-based SaaS will result in a spike in energy usage, since the computation servers where the microservices are deployed will consume more energy as a result of an increase in computation workload. The data center's communications network will also consume more energy due to the increased communication among the microservices of the SaaS. Due to the fact that microservice-based SaaS deployment is handled by the developer of the microservice-based SaaS and can only be deployed on virtual machines rented by the developer, this issue cannot be taken into account in traditional microservice-based SaaS deployment methods. In this paper, a new microservice-based SaaS deployment method is proposed. The new approach relies on the data center determining where microservices should be deployed. The new microservice-based SaaS deployment method considers the energy increase in the computation servers and in the communication network. The microservice-based SaaS deployment problem is a combinatorial optimization problem. Thus, a genetic algorithm with repairing mechanism is proposed to solve the problem. Compared to traditional deployment approach, the proposed method is capable of reducing the energy consumption associated with microservicebased SaaS deployment by 37.55%.", "From the first website being created in 1991 by Tim Berners-Lee to this day in 2021, the world of websites and their development has seen a rapid evolution. Every business nowadays has a website to make its online presence in this digital age. Website use is not only limited to this, but many people use them to build their online portfolio, apart from that there are many web-based applications/software, etc. This research paper discusses the process involved in developing a website in past and present, development of content delivery over the years, the website uses, a website for mobile devices, and performance comparison between two of the most used web backend development technologies, i. e, Node.js and Python. For comparing performance, we have used Locust -an open-source software and Autocannon and tested both of them under similar conditions.", "Data privacy requirements are a complex and quickly evolving part of the data management domain. Especially in Healthcare (e.g., United States Health Insurance Portability and Accountability Act and Veterans Affairs requirements), there has been a strong emphasis on data privacy and protection. Data storage is governed by multiple sources of policy requirements, including internal policies and legal requirements imposed by external governing organizations. Within a database, a single value can be subject to multiple requirements on how long it must be preserved and when it must be irrecoverably destroyed. This often results in a complex set of overlapping and potentially conflicting policies. Existing storage systems are lacking sufficient support functionality for these critical and evolving rules, making compliance an underdeveloped aspect of data management. As a result, many organizations must implement manual ad-hoc solutions to ensure compliance. As long as organizations depend on manual approaches, there is an increased risk of non-compliance and threat to customer data privacy.In this paper, we detail and implement an automated comprehensive data management compliance framework facilitating retention and purging compliance within a database management system. This framework can be integrated into existing databases without requiring changes to existing business processes. Our proposed implementation uses SQL to set policies and automate compliance. We validate this framework on a Postgres database, and measure the factors that contribute to our reasonable performance overhead (13% in a simulated real-world workload).", "In order to get more effective information and improve the recognition accuracy, this paper proposes a speech emotion recognition model based on multi-feature fusion and deep convolutional neural network. First, the speech emotion data is preprocessed to obtain the two-dimensional three-channel fusion feature parameters, which are used as the input layer of the AlexNet DCNN model. Second, the model is improved. Batch normalization is added after each convolutional layer, and use genetic algorithm and simulated annealing algorithm to optimize the model. Final, we use SoftMax classifier to classify emotion. In this paper, the cross-validation method is used to evaluate the model, and it is verified on the EMO-DB and IEMO-CAP datasets. The experimental results verify that the method is superior to the existing speech emotion recognition technology.\u2022 Machine learning \u2192 Machine learning approaches; Neural networks.", "To process real-world datasets, modern data-parallel systems often require extremely large amounts of memory, which are both costly and energy inefficient. Emerging non-volatile memory (NVM) technologies offer high capacity compared to DRAM and low energy compared to SSDs. Hence, NVMs have the potential to fundamentally change the dichotomy between DRAM and durable storage in Big Data processing. However, most Big Data applications are written in managed languages and executed on top of a managed", "Recent technological and regulatory changes are paving the way to enable decentralized, zero-trust mobile network. Properly secured decentralization allows or improves \"inherently distributed\" use cases such as military coalition mobile networks distributed between allies or community-infrastructure networks. While zerotrust security has been flagged by the U.S. NIST as critical to modern networks, decentralized mobile network environment security threats have not been thoroughly studied and mostly focus on distributing only the Radio Access Network (RAN), potentially leading to unreliable Quality of Service (QoS) and low security in the network core. We therefore introduce dNextG, a mobile core network user plane that provides a zero-trust security monitoring framework to enable reliable decentralization even in the presence of malicious internal network nodes. With dNextG, both centralized and decentralized node operators can run User Plane Functions (UPFs) and Base Stations without giving up any node control; instead, nodes maintain a blockchain tracking node average reputation using tamper-resistant connectivity tests that they must periodically perform on each other. We identify various malicious node threats including dropping or modifying traffic and lying about reputation, then design, implement, and evaluate dNextG to overcome these threats and provide a long-term, reliable QoS. We provide an open-source, instantly replicable version of dNextG on POWDER (Platform for Open Wireless Data-driven Experimental Research).\u2022 Computer systems organization \u2192 Peer-to-peer architectures; Fault-tolerant network topologies; \u2022 Networks \u2192 Mobile and wireless security;", "Cluster managers play a crucial role in data centers by distributing workloads among infrastructure resources. Declarative Cluster Management (DCM) is a new cluster management architecture that enables users to express placement policies declaratively using SQL-like queries. This paper presents our experiences in scaling this architecture from moderate-sized enterprise clusters (10 2 -10 3 nodes) to hyperscale clusters (10 4 nodes) via query optimization techniques. First, we formally specify the syntax and semantics of DCM's declarative language, C-SQL, a SQL variant used to express constraint optimization problems. We showcase how constraints on the desired state of the cluster system can be succinctly represented as C-SQL programs, and how query optimization techniques like incremental view maintenance and predicate pushdown can enhance the execution of C-SQL programs. We evaluate the effectiveness of our optimizations through a case study of building Kubernetes schedulers using C-SQL. Our optimizations demonstrated an almost 3000\u00d7 speed up in database latency and reduced the size of optimization problems by as much as 1/300 of the original, without affecting the quality of the scheduling solutions.", "Unlike traditional 5G public network services, 5G vertical industry applications have highly customized requirements in terms of coverage, latency, reliability and transmission bandwidth, which differ greatly from traditional public 5G networks, making it difficult to adopt a unified 5G public network architecture and performance requirements. Light-weight 5G Core network can provide a good solution. This paper proposes a lightweight 5G private network architecture design scheme, incorporating Mobile Edge Computing(MEC) architecture on a user side to achieve flexible and mobile rapid deployment of 5G private networks, and proposes a lightweight access authentication process applicable to 5G private networks, reducing redundant processes and improving the overall performance of the system. Through experimental verification, it can effectively reduce the access delay and end-to-end transmission delay of terminals.CCS CONCEPTS\u2022Networks\u223cNetwork performance evaluation\u223cNetwork experimentation\u2022Networks\u223cNetwork architectures\u223cNetwork design principles\u2022Networks\u223cNetwork protocols\u223cCross-layer protocols", "Cybersecurity is an important part of national security. With the rapid development of Internet big data and network technology, national cybersecurity threats and potential cybersecurity crisis are prominent. Cybersecurity crisis management model and management countermeasures also need to launch adaptive innovation framework and strategic countermeasures with the development of the times. Therefore, based on referring to the international practice of cybersecurity crisis management, we construct the \"goal-stagedimension\" cybersecurity crisis management analysis framework and puts forward the cybersecurity crisis management path selection with national characteristics, which has important enlightenment and theoretical value to maintain national cybersecurity.", "SQL is a crucial language for managing relational database systems, and is an essential skill for individuals in roles such as researchers, developers, and business professionals who work with databases. However, learning SQL can be a challenge, presenting an opportunity to study the various methods students use to arrive at semantically equivalent SQL queries. In this study, we examined students' SQL submissions to homework assignments in the Database Systems course offered to upper-level undergraduate and graduate students at the University of Illinois Urbana-Champaign during the Fall 2022 semester. Our goal was to understand how students arrive at SQL solutions and overcome challenges in the learning process by building on prior research on line chart visualizations that instructors can use to increase visibility on students who are struggling. However, a major limitation of this approach was the difficulty for instructors to sift through a large number of visuals representing each student's performance on a SQL problem and generate action items at scale, especially when dealing with enrollments of over 700 students. To overcome this limitation, we developed a novel technique to generate textual representations of the student submission sequence using global sequence alignment scores and regular expression algorithms to further compact these submission sequences. This allows instructors to gain insights quickly, on an aggregate level, and in an automated manner, enabling them to identify students who may be struggling with SQL based on their submission sequence characteristics and take appropriate action to improve database education. Our study discovered common textual submission patterns and pattern elements, and we present our recommendations to instructors to improve database education based on these findings.", "The dynamic development of network services puts forward higher requirements for traditional information networks. In order to adapt to the development, the concept of \"reconfigurable network\" is proposed to improve the robustness and expansibility of network service support. However, the reconfiguration of the routing switching platform represented by the upgrading of the architecture hardware system will bring great cost pressure to users. In order to reduce the operation and maintenance cost of the network system and improve the reliability of the network system, the reconfiguration of the routing switching platform gradually transits and develops to the direction of retaining hardware equipment, upgrading software system and updating some equipment. In this paper, it analyses and design the security architecture of the open reconfigurable routing and switching platform to meet the demand for high speed, high capacity and high efficiency processing of network information, especially the demand for secure data transmission and exchange. For the prominent and critical security issues and matters in the reconfigurable routing and switching platform, the security reconfiguration method of platform components and components is constructed, and the system of components is analysed and modelled. Finally, the effectiveness and necessity of security techniques applied in the open reconfigurable routing and switching platform are verified.", "The Software-Defined Networking (SDN) paradigm empowers network operators to manage and coordinate network activities, allowing for greater flexibility and dynamic updating of switching tables. Over time, more and more service providers are integrating SDN into their core network infrastructure, recognizing the benefits of its robustness and adaptability. In the face of the rapid expansion of high-speed consumer Internet, data centers are increasingly migrating their internal networks to SDN-based backbones, which offer enhanced performance and scalability. SDN is widely projected to become the technology of the future, with many of the top Fortune 500 companies already implementing SDN in some form or another to meet their core network requirements. As a result, network devices, Internet service providers, content delivery networks, and data centers will increasingly be linked to high-performing SDNs and will communicate via them. The ubiquitous penetration of SDN-based networks, coupled with the multitude of user devices connected to them, is critical for the consumers of these services. However, like traditional networks, Software Defined networks are vulnerable to Denial of Service attacks, which target the availability of a service connected to the network. Thus, it is essential to develop effective strategies for identifying and mitigating such attacks to ensure the integrity and reliability of SDN-based networks.", "This paper aims to provide a systematic review of the published results on design optimization techniques in the area of compliant and soft robots, with a focus on the manufacturing processes, actuation methods and application areas. The goal of this work is to provide a comprehensive view and categorization of recent efforts using optimization for improving the design paradigms of such robot technologies, while focusing on the popular methods of topology optimization and generative design. In addition, this paper provides insights into the technical and technological trends that could potentially steer this area towards widespread adoption in domestic and industrial settings.", "", "Cyberspace has inflated over the past decade, primarily driven by pervasive development and widespread usage of the internet. Prolonged cyber-attacks and security vulnerabilities have become more common as a consequence. A recent study conducted by Ponemon Institute revealed that 64% of businesses have suffered web-based attacks in 2023. Thus, cybersecurity measures have become mandatory in every sector, that leverages technology, to protect confidential information from malignant threats. The majority of the sectors use conventional security measures like anti-virus products to defend their systems against outside attacks, however, these products fail to work on unseen and polymorphic threats. With cutting-edge deep learning (DL) processes getting adopted in nearly every field, it has been widely exploited in cybersecurity to detect and classify cyber-attacks. This study discusses the application of common deep learning models in cybersecurity to detect malware, intrusion, phishes, and spam. This study provides a description of deep learning models and their mathematical backgrounds that are common in cybersecurity. This study also reviews and analyses the work of other researchers who experimented with deep learning models in cybersecurity. This study delineates the challenges faced by deep learning models in cybersecurity. Finally, concluding remarks and future research directions are summarized to foresee the potential improvement of deep learning in cybersecurity.", "New details of the implementation of the data representation and editing component of the knowledge-based systems development platform is proposed in the paper. The two modes of considered component is described. The typical component structure along with the core to client component parts communication issues are presented. The main UI control elements are listed and grouped according to the criteria of the number of efforts that applied developers spend in the course of making UI. On the top of controls from the first group considered component provides user interface for data control component and implements unified user interface for any valid component of the platform. The second group is responsible for user interface of the platform as a whole and also for problem-oriented functions of the core components (for example, rule or workflow editors). The third group relies on a predefined set of parameterized typical database manipulations and supports the applied developer in the process of UI customization. The implementation of two techniques is considered on the case of the conceptual model design component extension.", "Integrating the internet of things (IoT) technology has played a crucial role in developing smart devices such as smartphones, automobiles, smart homes, and artificial intelligence. As a result, researchers have investigated IoT-based home security system development. This research aims to create a system that uses Raspberry Pi, a small computer board, and various sensors to detect intruders and notify users via the internet. The Python programming language and OpenCV library were used to develop the system, which uses a camera and PIR (Passive Infrared Sensor) to detect faces and motion, respectively. The proposed system is designed to monitor specific areas and can be implemented in future home security innovations. In addition, the system sends notifications to users via Line Notify, enabling developers to send messages to LINE users via an API, thereby enhancing the security of homeowners. Utilizing the capabilities of IoT technology, the results of this study are to develop a cost-effective and efficient home security solution.", "Building a sustainable datacenter requires coordinated decisions in its design and system management. Existing research work on datacenter sustainability often considers the design space in isolation and misses opportunities to minimize carbon footprint through coordinated design and management where sustainability is a first-class objective. Design decisions such as datacenter site selection, renewable energy investment portfolios, and the provisioning of energy storage are intertwined with complementary solutions for operation, including various forms of demand response and carbon-aware workload management. In this paper, we advocate for holistic frameworks that take into account both operational and embodied carbon to coordinate between datacenter design and system management decisions.", "Multiplex types of disciplines and complex stages are the characteristics of management of scientific research suppliers in Colleges and Universities. Therefore, the enterprise supplier management ideas can not be copied completely by it. All processes of scientific research supplier management in Colleges and Universities are mentioned in the article. It focuses on analysis of Characteristics and difficulties of scientific research supplier management in Colleges and Universities, and studies the application advantages of big data technology in the management and maintenance of University suppliers. Based on the research above, a software platform design of university scientific research supplier management system is proposed by applying big data technology in this article. This design not only establishes supplier database, but introduces big data technology to process Internet information in a direction to assist in updating the directory. Moreover, the management process of university scientific research suppliers is standardized, and the reliability of supplier list update is improved in the article.", "Typhoon is the most destructive marine disastrous weather system. The strong winds and waves, heavy rainfall and poor visibility caused by typhoon have a significant impact on marine activities. With the progress of science and technology, the theory and technical means of retrieving typhoon by satellite remote sensing have made great progress. This paper collects and compiles the data and products of multi-source full polarization microwave radiometer, studies and establishes the theory of typhoon retrieval by satellite remote sensing under high sea conditions (strong wind, rainstorm, huge waves, low visibility, etc.), verifies the algorithm, and analyses the retrieval accuracy of the algorithm under different wind speeds and different precipitation; The visual demonstration software of typhoon retrieval by satellite remote sensing is developed, which realizes the historical analysis and real-time monitoring of typhoons in the global sea area, and can provide new theoretical and technical means for typhoon ensuring CCS CONCEPTS", "In response to the application requirements of identifying and classifying multiple types of fibers, this paper proposes a fiber recognition algorithm based on improved Mask RCNN to achieve recognition and classification of multiple types of fibers, reduce the labor cost of fiber inspection, and improve inspection efficiency and quality. Firstly, a data augmentation strategy is adopted, which combines three data augmentation methods: RandomFlip, RandomCrop, and Cutout to achieve the best increase in network performance; Subsequently, a multi-scale training strategy is introduced to improve the model's training efficiency while also enhancing its robustness to scale; Finally, the attention mechanism module of convolutional blocks is added to solve the problem of low recognition and classification accuracy caused by small differences in fine-grained granularity between certain fiber classes. The experimental results show that the algorithm achieves a recognition and classification accuracy of 97.87% on the test set by introducing techniques such as data augmentation, multi-scale training, and CBAM, significantly improving the recognition and classification accuracy of various fiber targets.", "The rapid development of big data technology has transformed the business models of many Chinese enterprises to information. As a new type of production factor, data is gradually being valued by enterprises. Many companies have used big data technology to mine the potential value behind the data, and it has been widely used in the field of financial decision-making. Therefore, it is necessary to introduce big data technology into the financial decision-making process of enterprises, so as to organize and analyze relevant data onto enterprises in a timely and effective manner, so as to provide scientific and effective basis of enterprise decision-makers. This paper mainly adopts literature research method and interdisciplinary research method to deeply study the application process of big data technology in enterprise financial decision-making. This paper first illustrates the necessity of introducing big data technology into the financial decision-making process of enterprises. Then, the main methods and specific functions of big data technology in the process of enterprise financial decision-making to explain the role of big data technology in the process. Finally, the platform of enterprise financial decision-making is designed based on big data technology. This paper finds that the application of big data technology in the financial decision-making process of enterprises is mainly reflected in four aspects: first, data collection; Second, data storage; Third, financial analysis; Fourth, decision support. The introduction of big data technology into the financial decision-making process of enterprises is beneficial to broaden the channels of data collection and enrich the methods of financial analysis and decision-making, but also provides strong support for enterprises to make more accurate and effective financial decision-making schemes.", "To reduce the weight of a mechanical arm, 3D printing is gradually being applied to the field of robotics. A lightweight robotic arm indirectly reduces the torque required of the motor and reduces the overall cost and energy consumption of the robot. However, with 3D printing, there is no standard for choosing the filling density. A low filling density means fast printing, cost saving, and light weight. A high filling density results in superior bending strength and more perfect appearance. Compared with high-rigidity metals, resin is more easily affected by vibrations. To apply 3D printing technology to industrial robotic arms and other applications that require motion precision in future, we start with the influence of the filling density on the vibration characteristics, take the settling time required for the manipulator to return to rest after vibration as the criterion. The optimal filling density and the applicable occasions of different filling densities are discussed. According to the experimental results, printing with low filling density is preferred in applications that require less load or impact on the robotic arm such as chip manufacturing. For robotic arms that require high-load operations or high impact on the arm, high-fill-density printing is preferred.", "Cloud providers are adapting datacenter (DC) capacity to reduce carbon emissions. With hyperscale datacenters exceeding 100 MW individually, and in some grids exceeding 15% of power load, DC adaptation is large enough to harm power grid dynamics, increasing carbon emissions, power prices, or reduce grid reliability.To avoid harm, we explore coordination of DC capacity change varying scope in space and time. In space, coordination scope spans a single datacenter, a group of datacenters, and datacenters with the grid. In time, scope ranges from online to day-ahead. We also consider what DC and grid information is used (e.g. real-time and day-ahead average carbon, power price, and compute backlog). For example, in our proposed PlanShare scheme, each datacenter uses day-ahead information to create a capacity plan and shares it, allowing global grid optimization (over all loads, over entire day).We evaluate DC carbon emissions reduction. Results show that local coordination scope fails to reduce carbon emissions significantly (3.2%-5.4% reduction). Expanding coordination scope to a set of datacenters improves slightly (4.9%-7.3%). PlanShare, with grid-wide coordination and full-day capacity planning, performs the best. PlanShare reduces DC emissions by 11.6%-12.6%, 1.56x-1.26x better than the best local, online approach's results. PlanShare also achieves lower cost. We expect these advantages to increase as renewable generation in power grids increases. Further, a known full-day DC capacity plan provides a stable target for DC resource management.", "Aiming at overcoming the instability of the chain structure of the supply chain, the lack of flexibility and adaptability of the supply chain caused by the \"core enterprises\" in the chain, and such deficiency as easy occurrence of broken chain, etc., this Paper introduces the concept of Supply and Demand Network with multifunction and opening characteristics for enterprises (SDN). This Paper carries out the study on SDN cooperation subnet, build a model to depict the emergence of the SDN cooperation subnet from the perspective of the hierarchy. Based on the Kruskal algorithm and the Dijkstra algorithm respectively, studies on the optimization of all enterprises and individual enterprise are given, and the numerical examples are also presented. The model has a practical significance for guiding the enterprises in SDN cooperation subnet to carry out the cooperation target selection and global strategy optimization.", "Recently, subdomains of Human-Computer interaction (HCI), such as Tangible Interfaces and Haptics, have experienced disruptive hardware transformations owing to advances in Soft Robotics and Programmable Materials. How will these felds shape the future of HCI over the next decade and beyond? Unfortunately, the transfer of fundamental advances from basic science to end-user experiences can take years due to many interdisciplinary challenges. These include challenges related to fabrication methods, durability, tools, access to resources, and transfer of knowledge. How can we most efectively overcome such challenges, what opportunities exist to accelerate progress, and what application possibilities can we envision and contribute to the future? We aim for a comprehensive approach to soft robotics design and fabrication and concepts of future applications for their integration into daily life. This workshop invites to explore how programmable materials develop new streams of HCI at the intersection of technology, design, art, and innovation.", "The introduction of the Digital Twin (DT) has sparked a great deal of interest in the virtual replication of physical assets and processes. However, to fully realize the potential of DT, companies require robust and scalable front-end solutions. This study proposes harnessing micro-frontend technologies to surmount the limitations of monolithic front-end frameworks, thereby crafting effective presentation layers tailored for industrial companies. By decomposing complex and distributed systems into modular web-based DT, the proposed framework enables better scalability, synergy, and efficient application development. It also tackles the intricacies introduced by complex multi-vendor elements within DT and the orchestration of services and virtual environments. Research is focused on developing an architecture that facilitates seamless connectivity between multiple blocks of DT as well as interactivity and immersive experiences. Our study offers insights into our journey of implementing this framework for various industrial use cases, such as training, monitoring, and control, highlighting the benefits, drawbacks, and challenges. Ultimately, this research aims to accelerate the creation of DT, improve maintainability, and increase efficiency and productivity in industrial environments.", "For the last several years, all organisations from public and private sectors, that were somehow strategically oriented in learning advancement, had more experience in implementing some kind of Learning Management System (LMS). The identical education strategy required organisations to foresee not only how such LMS technology can be used for gaining benefits generating, but also what are the unexpected risks related to education cybersecurity. Secured educational data is among the educational institution's priorities and has the same impact on the improved educational development as the ROI, efficiency, and other financial indicators used to be analyzed how much the benefit and growth. This research aims to make an overview of the LMS, data and repositories, to identify education security risks in order to propose recommendations for education cybersecurity. The paper is structured as follows. Part one outlines the current trends in LMS development and how different organisations are using LMS. Part two is focused on LMS data and repositories based on LMS data available. Part three outlines the education data-related risks and cybersecurity-related issues. In order to prevent any risks related to education data, systems, and infrastructure, in the final part, proposals for education cybersecurity recommendations are given. In the conclusion, the contributions are outlined.CCS CONCEPTS \u2022Software and its", "Machine Learning (ML) techniques are employed to analyze and process big Remote Sensing (RS) data, and one wellknown ML technique is a Support Vector Machine (SVM). An SVM is a quadratic programming (QP) problem, and a D-Wave quantum annealer (D-Wave QA) promises to solve this QP problem more efficiently than a conventional computer. However, the D-Wave QA cannot solve directly the SVM due to its very few input qubits. Hence, we use a coreset (\"core of a dataset\") of given EO data for training an SVM on this small D-Wave QA. The coreset is a small, representative weighted subset of an original dataset, and any training models generate competitive classes by using the coreset in contrast to by using its original dataset. We measured the closeness between an original dataset and its coreset by employing a Kullback-Leibler (KL) divergence measure. Moreover, we trained the SVM on the coreset data by using both a D-Wave QA and a conventional method. We conclude that the coreset characterizes the original dataset with very small KL divergence measure. In addition, we present our KL divergence results for demonstrating the closeness between our original data and its coreset. As practical RS data, we use Hyperspectral Image (HSI) of Indian Pine, USA.", "Many database optimization problems, e.g., slow SQL diagnosis, database testing, optimizer tuning, require a large volume of SQL queries. Due to privacy issues, it is hard to obtain real SQL queries, and thus SQL generation is a very important task in database optimization. Existing SQL generation methods either randomly generate SQL queries or rely on human-crafted SQL templates to generate SQL queries, but they cannot meet various user speci c requirements, e.g., slow SQL queries, SQL queries with large result sizes. To address this problem, this paper studies the problem of constraintaware SQL generation, which, given a constraint (e.g., cardinality within [1k,2k]), generates SQL queries satisfying the constraint. This problem is rather challenging, because it is rather hard to capture the relationship from query constraint (e.g., cardinality and cost) to SQL queries and thus it is hard to guide a generation method to explore the SQL generation direction towards meeting the constraint. To address this challenge, we propose a reinforcement learning (RL) based framework LearnedSQLGen, for generating queries satisfying the constraint. LearnedSQLGen adopts an exploration-exploitation strategy that exploits the generation direction following the query constraint, which is learned from query execution feedback. We judiciously design the reward function in RL to guide the generation process accurately. We also integrate a nite-state machine in our model to generate valid SQL queries. Experimental results on three benchmarks showed that LearnedSQLGen signi cantly outperformed the baselines in terms of both accuracy (30% better) and e ciency (10-35\u00d7).", "Frequent and granular population data are essential for decision making. Further-more, for progress monitoring towards achieving the sustainable development goals (SDGs), data availability at global scales as well as at different disaggregated levels is required. The high population coverage of mobile cellular signals has been accelerating the generation of large-scale spatiotemporal data such as call detail record (CDR) data. This has enabled resource-scarce countries to collect digital footprints at scales and resolutions that would otherwise be impossible to achieve solely through traditional surveys. However, using such data requires multiple processes, algorithms, and considerable effort. This paper proposes a big data-analysis pipeline built exclusively on an open-source framework with our spatial enhancement library and a proposed open-source mobility analysis package called Mobipack. Mobipack consists of useful modules for mobility analysis, including data anonymization, origin-destination extraction, trip extraction, zone analysis, route interpolation, and a set of mobility indicators. Several implemented use cases are presented to demonstrate the advantages and usefulness of the proposed system. In addition, we explain how a large-scale data platform that requires efficient resource allocation can be con-structed for managing data as well as how it can be used and maintained in a sustainable manner. The platform can further help to enhance the capacity of CDR data analysis, which usually requires a specific skill set and is time-consuming to implement from scratch. The proposed system is suited for baseline processing and the effective handling of CDR data; thus, it allows for improved support and on-time preparation.", "Knowledge graphs (KGs) such as DBpedia, Freebase, YAGO, Wikidata, and NELL were constructed to store large-scale, real-world facts as \u27e8subject, predicate, object\u27e9 triples -that can also be modeled as a graph, where a node (a subject or an object) represents an entity with attributes, and a directed edge (a predicate) is a relationship between two entities. Querying KGs is critical in web search, question answering (QA), semantic search, personal assistants, fact checking, and recommendation. While significant progress has been made on KG construction and curation, thanks to deep learning recently we have seen a surge of research on KG querying and QA. The objectives of our survey are two-fold. First, research on KG querying has been conducted by several communities, such as databases, data mining, semantic web, machine learning, information retrieval, and natural language processing (NLP), with different focus and terminologies; and also in diverse topics ranging from graph databases, query languages, join algorithms, graph patterns matching, to more sophisticated KG embedding and natural language questions (NLQs). We aim at uniting different interdisciplinary topics and concepts that have been developed for KG querying. Second, many recent advances on KG and query embedding, multimodal KG, and KG-QA come from deep learning, IR, NLP, and computer vision domains. We identify important challenges of KG querying that received less attention by graph databases, and by the DB community in general, e.g., incomplete KG, semantic matching, multimodal data, and NLQs. We conclude by discussing interesting opportunities for the data management community, for instance, KG as a unified data model and vector-based query processing.", "In recent times, there has been a notable surge in the amount of vision and sensing/time-series data obtained from drones and satellites. This data can be utilized in various fields, such as precision agriculture, disaster management, environmental monitoring, and others. However, the analysis of such data poses significant challenges due to its complexity, heterogeneity, and scale. Furthermore, it is critical to identify anomalies and maintain/monitor the health of drones and satellite systems to enable the aforementioned applications and sciences. This workshop presents an excellent opportunity to explore solutions that specifically target the detection of anomalies and novel occurrences in drones and satellite systems and their data. For more information, visit our website at https://sites.google.com/view/ansd23.", "Growing air pollution has become a global threat to the environment. Controlling this global threat is very challenging and costly. Therefore, this paper proposes an air pollution control measure using green metrics (GMs). For doing this, we minimize the carbon emission from traditional data centers (DCs) by designing the 'Green Data Centers' (GDCs). GDCs are the control mechanism, which includes a set of different green protocols. GDCs are designed in such a way that they can minimize the carbon emission (i.e., CO CO CO, and CO2 CO2 CO2) from the traditional DCs. The design of GDCs is also responsible for optimizing energy consumption, cost-effectiveness, efficient network infrastructures, load scheduling algorithms, and the number of used devices like switches, ports, and linecards. GDCs are constructed by taking care of the idle server because it consumes massive energy than the computing server. This paper also presents a taxonomy of the existing research work, which contains the research of GDCs related to DCs, like cloud computing and cooling techniques. Apart from this, we discuss various green metrics (GMs), green computing, and networking proposals of GDCs.", "NoSQL is becoming an in-demand required skill for data engineers and developers. [2] notes that Internet of Things (IOT) applications require workers to have NOSql skills. In \"Why Amazon, Google, Netflix and Facebook Switched to NoSQL?\" [3] Dr. Brock answers the fore-mentioned question by highlighting that relational databases are no/t designed to support the gargantuan amount of unstructured data produced nor the exponential growth of such data whereas NoSql databases are designed to support such environments. According to [1], \"One could say that non-relational DB's are here to stay, and their popularity means that employers will be looking for those who are skilled in DBMS like it.\" Hence, to support our students we must teach them NoSQL.In this tutorial, I will share my experience in designing, developing, and teaching an elective in NoSQL. I will share both the challenges and rewards in the hopes that it encourages others to incorporate NoSQL into a course as well. A variety of resources to develop and teach four different types of NoSQL databases will be presented.This tutorial session will provide instructors with an introduction to NoSQL databases (non-relational databases). Participants will learn the basics of developing and implementing four types of NoSQL databases (namely, Document-Oriented, Key-Value Pair, Column-Oriented and Graph) as well as instructional approaches on teaching each within a course. This will be an active learning session with demonstrations and discussion activities.", "In recent years, the investigations on cyberphysical systems (CPS) have become increasingly popular in both academia and industry. A primary obstruction against the booming deployment of CPS applications lies in how to process and manage large amounts of generated data for decision making. To tackle this predicament, researchers advocate the idea of coupling edge computing, or edge-cloud computing into the design of CPS. However, this coupling process raises a diversity of challenges to the quality-of-services (QoS) of CPS applications. In this article, we present a survey on edge computing or edge-cloud computing assisted CPS designs from the QoS optimization perspective. We first discuss critical challenges in service latency, energy consumption, security, privacy, and reliability during the integration of CPS with edge computing or edge-cloud computing. Afterwards, we give an overview on the state-of-the-art works tackling different challenges for QoS optimization, and present a systematic classification during outlining literature for highlighting their similarities and differences. We finally summarize the experiences learned from surveyed works and envision future research directions on edge computing or edge-cloud computing assisted CPS optimization.", "5G suffers from new security and privacy issues. More specifically, distributed denial-of-service (DDoS) is one of the most common and destructive attack types. The traditional network does not perform well, because they do not quickly support the deployment of new service function as well as provide network security service on demand. Recently, with the rise of Reinforcement Learning (RL), Software Defined Network (SDN)/Network Functions Virtualization (NFV), and Interface to Network Security Functions (I2NSF) techniques, they play a significant role in security enhancement. Hence, we propose a framework to integrate RL with SDN/NFV and I2NSF architecture (RL-SDNV), in which the RL agent can intelligently select suitable security function chain (SFC) under attack scenarios. Then, we model the DDoS detection problem as a Markov Decision Process (MDP), and a QLearning detection algorithm (QLSFC) is proposed, in which the designed reward includes the processing time and the malicious traffic reduction rate. Finally, we build a corresponding prototype system and verify the feasibility and effectiveness of the proposed algorithm through compared experiments with other RL algorithms.", "The paper presents and compares the data mining techniques for selection of the diagnostic features in the problem of blood cell recognition in leukemia. Different techniques are compared, including the linear SVM ranking, correlation and statistical analysis of centers and variances of clusters corresponding to different classes. We have applied radial kernel SVM as the classifier. The results of recognition of 10 classes of cells are presented and discussed.", "The satellite-based ADS-B system is an important realization of efficient aviation management in the future. However, the phased array antenna of the satellite payload is prone to multi-channel amplitudephase mismatch in the variable environment. In this study, the optimal beam distribution is designed and simulated by establishing a signal reception probability detection model. In the signal demodulation part, the LMS-based amplitude-phase mismatch calibration technique is proposed to address the shortcomings of the traditional amplitude-phase mismatch calibration method that needs to be recalibrated every time the system is turned on and the calibration accuracy is not high. The simulation results show that the method can effectively calibrate the amplitude-phase mismatch phenomenon, and the error is less than the accuracy requirement, which has obvious application advantages over the traditional method.", "The paper focuses on a new type of interactive learning content for SQL programming -worked examples of SQL code. While worked examples are popular in learning programming, their application for learning SQL is limited. Using a novel tool for presenting interactive worked examples, Database Query Analyzer (DBQA), we performed a large-scale randomized controlled study assessing the value of worked examples as a new type of practice content in a database course. We report the results of the classroom study examining the usage and the impact of DBQA. Among other aspects, we explored the effect of textual step explanations provided by DBQA.", "Internet-of-things is one of the prominent communication technologies in the 21st century. We can connect everyday objects, like baby monitors, thermostats, e-health, etc., Connecting IoT with Software-defined networking is the best approach to security provisioning during network communication. Because the enormous features of SDN are programmable and centralized management, attackers can create multiple security vulnerabilities in SDN that redeem the distributed denial-of-service attack. This security breach causes bandwidth depletion and server resource impoverishment and perplexes benign users. This study proposes and builds a DDoS attack detection and mitigation defense system for SDN to address this issue. Two different defense modules are deployed in the SDN controller: suspicious identification, and mitigation of the malicious traffic flow. The first module of the SDN defense system used for detecting malignant traffic from DDoS attacks which works under a CNN-ELM is an integrated deep learning approach that combines a convolutional neural network with an extreme learning machine. The suspicious flows are identified, whether benign or malignant, by using a hybrid CCN-ELM model, and this process improves the accuracy of the attack detection. The second module of the mitigation strategy identifies the attacker's location by using IP traceback and removes that malicious traffic by transmitting the flow rule from the controller. These two SDN defense modules are evaluated by simulation processes. Finally, the experimental results of the SDN defense system, precisely detect the DDoS attack with an accuracy of 99.85% and efficiently mitigate the malicious traffic flow in real-time.", "Context: API is important in daily programming activities during app development, but finding appropriate APIs is time-consuming for developers. To simplify this process, many researchers pay attention to overcoming the task-API knowledge gap using semantic information mined from the large-scale dataset for API recommendation. However, only semantic information is not enough since API descriptions and developers' query may not share similar words, meanwhile, large-scale data mining brings high costs. These limit the efficiency of existing API recommendation methods. Objective: In this work, we aim at proposing a lightweight API recommendation method based on small-scale data with low costs, so that everyone can use it obtain appropriate API knowledge for supporting their development tasks. Method: We model API recommendation as a multiobjective optimization problem by considering both structural and semantic information of APIs, and use the genetic algorithm to gain optimal solutions for overcoming the limitations of the small-scale dataset. Specially, we extract the structural and semantic information of APIs from APK files and API descriptions with graph embedding and NLP techniques respectively. Then, we get the recommended APIs satisfying structural and semantic objectives according to the developers' target functionality with a genetic algorithm. Finally, we give the usage scenarios of our recommendation information and the guideline of our approach to help developers understand and use our method easily. Results and Conclusion: We conduct a series of experiments based on apps in Google Play, API descriptions in Android Tutorial and Q&As in Stack Overflow. The results show that Precision@N of our recommendation can be up to 0.89, MAP@N is up to 0.50, and MRR reaches 0.69, and our method achieves such good performance only utilizing less than 1/10 of the project number of our compared machine learning method with less time and lower device requirement. Besides, we conduct a survey and most of the participants confirm the understandability and usability of our recommended APIs in practice.", "In 2022, over half of the web traffic was accessed through mobile devices. By reducing the energy consumption of mobile web apps, we can not only extend the battery life of our devices, but also make a significant contribution to energy conservation efforts. For example, if we could save only 5% of the energy used by web apps, we estimate that it would be enough to shut down one of the nuclear reactors in Fukushima. This paper presents a comprehensive overview of energy-saving experiments and related approaches for mobile web apps, relevant for researchers and practitioners. To achieve this objective, we conducted a systematic literature review and identified 44 primary studies for inclusion. Through the mapping and analysis of scientific papers, this work contributes: (1) an overview of the energy-draining aspects of mobile web apps, (2) a comprehensive description of the methodology used for the energy-saving experiments, and (3) a categorization and synthesis of various energy-saving approaches.", "As the network is more and more important in people's life, network security has become very important. In the face of a large number of network attacks, we need a network security defense decision support technology, which can quickly and accurately complete the judgment of network defense in a tense environment. Current researchers focus on the improvement and promotion of dynamic defense technology in the field of network security dynamic defense, and fail to consider how to maximize the role of \"changing the rules\" in the defense system from the overall perspective. Therefore, this paper establishes a dynamic and static fusion of network security defense system, sets the evaluation index, puts forward the construction method of network defense decision-making model, and uses DDoS attack as an example to simulate, show the specific evaluation decision-making process. The simulation results show that the model can accurately assist people to make network defense decisions, and provide a new layer of protection for network security defense.", "Network Function Virtualization (NFV) platforms consume significant energy, introducing high operational costs in edge and data centers. This paper presents a novel framework called GreenNFV that optimizes resource usage for network function chains using deep reinforcement learning. GreenNFV optimizes resource parameters such as CPU sharing ratio, CPU frequency scaling, last-level cache (LLC) allocation, DMA buffer size, and packet batch size. GreenNFV learns the resource scheduling model from the benchmark experiments and takes Service Level Agreements (SLAs) into account to optimize resource usage models based on the different throughput and energy consumption requirements. Our evaluation shows that GreenNFV models achieve high transfer throughput and low energy consumption while satisfying various SLA constraints. Specifically, GreenNFV with Throughput SLA can achieve 4.4\u00d7 higher throughput and 1.5\u00d7 better energy efficiency over the baseline settings, whereas GreenNFV with Energy SLA can achieve 3\u00d7 higher throughput while reducing energy consumption by 50%.", "Machine learning and deep learning models are commonly developed using programming languages such as Python, C++, or R and deployed as web apps delivered from a back-end server or as mobile apps installed from an app store. However, recently front-end technologies and JavaScript libraries, such as TensorFlow.js, have been introduced to make machine learning more accessible to researchers and end-users. Using JavaScript, TensorFlow.js can define, train, and run new or existing, pre-trained machine learning models entirely in the browser from the client-side, which improves the user experience through interaction while preserving privacy. Deep learning models deployed on front-end browsers must be small, have fast inference, and ideally be interactive in real-time. Therefore, the emphasis on development and deployment is different. This paper aims to review the development and deployment of these deep-learning web apps to raise awareness of the recent advancements and encourage more researchers to take advantage of this technology for their own work. First, the rationale behind the deployment stack (front-end, JavaScript, and TensorFlow.js) is discussed. Then, the development approach for obtaining deep learning models that are optimized and suitable for front-end deployment is then described. The article also provides current web applications divided into seven categories to show deep learning potential on the front end. These include web apps for deep learning playground, pose detection and gesture tracking, music and art creation, expression detection and facial recognition, video segmentation, image and signal analysis, healthcare diagnosis, recognition, and identification.", "At present, the phase monitoring method of optical fiber sensor signal cannot meet the practical application requirements of optical fiber communication. This paper proposes an optical fiber sensor signal monitoring system based on FPGA to solve the problems such as the phase adjustment accuracy of optical fiber sensor. This system takes FPGA BQR7VX690T as the core master, and uses FFT to transform the spatial frequency domain signal of the signal, so as to achieve the sampling signal processing in the frequency domain. Aiming at the phase difference of different optical fiber signals, this paper designs CORDIC algorithm to realize the frequency domain data processing. It can realize the parallel processing of four groups of signals within 1ms of system processing time, identify the phase difference of signals of 1 \u00b0and above, and make the phase difference of output signals within 1 \u00b0, so as to achieve the effect of real-time and rapid correction of signals. The system uses DDR3 controller IP to realize DDR3 read/write control, and obtains the corrected signal in the time domain for the signal buffer delay, and communicates with the host computer through the serial port, so as to achieve the final system optical fiber sampling data waveform display phase adjustment.", "In modern automobiles, the reliance on vehicle Controller Area Network (CAN) networks has surged, underlining the paramount significance of safeguarding these networks against intrusions. In this work, we unveil an innovative approach for intrusion detection and explanation within in-vehicle CAN networks, employing the formidable synergy of Extreme Gradient Boosting (XGBoost) and SHapley Additive exPlanations (SHAP). Our method is tailored to address network imbalance challenges, offering prowess in binary and multiclass classification tasks. Integral to our approach is the seamless integration of SHAP values, serving as illuminating guides that unravel the intricacies of detected intrusions. This fusion elevates the system's interpretability, equipping stakeholders with deeper insights. Our contribution is underpinned by a rigorous evaluation of our approach, featuring a comprehensive analysis of a published dataset alongside comparisons with established literature. The results underscore the exceptional efficacy of our method, showcasing its remarkable accuracy in detecting intrusions. However, the essence of our methodology transcends mere detection precision. The explanatory capabilities of SHAP values come to the forefront. This augments both understanding and decision-making into the contributing factors behind the detected intrusion classification model.", "We are currently in the big data era. The Metaverse is an upcoming technology that combines big data, virtual reality (VR), augmented reality (AR), artificial intelligence (AI), and other technologies to reduce the gap between online and offline contact. It wants to be a place where we may work, travel, communicate, shop, play, and mingling. When a person joins the Metaverse, they all engage with the virtual environment in some way using data. Data will continue to increase as the Metaverse is developed and used, creating a big data network that will put a tremendous amount of pressure on the digital world's process data ability. Therefore, one of the crucial technologies to construct the Metaverse is large data processing technology. In this study, we thoroughly analyze how Metaverse is transforming large data. Furthermore, we go into great length about the important security and privacy of Metaverse large data. Finally, we provide a summary of the Metaverse's current challenges and potential as well as its prospects for using big data. With this survey, we hope to give researchers ideas for future research and the potential of using big data in the Metaverse.", "The management and control of heterogeneous IoT devices in cyber-physical systems (CPS) involves ensuring authorized access to cloud-stored data, including instructions, commands, and configuration settings, and issuing them securely to IoT devices for remote execution. Existing access management techniques present various security challenges in ensuring fine-grained access control to sensitive data present on untrusted cloud servers. These challenges are further complicated by the need to dynamically evaluate contextual parameters linked to IoT devices before issuing instructions. This work proposes a secure and context-aware encryption technique for remote access control of IoT devices. Leveraging ciphertext-policy attribute-based encryption (CP-ABE), the scheme encrypts instructions, requiring the user's decryption key to satisfy embedded access policies for access. The integration of access policies considers both user attributes and dynamic parameters associated with IoT devices, ensuring a comprehensive evaluation before access is granted. To verify the dynamic parameters, fogbased servers are employed, positioned in proximity to IoT devices for efficient and real-time assessment. The scheme introduces a two-phase decryption process, involving fog servers in generating key components based on the verified dynamic parameters (of IoT devices) that are combined with the user's existing key to ensure secure partial decryption. Final decryption is performed by the user who securely sends instructions for execution on the IoT devices. Our proposed cryptosystem security and computational complexity analysis demonstrate the scheme's effectiveness in achieving secure and context-aware IoT device access in dynamic CPS environments, ensuring efficient control, monitoring, and automation while preserving data privacy.", "As the cybersecurity situation continues to get tougher, more and more attackers are beginning to place their attention on power system networks, and the struggle between various countries is shifting from the real world to cyberspace. Power system network security protection is crucial. Humans have become inseparable from electricity, so it is vital to ensure power security. Whether for political or war purposes, many attacks related to power systems have occurred throughout history, resulting in extremely serious consequences and extremely high property damage. And power systems require special protection due to their high speed, high energy, and high-risk characteristics. In this paper, we analyze past network attacks on electric power systems, summarize common network attacks, analyze common network security protection means in the industry, dig into the progress of network security protection research on the electric power system, explore how traditional network security protection means including firewall, antivirus software, intrusion detection, and honeypot technology are applied on the electric power system.", "With the rapid development of network and information technology, various types of network attacks have brought more and more serious threats to the network security of nuclear power plants. The conventional network security situational awareness system can no longer meet the network security requirements of nuclear power plants. When processing multi-user requests, the user response delay is high, and the network security situational awareness performance is poor. In this paper, a nuclear power plant network security situational awareness platform model is designed. First, the network security situational awareness platform model architecture and its functional modules are described, then the key technologies of the model application are studied, and finally the model is tested experimentally. The experimental results show that the designed network security situational awareness platform model has short response time and good performance, which meets the needs of network security protection of nuclear power plants.", "Figure 1: System diagram. Users can deploy their custom optimization algorithm and carry out real-time evaluations.", "Cybersecurity has emerged as one of the most crucial facets of the Internet of Things (IoT) due to the increased possibility of cyberattacks. IoT cybersecurity aims to lower cybersecurity risk for businesses and users by safeguarding IoT resources and privacy. IoT security management could be improved by using new cybersecurity technology and solutions. However, efficient IoT cyber risk management frameworks are lacking for organizations. This paper presents the most significant proposals of cybersecurity in IoT by describing their objectives, working principles, applications, features, and approaches referred. The paper also presents cybersecurity in IoT using five optimization algorithms such as particle swarm optimization, ant colony optimizations, an artificial bee colony, genetic algorithm, and AdaBoost algorithm. The paper concludes with research gaps and limitations, which urge for further study for subsequent research work.", "Although dominant for tabular data, ML libraries that train tree models over normalized databases (e.g., LightGBM, XGBoost) require the data to be denormalized as a single table, materialized, and exported. This process is not scalable, slow, and poses security risks. In-DB ML aims to train models within DBMSes to avoid data movement and provide data governance. Rather than modify a DBMS to support In-DB ML, is it possible to o er competitive tree training performance to specialized ML libraries...with only SQL?We present JoinBoost, a Python library that rewrites tree training algorithms over normalized databases into pure SQL. It is portable to any DBMS, o ers performance competitive with specialized ML libraries, and scales with the underlying DBMS capabilities. JoinBoost extends prior work from both algorithmic and systems perspectives. Algorithmically, we support factorized gradient boosting, by updating the variable to the residual in the non-materialized join result. Although this view update problem is generally ambiguous, we identify addition-to-multiplication preserving, the key property of variance semi-ring to support , the most widely used criterion. System-wise, we identify residual updates as a performance bottleneck. Such overhead can be natively minimized on columnar DBMSes by creating a new column of residual values and adding it as a projection. We validate this with two implementations on DuckDB, with no or minimal modi cations to its internals for portability. Our experiment shows that JoinBoost is 3\u00d7 (1.1\u00d7) faster for random forests (gradient boosting) compared to LightGBM, and over an order of magnitude faster than state-ofthe-art In-DB ML systems. Further, JoinBoost scales well beyond LightGBM in terms of the # features, DB size (TPC-DS SF=1000), and join graph complexity (galaxy schemas).", "With advances in network capabilities, the gaming industry is increasingly turning towards offering \"gaming on demand\" solutions, with cloud gaming services such as Sony PlayStation Now, Google Stadia, and NVIDIA GeForce NOW expanding their market offerings. Similar to adaptive video streaming services, cloud gaming services typically adapt the quality of game streams (e.g., bitrate, resolution, frame rate) in accordance with current network conditions. To select the most appropriate video encoding parameters given certain conditions, it is important to understand their impact on Quality of Experience (QoE). On the other hand, network operators are interested in understanding the relationships between parameters measurable in the network and cloud gaming QoE, to be able to invoke QoE-aware network management mechanisms. To encourage developments in these areas, comprehensive datasets are crucial, including both network and application layer data. This paper presents CGD, a dataset consisting of 600 game streaming sessions corresponding to 10 games of different genres being played and streamed using the following encoding parameters: bitrate (5, 10, 20 Mbps), resolution (720p, 1080p), and frame rate (30, 60 fps). For every combination repeated five times for each game, the dataset includes: 1) gameplay video recordings, 2) network traffic traces, 3) user input logs (mouse and keyboard), and 4) streaming performance logs.", "Resumen. La investigaci\u00f3n existente acerca del desarrollo de MOOCs, presenta diferentes \u00e1reas de investigaci\u00f3n; desde an\u00e1lisis de datos, objetos de aprendizaje, an\u00e1lisis de videos, etc. Poca literatura existe acerca de los primeros pasos que se deben ejecutar para la creaci\u00f3n de un MOOC, de igual manera no existen consideraciones b\u00e1sicas con respecto a los tipos de videos a desarrollar para cubrir diversos temas ni tampoco se hace menci\u00f3n a los errores t\u00edpicos que se cometen. La experiencia en la generaci\u00f3n de MOOCs desde sus inicios en el 2012 hasta la", "The metaverse has become a topic of interest in both industry and academic settings. Research and development that focus on the 'metaverse' explore the immersive future of the internet, where distributed people from around the world can connect through virtual social environments. Unsurprisingly, the term has gained traction in the digital gaming realm as many related games and play research topics directly contribute to the metaverse. We propose to host a panel at CHI PLAY 2022 which will facilitate discussion amongst researchers in the field regarding the current landscape of the metaverse in game research, and opportunities and challenges to propel the future evolution of research in this area.", "Despite being treatable, tuberculosis (TB) remains among the most common causes of death worldwide. One of the countries with the highestburden from TB is Vietnam. A major factor responsible for the high mortality rate is nonadherence to medication and the subsequent outbreak of multidrug-resistant forms of TB, which are harder to treat and show a lower chance of survival. Existing measures to increase medication adherence focus on monitoring medication intake without considering the reasons for nonadherence -the stigmatization of TB patients. Addressing this problem, we design a concept for a patient-centered, gamified application aiming to reduce stigmatization and empower TB patients. Based on a literature review and interviews with experts from science and practice, including former TB patients, we elaborate on the functionalities and gamified elements of the application. Eventually, we present the design concept for the application based on Lui et al.'s framework for designing a gamified information system.", "Machine Learning-based Intrusion Detection Systems have been proven to be very effective in the protection of IoT Networks. However, the expansion of Adversarial Machine Learning attacks threatens their efficacy affecting also the security of IoT networks. Thus, this paper proposes a Machine Learning-driven methodology for multiclass classification of cyber-attacks in IoT networks and investigates the robustness of the Machine and Deep Learning classifiers against several well-known Adversarial Machine Learning attacks (JSMA, FGSM, DeepFool). Moreover, the effectiveness of the Adversarial Training defense method has been studied in tackling Adversarial Machine Learning attacks. The proposed methodology was evaluated using a new and large IoT dataset (IoTID20) and the experimental results concluded that the Random Forest classifier can classify the cyber-attacks with high classification accuracy (99.9%) as well as the JSMA, FGSM, and DeepFool attacks can significantly reduce the performance of all the classifiers. Finally, based on the evaluation adversarial training can overall enhance the classifiers' robustness against all the utilized Adversarial Machine Learning attacks without affecting the performance when only normal samples are present.", "Quantum computers are capable of performing large-scale calculations in a shorter time than conventional classical computers. Because quantum computers are realized in microscopic physical systems, unintended change in the quantum state is unavoidable due to interaction between environment, and it would lead to error in computation. Therefore, quantum error correction is needed to detect and correct errors that have occurred.In this paper, we propose quantum computer architecture for quantum error correction by taking account that the components of a quantum computer with quantum dots in silicon are divided into multiple temperature layers inside and outside the dilution refrigerator. Analog signals to control the qubits are precisely generated on a 4 K stage inside the dilution refrigerator, while real-time digital processing is performed outside the dilution refrigerator. We then experimentally demonstrate the digital control sequence for quantum error correction combined with a simulator which simulates quantum states during quantum computation. The real time processing including determination of feed-forward operation and transmission of feed-forward operation command is carried out by an FPGA outside the dilution refrigerator within 0.01 ms for bit-flip error correction. This is a sufficiently short time compared to the assumed relaxation time, which is the approximate time that the quantum state can be preserved, meaning that our proposed architecture is applicable to quantum error correction.", "Indoor cellular networks (ICNs) are anticipated to become a principal component of 5G and beyond systems. ICNs aim at extending network coverage and enhancing users' quality of service and experience, consequently producing a substantial volume of traffic in the coming years. Despite the increasing importance that ICNs will have in cellular deployments, there is nowadays little understanding of the type of traffic demands that they serve. Our work contributes to closing that gap, by providing a first characterization of the usage of mobile services across more than 4, 500 cellular antennas deployed at over 1, 000 indoor locations in a whole country. Our analysis reveals that ICNs inherently manifest a limited set of mobile application utilization profiles, which are not present in conventional outdoor macro base stations (BSs). We interpret the indoor traffic profiles via explainable machine learning techniques, and show how they are correlated to the indoor environment. Our findings show how indoor cellular demands are strongly dependent on the nature of the deployment location, which allows anticipating the type of demands that indoor 5G networks will have to serve and paves the way for their efficient planning and dimensioning.", "This paper presents NoSQL Over SQL Block as a Value Database (NOSD), a system that speeds up data retrieval time and availability in very large relational databases. NOSD proposes a Block as a Value model (BaaV). Unlike a relational database model where a relation is R(K, A1, A2, ...An), with a key attribute K and a set of attributes of the relation: A1, A2, ...An, BaaV represents a relation R(K, r1, r2, ...rn) with a key attribute K and a set of n relations called blocks. Each r contains a set of its own attributes denoted as r(k, a1, a2, ...an) with a key attribute k and a set of n attributes. The relations r1, r2, ...rn in R are related through foreign key relationships to a super relation R with primary key K. The BaaV model is then denoted in a keyed block format R{K, B}, where K is a key to a block of values B of partial relations implemented on NoSQL databases and replicating existing large relational database systems. As opposed to conventional systems such as Zidian, Google's Spanner, SparkSQL and Simple Buttom-Up (SBU) which implement SQL over NoSQL and replicate data into different nodes, NOSD implements NoSQL over SQL and uses Lucene functionality on NoSQL to enhance data retrieval costs. Experimenting with our proposed model, we demonstrated the performance of NOSD under the following conditions to prove its novelty (a) scan free queries, and (b) bounded queries on NoSQL databases. We showed that NOSD (a) performs excellently than ordinary relational databases (b) guarantees no scans for no scan queries (c) allows parallelization in query execution, and (d) can be deployed into existing SQL databases with guaranteed horizontal scalability, data retention and accurate autonomous data replication. Using existing benchmark systems, we demonstrated that NOSD outperforms existing SQL databases, SQL over NoSQL systems and is novel in ensuring that existing large SQL database systems utilize the functionalities of NoSQL databases without data loss.", "The numerical simulation of quantum circuits is an indispensable tool for development, verification, and validation of hybrid quantum-classical algorithms intended for near-term quantum co-processors. The emergence of exascale high-performance computing (HPC) platforms presents new opportunities for pushing the boundaries of quantum circuit simulation. We present a modernized version of the Tensor Network Quantum Virtual Machine (TNQVM) that serves as the quantum circuit simulation backend in the eXtreme-scale ACCelerator (XACC) framework. The new version is based on the scalable tensor network processing library ExaTN (Exascale Tensor Networks). It provides multiple configurable quantum circuit simulators that perform either an exact quantum circuit simulation via the full tensor network contraction or an approximate simulation via a suitably chosen tensor factorization scheme. Upon necessity, stochastic noise modeling from real quantum processors is incorporated into the simulations by modeling quantum channels with Kraus", "Choosing which database to use is one of the most important decisions an organization needs to make when working on a new microservice. When deciding on a modern database, one of the biggest decisions is to select the correct type of (relational or nonrelational) database. Organizations make this decision based on the application scenario before the development starts. However, sometimes due to the changes in requirements, developers need to switch between database systems after the development starts. Switching between database systems can be a tedious and time-consuming task. In this study, we propose a tool that will automate the process of schema and data migration from MongoDB to MySQL database. The tool has been developed using Python programming language and gives users the ability to convert the database structures while maintaining the relationships between the data fashion accurately and consistently.", "Data center schedulers must make complex tradeoffs and optimizations to achieve their scalability and high-quality scheduling goals. Scalability refers to the scheduler's ability to support both the increasing scale of the workloads (in terms of arrival rate and resource demand) and the infrastructure required by these workloads. Scheduling quality refers to the scheduler's ability to meet the user's performance requirements (such as latency guarantees and placement constraints) without compromising the data center's resource utilization.We propose two solutions to achieve scalability and highquality scheduling. The first is Megha, a decentralized, federated scheduling framework that uses an eventually-consistent global state to make fast, high-quality scheduling decisions for data centers with tens of thousands of nodes. The second is an intra-node scheduling technique called Niyama, which provides robust CPU bandwidth isolation to latency-sensitive tasksprotecting them from interference from co-located tasks. The two frameworks have been evaluated using workloads generated from publicly available cluster traces, and the results show significant improvements over existing state-of-the-art solutions.", "This paper presents an image encryption algorithm based on cellular automata and chaotic systems. The basic unit of cellular automata is a single cell. Cellular automata evolve based on the rules of evolution by combining the states of cells and their neighbors. Cellular automata can evolve complex behavior states. Using the random sequence of the hyperchaotic system, the random sequence is mapped to the cell value, and the cell is randomly replaced in the process of image scrambling. This method greatly improves the parallelism of the algorithm. Through the analysis of the experimental results and security of the encryption algorithm, it is found that the method has a sufficient anti-attack ability. Therefore, it is very suitable for application in the actual system.", "Backend database systems have been proposed as a solution to the problems of overloaded data processing installations. This tutorial examines backend database systems in terms of their basic structure, their potential benefits and drawbacks, and the problems facing developers of such systems. Several prototype systems are described, and research on extensions of the backend concept is discussed. The structure of the hardware and software components of backend database systems is presented in detail. The performance problems encountered in recent prototypes are pointed out and potential solutions indicated.", "With the rapid expansion of network scale and the increasing diversity of network applications, traditional network architectures have often struggled to meet the high demands for performance, reliability, and flexibility. To address these challenges, this paper proposes a network architecture that leverages an improved MPLS protocol in combination with SDN technology. The integration of MPLS protocol, a widely used routing protocol, enables fast and efficient traffic forwarding. MPLS labels are attached to packets, allowing them to be quickly forwarded through the network without the need for complex routing calculations. This ensures high-quality service delivery and reduces latency, crucial for real-time applications such as voice and video conferencing. SDN technology, on the other hand, enables centralized control and flexible network management. SDN separates the control plane from the data plane, allowing network administrators to programmatically control network behavior. This provides greater operational efficiency as changes can be made quickly and easily without having to manually configure individual devices. SDN also enables scalability as new devices can be easily integrated into the network without disrupting existing operations. By effectively combining MPLS protocol and SDN technology, we can create a high-performance, highly reliable, and flexible network architecture that meets the modern networking requirements. This architecture not only enhances network efficiency but also reduces operational costs, making it an attractive solution for tomorrow's networking needs.", "Smart contracts written in Solidity are programs used in blockchain networks, such as Etherium, for performing transactions. However, as with any piece of software, they are prone to errors and may present vulnerabilities, which malicious attackers could then use. This paper proposes a solidity frontend for the efficient SMT-based context-bounded model checker (ESBMC), named ESBMC-Solidity, which provides a way of verifying such contracts with its framework. A benchmark suite with vulnerable smart contracts was also developed for evaluation and comparison with other verification tools. The experiments performed here showed that ESBMC-Solidity detected all vulnerabilities, was the fastest tool and provided a counterexample for each benchmark. A demonstration is available at https://youtu.be/3UH8_1QAVN0.", "Modern enterprise systems allow users to access the network and associated applications remotely while being mobile. Internet Service Providers (ISPs) support this access through mobile networks. Public mobile networks from ISPs that target consumers might not provide adequate guarantees or support mission-critical services. This can lead to reduced productivity for the enterprises. A non-public mobile network with assured SLAs is an efficient way to solve this problem. However, identifying the most economical deployment of such networks satisfying the security requirements is very challenging. This work proposes a security framework to identify the optimal deployment strategy for enterprises.", "Communication trends demand services that require flexible multicast transmission with requirements for data processing functions at the network nodes. This challenge is achieved with softwaredefined networking (SDN) and network functions virtualization (NFV) technologies. In the multicast routing problem in NFV-SDN networks, the goal is to compute a multicast tree and the location of virtual network functions (VNFs) at nodes, satisfying the traffic demand and processing functions with the least possible resource. The traffic flow must pass through a VNF node before reaching a destination node. Since the problem has high computational complexity and current proposals consider only one type of virtual function in all demands, the development of scalable solutions for multiple sessions with different virtual functions is necessary. This paper addresses the multicast session routing and VNF placement (MSVNFP) problem in NFV-SDN networks as a joint optimization problem. In this context, we propose an approach based on Genetic Algorithms (GA) called MSVNFP-GA. Given a set of multicast demands, the proposed algorithm calculates for each demand a tree and the location of VNFs seeking to minimize the total cost of links and node activation. Numerical simulations on different network topologies and traffic loads show that MSVNFP-GA is promising compared to the state-of-the-art competitive algorithms.", "With the rapid development of cloud computing technologies, more and more individual users and enterprises choose to deploy their key applications in green data centers (GDCs), and the scale of GDCs is increasing rapidly. To ensure service quality and maximize the revenue, cloud service providers in GDCs need to reasonably and efficiently allocate computing resources and schedule tasks of users. Traditional heuristic algorithms face challenges of uncertainty and complexity in GDCs for scheduling tasks. To solve them, this work establishes an improved resource allocation and task scheduling method based on deep reinforcement learning. It considers the dependency among different tasks, and builds a workload model based on the real-life data in Google cluster trace. In addition, a deep reinforcement learning-based scheduling model is proposed to reasonably allocate and schedule resources (CPU and memory) in GDCs. Based on two models, an Improved Deep Q-learning Network (IDQN) is proposed to autonomously learn the changing environment of GDCs, and yield the optimal strategy for resource allocation and task scheduling. Real-life data-based experiments demonstrate that IDQN achieves lower task rejection rates and energy cost than several typical task scheduling methods.", "Element extraction of Network Security Situation is the foundation for Network Security Situation awareness. Traditional methods for network security element extraction struggle with efficiently processing large-scale data and establishing effective cross-level element associations, leading to a higher false alarm rate in situation awareness. This paper proposes a cross-level network security element fusion extraction method based on deep learning. Firstly, through a data preprocessing method based on element correlation, we reduce data dimensionality, addressing the challenge of largescale nonlinear data processing. Secondly, we employ principal component analysis to construct a method for cross-level network security element fusion extraction. Moreover, by integrating convolutional neural networks and long short-term memory networks, we establish a cross-level network security element fusion classification model, achieving precise perception of the Network Security Situation. Experimental results indicate that the proposed crosslevel network security element fusion extraction method effectively reduces dataset dimensions, extracts 32-dimensional crucial network security fusion elements, and achieves a detection accuracy rate of up to 99.99% for network attack behaviors, significantly enhancing the capability of network security situation awareness.", "Geostationary (GEO) satellite communication achieves high data rates but relies on Performance Enhancing Proxies to mitigate the negative effects of high latency paths. However, such proxies cannot be applied if the transport protocol headers are encrypted, as is the case for VPNs. Recently, there has been an enormous momentum towards low Earth orbit megaconstellations, with Starlink currently being the largest satellite constellation ever deployed. In this paper, we compare two GEO systems with the Starlink megaconstallation, and unencrypted TCP with two different VPN networks: OpenVPN and Wireguard. The impact of congestion control algorithms is shown by a comparison of BBR and CUBIC. Traffic generation is done with TCP bulk data transfers.Results confirm that GEO systems achieve their configured link rate if PEPs can be applied. Without PEPs, the convergence towards the path capacity takes a considerable amount of time (~10 s) and goodput of a single flow is limited (~30 Mbit/s) due to default buffer sizes. Starlink achieves high data rates (~200 Mbit/s in forward link, ~25 Mbit/s in return link), and compared to GEO systems, has much lower latencies. Wireguard usually performs better than OpenVPN, and BBR usually performs better than CUBIC. A non-optimal combination is Starlink with OpenVPN and CUBIC, which reaches a goodput of only ~50 Mbit/s for a single flow in the forward link.", "Inibatikita is an online clothing store company which sells its products through multiple online stores, each of which is associated with a partner influencer. Currently, there exist no ecommerce solution which can accommodate this business process. This research aims to develop a system which facilitates this business process while addressing scalability for up to 50000 users. After the requirements are gathered, a system analysis is performed to compare existing ecommerce solutions with a custom solution. Post analysis, system design takes place and is swiftly followed by development and testing; finishing with deployment of the system. The results of system analysis indicate that existing ecommerce solutions aren't able to accommodate a multiple store approach, while a custom NodeJS solution is capable of doing so. Development and testing then proves that a NodeJS solution is able to fulfill the business process while accommodating 50000 users through indexing and caching. The results show that a custom NodeJS solution addresses the business requirements and scalability of inibatikita, when existing solutions could not.", "Industrial cyber-physical systems (ICPSs) manage critical infrastructures by controlling the processes based on the \"physics\" data gathered by edge sensor networks. Recent innovations in ubiquitous computing and communication technologies have prompted the rapid integration of highly interconnected systems to ICPSs. Hence, the \"security by obscurity\" principle provided by air-gapping is no longer followed. As the interconnectivity in ICPSs increases, so does the attack surface. Industrial vulnerability assessment reports have shown that a variety of new vulnerabilities have occurred due to this transition. Although there are existing surveys in this context, very little is mentioned regarding the outputs of these reports. While these reports show that the most exploited vulnerabilities occur due to weak boundary protection, these vulnerabilities also occur due to limited or ill-defined security policies. However, current literature focuses on intrusion detection systems (IDSs), network traffic analysis (NTA) methods, or anomaly detection techniques. Hence, finding a solution for the problems mentioned in these reports is relatively hard. We bridge this gap by defining and reviewing ICPSs from a cybersecurity perspective. In particular, multi-dimensional adaptive attack taxonomy is presented and utilized for evaluating real-life ICPS cyber incidents. Finally, we identify the general shortcomings and highlight the points that cause a gap in existing literature while defining future research directions.", "Datacenter networks have become a critical infrastructure of our digital society and over the last years, great eforts have been made to better understand the communication patterns inside datacenters. In particular, existing empirical studies showed that datacenter trafc typically features much temporal and spatial structure, and that at any given time, some communication pairs interact much more frequently than others. This paper generalizes this study to communication groups and analyzes how clustered the datacenter trafc is, and how stable these clusters are over time. To this end, we propose a methodology which revolves around a biclustering approach, allowing us to identify groups of racks and servers which communicate frequently over the network. In particular, we consider communication patterns occurring in three diferent Facebook datacenters: a Web cluster consisting of web servers serving web trafc, a Database cluster which mainly consists of MySQL servers, and a Hadoop cluster. Interestingly, we fnd that in all three clusters, small groups of racks and servers can produce a large fraction of the network trafc, and we can determine these groups even when considering short snapshots of network trafc. We also show empirically that these clusters are fairly stable across time. Our insights on the size and stability of communication clusters hence uncover an interesting potential for resource optimizations in datacenter infrastructures."], "ner": ["videogames,mmorpg,personalized recommendation,data cleaning,detection algorithm,online learning,massively multiplayer,training sample,gaming experiences,integrated data,role-playing game,engineering,gameplay,compression methods,computer games,language model,recommendation,", "node failure,3d printers,curse of dimensionality,sensor data,clustering algorithms,single sensor,sensors,", "artificial intelligence,case base,online learning,expert systems,social networks,client server,software reengineering,programming framework,intelligent systems,software,engineering,computer programming,online social networks,software engineering,education,machine learning,", "security systems,security analysis,big data,application layers,transport layers,computing technology,", "relational database management systems,data-base management systems,access control,data management,database systems,database management,", "communication systems,deep learning,optical fibers,stochastic,communication,coupling efficiency,stochastic approximation,single mode fibers,", "integrated data,clustering algorithms,architecture designs,database systems,communication overheads,", "cyber security,curricula,artificial intelligence,intelligent systems,machine learning,", "attack detection,ids,intrusion detection,firewall,", "videogames,world wide web,prototyping,internet,product design,augmented reality,gaming experiences,intranets,", "text mining,logistic regression models,logistic regression,regression model,student learning,web application development,web application,logistics,faculty,", "geospatial information,visualization,data visualization,prototyping,rapid prototyping,probability,usability tests,geo-spatial,correlation coefficient,geo-spatial data,domain knowledge,usability evaluation,telephone,usability studies,geoprocessing,usability assessment,voip,geographic information system,", "cryptocurrency,cloud computing,blockchain,data security,servers,distributed ledger,remote servers,data management,bitcoin,internet,", "digital image,convolutional neural networks,image classification,neural networks,gabor filter,reference image,classification models,color images,classification methods,", "optical fibre,microstructured fibers,micro-structured optical fibers,single-mode optical fiber,optical fibers,", "anechoic chambers,microwaves,wide-band,training sample,radar,received signals,clutter background,high resolution range profiles,radar systems,clutter (information theory),prior information,", "learning technologies,architecture designs,parallelism,artificial intelligence,parallelizations,network architecture,optimization,data parallel,machine learning,", "cyber threats,computer security,cyber-attacks,security challenges,cryptographic key,data security,network architecture,security analysis,security issues,security and privacy,network components,verification method,password,intrusion prevention systems,private key,network attack,evaluation models,information security,intrusion detection,verification,encryption,security risks,network security,", "fault-tolerant,network services,buffer management,dependability,source codes,proposed architectures,high availability,virtualizations,recovery mechanisms,fault tolerance,virtual networks,", "verification method,virtual spaces,network services,cloud computing,web servers,virtual machines,application servers,architecture designs,network architecture,cloud services,servers,communication,virtualized environment,verification,", "named entity recognition,statistical machine translation,machine translations,translation models,correlation analysis,translation process,", "user information,big data,information security,artificial intelligence,data security,security analysis,computer networks,", "bandwidth,radio frequency interference,wide bandwidth,radio communication,radio,", "web application,css,source codes,javascript,html,web application development,", "communication systems,computer hardware,global navigation satellite systems,satellite communications,gain control,software,radio,satellite system,antennas,automatic gain control,wireless,physical layers,communication,software-defined radios,", "spoken dialogue,dialogue,internet,user interfaces,internet of things,", "software project,software maintenance,software,maintenance tasks,visual analytics,programming languages,", "caching,database systems,read operation,flash,memory hierarchy,dram,cache,ssd,sql,", "genetic selection,denial-of-service,intrusion detection systems (ids),ids,classifiers,intrusion detection,ensemble models,machine learning,", "cloud computing,genetic algorithms,optimization problems,internet of things,computing paradigm,simulation environments,optimization,heuristic approaches,internet,", "genetic selection,unconstrained optimization,computer hardware,human genome,software,unconstrained optimization problems,data-base management systems,genetic algorithms,optimization problems,database systems,optimization,query optimization,database management,", "smart phones,wi-fi,access points,mobile phones,localization algorithm,localization technique,indoor positioning systems,personalized recommendation,cellular,it infrastructures,localization system,recommendation,ios,", "software,open source system,open source software,maintenance process,libraries,", "software developer,mobile applications,facebook,application servers,database systems,development processes,web application,twitter,ajax,authorization,", "web content,software requirements specifications,information systems,user interfaces,mobile users,", "broadcast,controller area network,artificial intelligence,detection rates,attack detection,vehicles,intrusion detection,detection algorithm,detection performance,security risks,", "translation systems,software frameworks,customized products,information systems,database systems,service delivery,", "network virtualization,mobile devices,control systems,data security,control planes,network management,", "malware attacks,cyber threats,decision trees,artificial intelligence,malwares,ids,internet of things,traffic classification,intrusion detection,fuzzy decision trees,internet,machine learning,", "network traffic,customer demands,optimization,traffic traces,network architecture,optimization problems,service time,", "gateways (computer networks),distribution network,bandwidth,network management,bandwidth efficiency,", "software developer,engineers,software,education,programming languages,sql,online course,", "computer security,mobile phones,network architecture,data security,computer networks,cell phone,network operations,security issues,security and privacy,network components,communication networks,smart phones,computer systems,network attack,information security,intrusion detection,network intrusion detection,wide area networks,security analysis,network security,", "web content,static analysis,software,world wide web,computer science,ajax,web information,quality concerns,", "content providers,cloud infrastructures,dependability,maintenance process,cloud services,", "gameplay,computer games,videogames,game experience,", "generative adversarial networks,neural networks,malware detection,malwares,data augmentation,malware analysis,malicious software,malicious codes,machine learning,", "digital libraries,software,engineering,libraries,software engineering,search engines,software maintenance,maintenance process,software reengineering,", "clustering methods,cluster analysis,big data,data analytics,database systems,association rules,clustering algorithms,data mining,machine learning,", "network analyzer,low power,cst microwave studio,wireless communications,qam,communication,microstripes,quadrature amplitude modulation,performance analysis,phase shift keying,demodulators,microwaves,wi-fi,uwb,qpsk,transceivers,wireless,vector network analyzers,ultra-wideband (uwb),frequency ranges,", "decision trees,convolutional neural networks,cloud computing,deep learning,privacy,cloud security,database systems,k-nn,naive bayes,sql,iaas,sql injection,machine learning,", "gaming experiences,videogames,validation,software,engineering,game development,database systems,engine,program debugging,optimization,verification,computer games,software verification,machine learning,", "software project,software,code generation,engineering,source codes,human factors,development processes,software component,", "nash equilibrium,incentive compatible,network services,trade,virtual machines,privacy requirements,network architecture,revenue,privacy,virtualizations,multi-tier,", "software developer,web content,mobile environments,world wide web,web-based applications,software architecture,html,web application development,information exchanges,web development,web application,javascript,ajax,", "virtual spaces,software developer,web servers,smart homes,application servers,", "wearable computers,classification methods,internet of things,intermediate node,text classification,cell phone,source nodes,wearable devices,knowledge transfer,individual privacy,privacy,mobile phones,destination nodes,smart phones,machine learning,data privacy,", "architecture designs,prototyping,systems design,design space exploration,", "robotics,expert systems,artificial intelligence,intelligent systems,", "outages,formal specification,semantics,fundamental solutions,database systems,distributed systems,", "cyber physical systems (cpss),cyber-attacks,big data,security controls,control systems,ids,internet of things,attack detection,intrusion detection,privacy,internet,sensitive informations,machine learning,", "signal analysis,inference,web application,user experience,android,detection algorithm,online learning,privacy,javascript,ajax,facial images,web content,back-end servers,deep learning,facial expression,probabilistic inference,hand gesture,python,programming languages,machine learning,", "load balancing technique,integrated data,software,electricity costs,data planes,control systems,servers,energy conservation,", "detection rates,multilayer perceptrons,backpropagation algorithm,detection algorithm,multiagent system,sensitive informations,cache,security vulnerabilities,malicious attack,dos attacks,multi-agent,reinforcement learning,expert knowledge,software agents,bandwidth,computer systems,multi-agent reinforcement learning,security attacks,intelligent agents,security issues,timing attacks,", "sql query,query translations,natural languages,domain knowledge,sql,language model,database systems,", "cyber security,software systems,software,curricula,information assurance,university,", "big data,cloud computing,parallelism,parallel processing,cloud services,", "optical fibre,higher frequencies,single-mode optical fiber,frequencies,optical fibers,", "storage systems,stream processing,big data,data stream,real time streaming,database systems,search engines,streaming data,", "microservices,anomaly detection,complex networks,intrusion detection,computer systems,security challenges,machine learning,", "data integration,big data,storage services,engine,database systems,storage resources,business process,smart cities,geo-spatial,", "network management,control systems,blockchain,control planes,data management,", "wireless networks,multimedia technologies,mobile applications,mobile networks,mobile communications,wireless communications,communication,user experience,mobile terminal,mobile devices,cellular network,mobile users,communication networks,", "virtual spaces,software frameworks,java virtual machines,virtual machines,java,application servers,jvm,programming languages,business logic,", "cellular,deep learning,localization system,localization algorithm,indoor positioning systems,", "network performance,network components,individual service,tcp,tcp flows,tcp congestion control,network architecture,tcp connections,", "software,intrusion detection,intrusion detection systems (ids),ids,virtual networks,", "convolutional neural networks,deep learning,neural networks,engineering,artificial intelligence,computer networks,security issues,information security,network security,", "convolutional neural networks,deep learning,neural networks,bayesian methods,asian,network architecture,african american,ethnicity,image processing,", "robotics,computer hardware,intelligent robots,robotic systems,industrial robots,robot system,robots,gear,planetary gears,human operator,", "noise ratios,base stations,channel capacity,resource sharing,sharing schemes,cellular,communication,power allocations,cellular network,cellular system,self-interferences,", "network traffic,network topology,bandwidth,topological structure,topology,", "gameplay,player experience,videogames,computer games,", "primary path,network virtualization,backup path,computing paradigm,virtual networks,virtualizations,", "syntactics,nosql,semantics,sql,student learning,database systems,", "smart homes,architecture designs,system architectures,internet of things,database systems,", "business process,big data,business processing,business intelligence,ebusiness,e-services,data analytics,", "dynamic composition,design tasks,architecture designs,prototyping,dependability,component composition,engineering design process,automatic composition,systems design,design activity,conceptual design,", "distributed database systems,single-machine,high availability,distributed database,file systems,database systems,", "software development,software,game development,requirements analysis,gameplay,design patterns,computer games,object-oriented design,", "decision trees,imitation learning,software agents,reinforcement learning,intelligent agents,machine learning,", "virtual machines,saas,microservices,combinatorial optimization,genetic algorithms,servers,optimization,communication,communication networks,", "python,web content,mobile devices,software,open source software,web-based applications,", "storage systems,data management,privacy and security,information management,data-base management systems,privacy requirements,database systems,storage devices,data privacy,business process,relational database management systems,privacy,privacy protection,individual privacy,database management,", "feedforward neural networks,convolutional neural networks,validation,emotion recognition,genetic algorithms,classifiers,output layer,human motion recognition,simulated annealing algorithms,speech emotion recognition,cross validation,neural networks,human emotion,facial expression recognition,emotion detection,speech signals,emotional speech,emotional expressions,machine learning,", "non-volatile memories,non-volatile,big data,dram,high capacity,nonvolatile storage,", "fault-tolerant,qos,base stations,mobile networks,computer systems,blockchain,network architecture,radio,malicious nodes,security issues,peer-to-peer architectures,wireless,access network,", "cluster systems,view maintenance,constrained optimization problems,optimization problems,database systems,optimization,semantics,sql,query optimization,", "network performance,private networks,network services,bandwidth,architecture designs,network protocols,network architecture,", "cyber threats,genetic selection,cyber security,big data,information security,internet,", "sift,visualization,university,database systems,graduate student,education,sql,relational database,recommendation,", "reconfigurability,software systems,network services,computer hardware,software,routing scheme,architecture designs,data security,network architecture,security architecture,security issues,computational efficiency,high capacity,routing algorithms,", "content delivery network,internet service providers,software,internet,network architecture,", "architecture designs,viewpoint,topology,mobile robots,robot system,optimization problems,robots,humanoid robot,shape optimization,optimization,topology optimization,multi-objective optimisation,", "", "cyber threats,cyber-attacks,deep learning,spam,malwares,security attacks,cyber security,information security,security vulnerabilities,internet,anti virus,", "user interfaces,database systems,software developer,graphical user interfaces,knowledge based systems,", "smart phones,sensors,artificial intelligence,internet of things,security systems,python,infra-red sensor,security issues,smart homes,programming languages,internet,", "capital investment,genetic selection,architecture designs,prototyping,design decisions,investments,demand response,systems design,", "big data,software,higher education institutions,university,internet,data analytics,database systems,", "satellite system,microwaves,software,compiler,demonstrations,retrieval performance,", "network performance,cbam,data augmentation,optical fibers,recognition algorithm,test samples,", "enterprise information system,big data,business activities,business models,data analytics,", "robotics,robot arms,cost savings,industrial robots,robotic manipulators,robots,costs saving,robotic arms,", "optimization,grid node,computational grids,cloud providers,coordination mechanisms,", "dijkstras algorithms,genetic selection,optimization problems,information exchanges,optimization,enterprise information system,logistics industry,business activities,numerical example,dijkstra,control planes,illustrative examples,", "tangible interfaces,tangible user interfaces,robotics,computer hardware,interaction design,user experience,human computer interaction,haptic systems,", "virtual spaces,software frameworks,virtual environments,virtual reality,immersive virtual environments,distributed systems,", "education technology,software,learning management system,least mean squares,cyber security,education,lms,educational technology,security risks,", "hyper-spectral images,svm,support vector machine,support vector,machine learning,", "sql query,relational queries,privacy concerns,query processing,reinforcement learning,optimization problems,keyword queries,reward function,database systems,xquery,optimization,query results,sql,privacy,query execution,", "big data,cellular,anonymization,libraries,data anonymization,mobility analysis,", "information retrieval,query languages,natural languages,query processing,web searches,natural language questions,computer vision,semantic search,dbpedia,deep learning,question answering,data mining,database systems,semantics,data management,semantic web,recommendation,natural language processing,machine learning,", "integrated data,satellite system,geostationary satellites,viewpoint,anomalous behavior,", "cyber threats,cyber-attacks,cloud computing,security issues,cloud services,", "facebook,internet of things,database systems,relational database,nosql,engineers,demonstrations,hbase,internet,", "cyber physical systems (cpss),cloud computing,qos,privacy,cloud services,", "denial-of-service,privacy concerns,software,reinforcement learning,markov decision processes,mdp,security issues,detection algorithm,detection problems,privacy,virtualizations,network security,", "correlation analysis,classifiers,data mining techniques,data mining,svm,genetic selection,", "antenna element,geostationary satellites,phased array antennas,antenna systems,array antennas,satellite system,antennas,antenna arrays,", "sql,sql query,programming languages,database systems,", "convolutional neural networks,bandwidth,deep learning,neural networks,software,dos attacks,internet of things,attack detection,distributed denial of service attack,communication,traceback,extreme learning machine,security vulnerabilities,internet,ip traceback,", "recommendation systems,recommender systems,genetic algorithms,personalized recommendation,optimal solutions,collaborative filtering,multi-objective optimisation,semantic information,data mining,multi-objective optimization problem,recommendation methods,semantics,graph embeddings,recommendation,natural language processing,machine learning,", "mobile networks,reduce energy consumption,user experience,android,mobile terminal,mobile devices,energy savings,ajax,web content,network traffic,smart phones,world wide web,location-aware,mobile web,web traffic,energy conservation,mobile users,energy use,web information,", "network security,information security,evaluation index,intrusion detection,network components,network architecture,dos attacks,network attack,", "low energy consumption,cpu,service level agreements,reducing energy consumption,cache,reinforcement learning,virtualizations,", "signal analysis,inference,web application,user experience,android,detection algorithm,online learning,privacy,javascript,ajax,facial images,web content,back-end servers,deep learning,facial expression,probabilistic inference,hand gesture,python,programming languages,machine learning,", "time frequency domain,fiber gratings,sensors,parallel processing,optical fibers,spatial frequency discrimination,optical fibre,frequency domains,strain sensors,fiber bragg gratings,field programmable gate array,optical fiber communication,single-mode optical fiber,signal processing,fiber bragg grating sensors,time domain,fiber sensor,optical fiber sensor,", "controller area network,interpretability,network architecture,network attack,vehicles,multi-class classification,classification models,intrusion detection,network intrusion detection,malicious activities,classification methods,boosting,", "big data,virtual environments,virtual reality,privacy,artificial intelligence,augmented reality,virtual worlds,", "decryption keys,decryption,attribute-based encryption,security challenges,cryptosystems,software component,privacy,access control,sensitive informations,encryption/decryption,cyber physical systems (cpss),context-awareness,access policies,encryption technique,private key,ciphertexts,internet of things,data privacy,encryption,", "anti virus,honeypots,interconnected power systems,electricity,network architecture,network attack,electric power,cyber security,information security,antivirus softwares,intrusion detection,firewall,power networks,network security,", "network security,information security,situation awareness,security requirements,information technology,network attack,", "optimization,sequence diagrams,class diagrams,mobile users,optimization problems,", "security management,cyber threats,cyber-attacks,genetic algorithms,differential evolution,cyber security,adaboost algorithm,artificial bee colonies,optimization,ant colony optimization,optimization problems,internet of things,adaptive boosting,information security,particle swarm optimization (pso),internet,", "logistic regression,random forests,data-base management systems,libraries,database systems,training algorithms,relational database management systems,sql,security risks,materialized view,boosting,", "video streaming,videogames,data stream,traffic traces,video encoder,application layers,adaptive streaming,network architecture,multimedia streaming,video streaming services,video streams,video delivery,video quality,network components,computer games,network traffic,streaming videos,media streaming,adaptive video streaming,network management,streaming service,", "on-line education,online course,video contents,linguistics,", "virtual spaces,computer games,videogames,virtual worlds,", "social sciences,kaplan-meiers estimate,combinatorial problems,information systems,combinatorial optimization,", "cyber-attacks,deep learning,random forest classifier,random forests,internet of things,classifiers,multi-class classification,intrusion detection,machine learning,", "quantum gates,field programmable gate array,analog signals,architecture designs,proposed architectures,digital control,", "mobile applications,base stations,principle component,network architecture,bss,mobile service,cellular,antennas,cellular network,machine learning,", "nosql,query execution,sql,relational database,database systems,", "virtual spaces,validation,matrix factorizations,virtual machines,co-processors,network architecture,circuit simulation,multiprocessors,factorization,quantum gates,logic gates,hardware accelerators,tensor factorization,verification,hpc,circuit simulators,", "python,programming languages,relational database management systems,data-base management systems,database systems,", "software frameworks,optimization,cpu,bandwidth,efficient scheduling,", "chaotic systems,cellular automata,automata,hyperchaotic,image encryption algorithm,random sequence,image encryptions,hyper-chaotic systems,image scrambling,push-down automata,encryption,finite state automata,", "computer hardware,software,software component,data-base management systems,database systems,", "video conferencing,routing scheme,data planes,network architecture,real-time application,service delivery,routing protocols,network management,control planes,routing algorithms,", "verification tools,model checker,smart contracts,contracts,software,malicious attack,blockchain,demonstrations,verification,", "service level agreements,internet service providers,security frameworks,mobile networks,network architecture,security issues,enterprise system,mobile terminal,internet,wireless networks,mobile internet,content providers,enterprise information system,mobile users,security model,cellular network,security requirements,", "destination nodes,network virtualization,competitive algorithms,routing problems,network architecture,genetic algorithms,multicast routing,optimization,communication,intermediate node,network components,control planes,virtualizations,virtual networks,virtual spaces,multicast tree,routing scheme,joint optimization,optimization problems,multicast sessions,multicasts,routing algorithms,", "optimal strategies,task scheduling problem,cloud computing,task-scheduling algorithms,cloud service providers,service quality,content providers,reinforcement learning,cloud services,private clouds,scheduling tasks,computing resource,q-learning,task scheduling,cloud providers,", "convolutional neural networks,deep learning,neural networks,principle component,network attack,classification models,situation awareness,principle component analysis,detection rates,network security,", "low earth orbits,satellite communications,transport protocols,congestion control (communication),congestion control algorithm,satellite constellations,satellite system,communication,tcp,congestion,", "business process,systems design,ebusiness,business process management,business requirement,", "cyber physical systems (cpss),network traffic,sensors,sensor networks,cyber security,communication,security policy,ubiquitous computing,intrusion detection,anomaly detection,", "servers,hadoop,web servers,facebook,database systems,"]}