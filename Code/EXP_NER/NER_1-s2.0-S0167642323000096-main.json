{"paper_id": "1-s2", "header": {"generated_with": "S2ORC 1.0.0", "date_generated": "2024-03-20T17:52:53.034943Z"}, "title": "A lightweight API recommendation method for App development based on multi-objective evolutionary algorithm", "authors": [{"first": "Xun", "middle": [], "last": "Li", "suffix": "", "affiliation": {"laboratory": "", "institution": "Jilin University", "location": {"postCode": "130012", "settlement": "Changchun, Jilin", "country": "China"}}, "email": ""}, {"first": "Lei", "middle": [], "last": "Liu", "suffix": "", "affiliation": {"laboratory": "", "institution": "Jilin University", "location": {"postCode": "130012", "settlement": "Changchun, Jilin", "country": "China"}}, "email": ""}, {"first": "Yuzhou", "middle": [], "last": "Liu", "suffix": "", "affiliation": {"laboratory": "", "institution": "Jilin University", "location": {"postCode": "130012", "settlement": "Changchun, Jilin", "country": "China"}}, "email": "liuyuzhou_jlu@qq.com"}, {"first": "Huaxiao", "middle": [], "last": "Liu", "suffix": "", "affiliation": {"laboratory": "", "institution": "Jilin University", "location": {"postCode": "130012", "settlement": "Changchun, Jilin", "country": "China"}}, "email": ""}], "year": "", "venue": null, "identifiers": {}, "abstract": "Context: API is important in daily programming activities during app development, but finding appropriate APIs is time-consuming for developers. To simplify this process, many researchers pay attention to overcoming the task-API knowledge gap using semantic information mined from the large-scale dataset for API recommendation. However, only semantic information is not enough since API descriptions and developers' query may not share similar words, meanwhile, large-scale data mining brings high costs. These limit the efficiency of existing API recommendation methods. Objective: In this work, we aim at proposing a lightweight API recommendation method based on small-scale data with low costs, so that everyone can use it obtain appropriate API knowledge for supporting their development tasks. Method: We model API recommendation as a multiobjective optimization problem by considering both structural and semantic information of APIs, and use the genetic algorithm to gain optimal solutions for overcoming the limitations of the small-scale dataset. Specially, we extract the structural and semantic information of APIs from APK files and API descriptions with graph embedding and NLP techniques respectively. Then, we get the recommended APIs satisfying structural and semantic objectives according to the developers' target functionality with a genetic algorithm. Finally, we give the usage scenarios of our recommendation information and the guideline of our approach to help developers understand and use our method easily. Results and Conclusion: We conduct a series of experiments based on apps in Google Play, API descriptions in Android Tutorial and Q&As in Stack Overflow. The results show that Precision@N of our recommendation can be up to 0.89, MAP@N is up to 0.50, and MRR reaches 0.69, and our method achieves such good performance only utilizing less than 1/10 of the project number of our compared machine learning method with less time and lower device requirement. Besides, we conduct a survey and most of the participants confirm the understandability and usability of our recommended APIs in practice.", "pdf_parse": {"abstract": [{"text": "Context: API is important in daily programming activities during app development, but finding appropriate APIs is time-consuming for developers. To simplify this process, many researchers pay attention to overcoming the task-API knowledge gap using semantic information mined from the large-scale dataset for API recommendation. However, only semantic information is not enough since API descriptions and developers' query may not share similar words, meanwhile, large-scale data mining brings high costs. These limit the efficiency of existing API recommendation methods. Objective: In this work, we aim at proposing a lightweight API recommendation method based on small-scale data with low costs, so that everyone can use it obtain appropriate API knowledge for supporting their development tasks. Method: We model API recommendation as a multiobjective optimization problem by considering both structural and semantic information of APIs, and use the genetic algorithm to gain optimal solutions for overcoming the limitations of the small-scale dataset. Specially, we extract the structural and semantic information of APIs from APK files and API descriptions with graph embedding and NLP techniques respectively. Then, we get the recommended APIs satisfying structural and semantic objectives according to the developers' target functionality with a genetic algorithm. Finally, we give the usage scenarios of our recommendation information and the guideline of our approach to help developers understand and use our method easily. Results and Conclusion: We conduct a series of experiments based on apps in Google Play, API descriptions in Android Tutorial and Q&As in Stack Overflow. The results show that Precision@N of our recommendation can be up to 0.89, MAP@N is up to 0.50, and MRR reaches 0.69, and our method achieves such good performance only utilizing less than 1/10 of the project number of our compared machine learning method with less time and lower device requirement. Besides, we conduct a survey and most of the participants confirm the understandability and usability of our recommended APIs in practice.", "cite_spans": [], "section": "Abstract", "sec_num": null}], "body_text": [{"text": "How to improve the development efficiency is a permanent topic for the application developers in the high competitive market [9] . In this topic, using APIs always plays an important role since it makes developers \"stand on the shoulders of giants\" to develop their products [4] . A common scenario for app developers is searching for appropriate APIs to implement the functionalities they want to realize (target functionalities) from the online resource (i.e. tutorials, blogs, Q&A forums, code repositories in GitHub) [39] . However, the task-API knowledge gap makes such daily work not only tedious but also time-consuming, so more and more researchers pay their attention to the method of recommending suitable APIs according to developers' demands.", "cite_spans": [{"start": 125, "end": 128, "text": "[9]", "ref_id": "BIBREF6"}, {"start": 275, "end": 278, "text": "[4]", "ref_id": "BIBREF1"}, {"start": 521, "end": 525, "text": "[39]", "ref_id": "BIBREF36"}], "section": "Introduction", "sec_num": "1."}, {"text": "In recent years, with the abundance of online resources and the development of data mining technologies, two trends appear in the research field of API recommendation:", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "One is more various kinds of data are used to find the semantic relationships between the programming task and API knowledge for API recommendation. The text data [41] [35] (e.g. API documentation, discussions in developer forums) and the resource of code [28] (in GitHub, and so on) are analyzed (separately or together) to establish semantic modes for bridging the lexical gap between APIs and target functionalities caused by different words used when describing them.", "cite_spans": [{"start": 163, "end": 167, "text": "[41]", "ref_id": "BIBREF38"}, {"start": 168, "end": 172, "text": "[35]", "ref_id": "BIBREF32"}, {"start": 256, "end": 260, "text": "[28]", "ref_id": "BIBREF25"}], "section": "Introduction", "sec_num": "1."}, {"text": "The other is larger scale data are mined for obtaining rich API knowledge for the recommendation [14] [19] . Many approaches tend to collect data as much as possible and use data mining technologies to pre-build large-scale API knowledge repositories from the data resources, so the developers can search for their task-related APIs quickly.", "cite_spans": [{"start": 97, "end": 101, "text": "[14]", "ref_id": "BIBREF11"}, {"start": 102, "end": 106, "text": "[19]", "ref_id": "BIBREF16"}], "section": "Introduction", "sec_num": "1."}, {"text": "Pursuing the above mainstream trends, we also have conducted a research on API recommendation for app developers in our previous work [23] : based on the data in app stores, we used the app features as a kind of new elements to establish relationships between the app development and API resources. Although the performance of our API recommendation seems relative good (the recommendation precision (Precision@10) of our approach is up to 0.86), two phenomena cause our attention during the research:", "cite_spans": [{"start": 134, "end": 138, "text": "[23]", "ref_id": "BIBREF20"}], "section": "Introduction", "sec_num": "1."}, {"text": "\u2022 Only semantic information is not enough to find related APIs for target functionality accurately. For one thing, despite natural language processing techniques have been well developed, it still cannot fully overcome all the lexical gaps between programming tasks and API knowledge. For the other, as the research [16] said, some relevant APIs do not share semantically similar words with developers' target functionalities, so it is hard to find these APIs for the recommendation.", "cite_spans": [{"start": 316, "end": 320, "text": "[16]", "ref_id": "BIBREF13"}], "section": "Introduction", "sec_num": "1."}, {"text": "\u2022 Large-scale data brings high costs. Obviously, more data needs more time to process but not all the cost gets equal payback: errors will be introduced in the data processing. Besides, processing large-scale data requires advanced equipment. Moreover, Android evolves fast at a rate of 115 API updates per month on average to accommodate new feature requests, fix bugs or meet new standards [25] . To keep pace with API evolution, all data has to be recollected and reprocessed, which increases the cost.", "cite_spans": [{"start": 392, "end": 396, "text": "[25]", "ref_id": "BIBREF22"}], "section": "Introduction", "sec_num": "1."}, {"text": "These phenomena lead us to think about two questions: 1) what else information can be used for bridging the tasks and APIs and 2) whether a small-scale data set can support the recommending process.", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "With respect to the first question, the contexts of APIs in existing codes are no doubt a kind of useful information and provide a different angle for describing APIs from its using structure, which can be used as a complement to semantic information of API [32] . Introducing such information into API recommendation can be seen as attaching structural related restriction on the APIs related to the target functionalities obtained by the methods only utilizing semantic information. In other words, the API recommendation can be seen as searching the APIs related to the developers' target functionalities not only semantically but also structurally. This process can be modeled as a multi-objective problem and solved by many classic approaches for recommending the comprehensive target functionality-related API knowledge.", "cite_spans": [{"start": 258, "end": 262, "text": "[32]", "ref_id": "BIBREF29"}], "section": "Introduction", "sec_num": "1."}, {"text": "With respect to the second question, similar products contain the knowledge that is more likely to be reused by each other, which means the domain-specific data could be more valuable in the API recommendation for a target application (to be implemented by developers). When the scale of data to be mined has reached a certain point, its increasement could not get equal payback: the cost grows but little new knowledge is gained [15] . However, the knowledge contained in smallscale data is less than the ones in large-scale data, so it needs to be expanded. The genetic algorithm can be adopted to achieve this goal, with the crossover and mutation operators, it could generate the knowledge as various as the ones in the large-scale data.", "cite_spans": [{"start": 430, "end": 434, "text": "[15]", "ref_id": "BIBREF12"}], "section": "Introduction", "sec_num": "1."}, {"text": "Furthermore, the high cost of large-scale data training makes it usually done by particular companies and others can only use the services provided by these companies. However, sometimes developers want more domain-specific knowledge rather than the general one for their tasks, or sometimes the services could not be used since there is no large-scale related data at all (for example, some companies have their specialized APIs which are not provided to the public). In these conditions, a lightweight API recommendation based on a small-scale data set can let everyone have their own model with low costs, and such a personalized model may be more applicable to support their coding process.", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "Inspired by the above idea, we propose a multi-objective genetic algorithm-based approach for recommending methodlevel APIs satisfying the target functionalities of developers with domain-specific small-scale data. The main process of the approach is shown in Fig. 1 .", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "Firstly, we extract the structural and semantic information of APIs from APK files and API descriptions with graph and word embedding separately.", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "Secondly, we model the API recommendation as a multi-objective problem and use a genetic algorithm to find feasible solutions for the developer's target functionality. Here, the semantic and structural information of API are considered, and it can be further extended to other kinds of information if necessary. Finally, to help the developers understand and use the solutions easily, we give its interpretation by showing the call relations between different APIs as well as some specific code fragments. Besides, we further provide a guideline to the end users to introduce the usage of our approach.", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "Overall, the main contributions of our approach are the following two points:", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "\u2022 We model the API recommendation problem as a multi-objective optimization problem, which integrates the semantic and structural information of APIs in the recommendation process. Unlike the prevailing machine learning approaches for mining API knowledge based on large-scale data, we use a multi-objective evolutionary algorithm to address such problem only based on small-scale data with low costs.", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "\u2022 We conduct experiments to evaluate the effectiveness of our approach based on apps from Google Play, API descriptions from Android Tutorial, and Q&As on Stack Overflow. The Precision@N of our recommendation can be up to 0.89, the MAP@N is up to 0.50, and MRR reaches 0.69. Moreover, our approach achieves this performance in less time and with low device requirement compared with the machine learning baseline. Besides, our data volume is less than 1/10 of the project number of the compared machine learning baseline. We also conducted a survey on the user-friendliness of the API knowledge we recommend. Most of the participants confirm the understandability and usability of our recommendation results. This indicates the APIs recommended by our approach are useful for app development in practice.", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "This paper is organized as follows. Section 2 introduces the background knowledge used in our approach. Section 3 gives the process of API structural and semantic information presentation. Section 4 introduces how our approach gain API knowledge based on the structural and semantic information of API using a multi-objective genetic algorithm. Section 5 presents the process of introducing API usage scenarios for helping developers better understand our recommendation results. Section 6 introduce how to use our approach to get target functionality-related API knowledge from the user perspective. Section 7 presents our experiments for evaluating our approach. Section 8 reviews the existing studies related to our work. Section 9 is the conclusion and future work.", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "Our method is based on the representation of structural information of codes and the solutions on the multi-objective optimization, so here we first introduce some related concepts.", "cite_spans": [], "section": "Background", "sec_num": "2."}, {"text": "Graph embedding is a popular method for learning the representations of graphs. Nodes in the graph are represented as the low dimensional vectors that capture the relationships between them and their adjacent nodes.", "cite_spans": [], "section": "Graph embedding", "sec_num": "2.1."}, {"text": "Random-walk based embedding technique is one kind of the most popular graph embedding methods, its basic idea and process are shown in Fig. 2 . Motivated by the neural language model Skip-gram, the random walk-based embedding uses one node to predict the embedding of its neighboring nodes. Such methods [33] [13] apply biased random walk to transform the graph into sequences of nodes, which further as the training data for machine learning methods to obtain the vector representation of each node. Such vector can reflect the partial structural information of the node in the graph.", "cite_spans": [{"start": 304, "end": 313, "text": "[33] [13]", "ref_id": null}], "section": "Graph embedding", "sec_num": "2.1."}, {"text": "For an optimization problem, if there are multiple simultaneous optimization objectives, it is called a multi-objective optimization problem. Since the sub-objectives usually contradict each other, trade-offs should be made among them for finding the proper solutions (Pareto optimal solutions) that optimize all the objectives as much as possible [46] . A common approach for addressing multi-objective optimization problems is applying the evolutionary algorithm (EA) [18] . Part B of Fig. 2 illustrates the process of this approach. The change operators (crossover and mutation) of EA can generate numerous distributed solutions as the population of evolution. Then the optimal individuals that balance the sub-objectives to approach their optimal values are selected to form the next generation of the population for further evolution until termination conditions are met. Generally, there are two common termination conditions: one is the number of iterations finished with a predefined number of iterations; the other is that the optimal individuals in the population or average fitness have basically not improved over several iterations. This algorithm is called the multi-objective evolutionary algorithm (MOEA). In this process, the population continuously converges to the optimal solutions, and the final population is taken as the Pareto optimal solutions of the multi-objective problems.", "cite_spans": [{"start": 348, "end": 352, "text": "[46]", "ref_id": "BIBREF43"}, {"start": 470, "end": 474, "text": "[18]", "ref_id": "BIBREF15"}], "section": "Multi-objective optimization", "sec_num": "2.2."}, {"text": "Our approach takes into account both API structural and semantic information in the API recommendation task. But these two types of information are contained in the code of applications and API descriptions respectively, which are not available directly. Therefore we need to obtain their vectorized representation for supporting the subsequent API recommendation process.", "cite_spans": [], "section": "Data processing", "sec_num": "3."}, {"text": "The structural information of APIs is contained in the control and data flow of code representing the logical information of API calls [8] . Previous study [31] shows the structural information captures the usage relations (i.e., co-occurring relations among APIs in usages) and can be represented with a function-call graph (FCG). Therefore, we extract the FCG of app and vectorize the API nodes in it for representing the API structural information by graph embedding.", "cite_spans": [{"start": 135, "end": 138, "text": "[8]", "ref_id": "BIBREF5"}, {"start": 156, "end": 160, "text": "[31]", "ref_id": "BIBREF28"}], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "Function-call graph (FCG) shows the call relations among the methods in code. Thus, to construct the FCG, we need to identify the methods in the code of the application and the call relations between them. The process of constructing FCG is illustrated in Fig. 3 . Here, we choose androguard [1] (a popular static analysis tool) to decompile the APK files for FCG construction. Specifically, for each APK file in App dataset, we first parse it to get all methods implemented in it. Secondly, for each method, we further parse it to get the methods it calls. In this process, the invocation relations between methods are determined. We identify the callers and callees in the invocation relations and treat them as the nodes in FCG. Thirdly, the directed edges (from callers to callees) are added between nodes. Finally, we get the FCG of a given app:", "cite_spans": [], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "F C G app = (V , E)", "cite_spans": [], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": ", where:", "cite_spans": [], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "\u2022 V = {v i |1 \u2264 i \u2264 k} denotes the methods in app, where v i represents a method name.", "cite_spans": [], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "\u2022 E \u2286 V \u00d7 V denotes the function calls, where < v i , v j > as a directed edge, pointing from v i to v j , representing method v i calls method v j . We further use node2vec [13] to embed the FCG of the app and take the vector of an API node as the representation of its structural information. For ease of expression, we denote it as the structural information vector of API. Though node2vec is a well-performed graph embedding algorithm, it still requires to be fine-tuned to become an FCG-specific algorithm in API node vectorization.", "cite_spans": [{"start": 174, "end": 178, "text": "[13]", "ref_id": "BIBREF10"}], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "There are two main problems we confront with: (1) Noise is contained in the FCGs we construct. An FCG presents all the method call relations in its corresponding application, these methods not only include API methods but also a large number of methods defined by developers. But we only focus on representing API structural information. (2) The node2vec algorithm only processes a whole graph structure. However, integrating all FCGs into one graph needs to add some new nonsense nodes. These nodes will change the original call relations of FCGs and decrease the accuracy of structural information vectors represented by node2vec.", "cite_spans": [], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "To deal with the above two problems, we filter the non-API nodes in FCGs and extract the sub-graphs containing API nodes as the training data for graph embedding. The details of this process are introduced as follows:", "cite_spans": [], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "Firstly, we take each API node in the FCG as the starting point and use the breadth-first traversal strategy to gain its sub-graph. In this step, we set the max depth of the subgraph as \u03b1 (\u03b1 = 5 in our experiment), so that the sub-graph can be located around the API node and better reflect the structural information of the API. Secondly, for each gained sub-graph, we also hope it can contain the nodes of different APIs so that we can catch the call relationships between them during the embedding. Thus, we further check each sub-graph: if it contains more than one API, it is retained; otherwise, we extend it by continuing to traverse the FCG until reaching another API node. To avoid excessive expanding, we define the threshold \u03b2 on the depth of the sub-graph (\u03b2 = 10 in our experiment).", "cite_spans": [], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "Based on the above steps, we extract a set of sub-graphs from the FCG of an app. To reflect the structure of each graph adequately, we traverse n times repeatedly with the breadth-first traversal strategy to get more diverse sequence of the nodes as the input for training the model of graph embedding. Note that we re-implement the node2vec to make it suit our task rather than directly apply it since it cannot directly process many graphs. The core idea of node2vec can be seen at [2] .", "cite_spans": [{"start": 484, "end": 487, "text": "[2]", "ref_id": null}], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "By training the graph embedding with all subgraphs, we can obtain the vectors representing the structural information of each API. The results consist of a set A P I structural = {api structural 1 , api structural 2 , ..., api structural m }, in which api structural i is the vector represents the structural information of api i .", "cite_spans": [], "section": "API structural information presentation", "sec_num": "3.1."}, {"text": "API descriptions introduce the functionalities of APIs in natural language. We extract the words describing the functionalities from API descriptions and vectorize them to represent semantic information of the API with word embedding. The process of API semantic information extraction is illustrated as follows. Note that we only take the APIs in Android Tutorial for illustration, the semantic information of APIs in third-party can be extracted in the similar way.", "cite_spans": [], "section": "API semantic information presentation", "sec_num": "3.2."}, {"text": "Specifically, we first collect the HTML files containing API descriptions from Android Tutorial. However, these files cannot be used directly since they contain noisy information (i.e. special symbols, API code snippets, etc.). To obtain descriptive text about the API functionality for further analysis, we process the collected HTML files: discarding the noise information, such as the index pages and pages containing the program.", "cite_spans": [], "section": "API semantic information presentation", "sec_num": "3.2."}, {"text": "By observing and analyzing the processed HTML file, we find that the contents of API functionalities are often aligned with the following two HTML tags:", "cite_spans": [], "section": "API semantic information presentation", "sec_num": "3.2."}, {"text": "\u2022 <h2 class = \"api-section\", id = \"summary\">. Contents in this tag is the overview of the functionalities of an API class.", "cite_spans": [], "section": "API semantic information presentation", "sec_num": "3.2."}, {"text": "\u2022 <h3 class = \"public-methods\">. Information associated with this tag is the description of the public methods of an API class.", "cite_spans": [], "section": "API semantic information presentation", "sec_num": "3.2."}, {"text": "We extract the descriptive texts associated with these tags as the main part of the description of the corresponding API and denote it as the Description api .", "cite_spans": [], "section": "API semantic information presentation", "sec_num": "3.2."}, {"text": "Then, for each Description api , we extract the semantic features (words describing the functionalities of API) of API from it. Although there are many classical methods that can be used for feature extraction, considering that we have proposed a method [24] to extract features from app descriptions previously, which has been verified with our experiments with good performance (Precision 86.15%, Recall 83.45%), we directly apply it here for API semantic features extraction. Specifically, we first split Description api into sentence level; Then each sentence is further parsed into a parsing tree with Standford Parser; Finally, all semantic features are extracted from the tree by using the feature extraction rules defined in our previous work.", "cite_spans": [{"start": 254, "end": 258, "text": "[24]", "ref_id": "BIBREF21"}], "section": "API semantic information presentation", "sec_num": "3.2."}, {"text": "Finally, we use Gensim [27] (a python package that implements word2vec) trained from all the API description texts to obtain the vectors of the semantic features of API. In this way, we can get the semantic information of each API:", "cite_spans": [{"start": 23, "end": 27, "text": "[27]", "ref_id": "BIBREF24"}], "section": "API semantic information presentation", "sec_num": "3.2."}, {"text": "A P I semantic = { f 1 , ..., f m }, where f = {word 1 , ..., word m } is its semantic feature representing one functionality provided by the api, and each word denotes a key word that describes f . After processing all the APIs' descriptions, we get their semantic information vector representations and construct a dataset A P I semantic = {api semantic 1 , ..., api semantic m }, where api semantic denotes the semantic information of api.", "cite_spans": [], "section": "API semantic information presentation", "sec_num": "3.2."}, {"text": "Based on the structural and semantic information of APIs, we want to recommend the APIs for the target functionalities given by developers from both these two angles. This process is modeled as a multi-objective optimization problem and we use a multi-objective evolutionary algorithm (MOEA) to get optimal solutions.", "cite_spans": [], "section": "Gaining recommendation information based on MOEA", "sec_num": "4."}, {"text": "Strength Pareto evolutionary algorithm (SPEA2) [46] is a widely used MOEA and it is good at solving low-dimensional multi-objective optimization problems. The API recommendation problem is modeled as a two-objective optimization problem, a low-dimensional optimization problem, in our approach. Besides, study [37] has experimented that SPEA2 performs better than other algorithms (i.e. MOEA/D, NSGA-II, etc.) regarding the distributivity of the solution and the convergence of the algorithm. Therefore, we choose it as the basic algorithm in our approach to get APIs for the recommendation. Before applying SPEA2, we need to model the solution of practical in a form that the algorithm can handle and give the initial population for further evolution.", "cite_spans": [{"start": 47, "end": 51, "text": "[46]", "ref_id": "BIBREF43"}, {"start": 310, "end": 314, "text": "[37]", "ref_id": "BIBREF34"}], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "With respect to solution representation, usually, a candidate solution is represented in the form of a number of decision variables that need to be optimized through an evolutionary search process. As the results we want to find is a list of method-level APIs that can be used for implementing the developer's target functionality, a feasible solution is encoded as a chromosome of length k by using vector representation, where: each bit of the chromosome corresponds to a method-level API; the length of the chromosome denotes the number of APIs in an API list. This means that any combination of k APIs contained in the dataset can be a candidate solution for our method. Part A of Fig. 4 shows an example of a chromosome that contains six APIs, and for readers' convenience, we use the API name instead of the API numerical ID in the illustration.", "cite_spans": [], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "With respect to the initial population for MOEAs, it can be generated randomly or based on prior knowledge. Considering that prior knowledge can provide a high-quality initial population which can speed up the global convergence and search efficiency of the algorithm [5] , we generate the population for our method based on the API knowledge used for functionality implementation in code.", "cite_spans": [{"start": 268, "end": 271, "text": "[5]", "ref_id": "BIBREF2"}], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "Since the semantics of the method name can reflect the functionality it implements [12] [6], we believe the APIs contained in the methods semantically similar to target functionality are more appropriate for implementing the target functionality and can be used to form the initial population compared to the randomly selected APIs. Thus, we use the target functionality-related API knowledge in our dataset to guide the population initialization. Based on this idea, we apply our previous work [23] to extract the target functionality from developer's query noted as f, which consists of nouns and verbs. Then we take each verb and noun as a sub-functionality f sub of f and give the following steps to get the initial population in our problem:", "cite_spans": [{"start": 83, "end": 87, "text": "[12]", "ref_id": "BIBREF9"}, {"start": 495, "end": 499, "text": "[23]", "ref_id": "BIBREF20"}], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "Firstly, we traverse the FCGs to find all non-API nodes (methods in apps) and segment the method names into words according to Snake case and Camel case. The verbs and nouns in the method names are selected as keywords to represent the functionality the corresponding methods realize;", "cite_spans": [], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "Secondly, the semantic similarity between the keywords (method) and the target functionality is calculated based on the following formula:", "cite_spans": [], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "Sim(method, f sub ) = i\u2208{verb,noun} w i \u00d7 S i (method, f sub ) (1)", "cite_spans": [], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "where S noun (method, f sub ) denotes the maximum semantic similarity between nouns of the keywords and the noun part of target functionality, S verb (method, f sub ) denotes the maximum semantic similarity between verbs of the keywords and the verb part of sub-functionality. Here we use word2vec to calculate the similarity S i between two words. Note that if the keywords of the method only contain nouns the w verb should be set to 0.", "cite_spans": [], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "Thirdly, if the value of Sim(method, f sub ) is less than the threshold, it means that the method is irrelevant to the subfunctionality. Otherwise, we consider it is the sub-functionality related one. After processing all sub-functionalities of f we obtain the final target functionality-related methods.", "cite_spans": [], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "Finally, we randomly select j methods from the target functionality-related methods. For each selected method, we parse it to gain the API invocation list (APIs invoked by the selected method) and take first the k APIs in the list to form a k length chromosome for forming the initial population. If the length of the API invocation list is smaller than k, we randomly select a chromosome already formed to present its corresponding chromosome.", "cite_spans": [], "section": "Solution representation and population initialization", "sec_num": "4.1."}, {"text": "Fitness is the criterion for selecting the best chromosomes from the population in MOEA and it simulates the \"survival of the fittest\" in the natural selection process. In our approach, we define a multi-objective function that simultaneously optimizes the following two objectives as the fitness function to measure the merit of a candidate solution.", "cite_spans": [], "section": "Fitness evaluation", "sec_num": "4.2."}, {"text": "Maximize structural similarity. This objective function is to measure the similarity between the structural information vectors corresponding to the APIs in a candidate solution. API structural information represents the call relations between collaborative APIs. Since such APIs are closer in the FCG, their corresponding structural information vectors embedded by node2vec are similar. Thus, by finding the APIs whose structural information vectors are similar, we get the APIs that may be invoked together to implement the same target functionality. Let Sol a candidate solution, which contains a list of APIs Sol = {api 1 , api 2 , ..., api m } for implementing the target functionality of developers. The structural similarity is calculated by the following formula:", "cite_spans": [], "section": "Fitness evaluation", "sec_num": "4.2."}, {"text": "Dis(Sol) = \u2200(api i ,api j )\u2208Sol,api i =api j dis(api i , api j ) |sol|times(|sol|-1) 2 (2)", "cite_spans": [], "section": "Fitness evaluation", "sec_num": "4.2."}, {"text": "where dis(api i , api j ) is the euclidean distance between the structural information vectors of api i and api j . The shorter the distance is, the more similar the vectors are.", "cite_spans": [], "section": "Fitness evaluation", "sec_num": "4.2."}, {"text": "2 is the total number of possible pairs (api i , api j ) to scale the objective function.", "cite_spans": [], "section": "|sol|times(|sol|-1)", "sec_num": null}, {"text": "The Dis(Sol) is a minimum optimization function, which means the smaller the function value is, the structural information vectors of APIs in the candidate solution Sol are more similar. For the convenience of understanding, we use the formula: Sim structural (Sol) = C -Dis(Sol) to calculate the maximum structural similarity, where C is a very large constant. In this case, the larger the value of Sim structural (Sol) is, the more similar the structure of each API in a candidate solution is.", "cite_spans": [], "section": "|sol|times(|sol|-1)", "sec_num": null}, {"text": "Maximize semantic similarity. This objective function is to measure whether the semantic information of each API in a candidate solution is similar to the developer's target function. APIs that are semantically similar to the target functionality tend to be utilized for implementing the functionality [12] [6]. For a candidate solution Sol = {api i , api 2 , ..., api m } the semantic similarity between it and the developer's target function is computed by the follows:", "cite_spans": [{"start": 302, "end": 306, "text": "[12]", "ref_id": "BIBREF9"}], "section": "|sol|times(|sol|-1)", "sec_num": null}, {"text": "Sim semantic (Sol) = |Sol| i=1 Sim(api i , f ) |Sol| (3)", "cite_spans": [], "section": "|sol|times(|sol|-1)", "sec_num": null}, {"text": "where,", "cite_spans": [], "section": "|sol|times(|sol|-1)", "sec_num": null}, {"text": "Sim(api i , f ) = Max Sim(api semantic i , f ) (4)", "cite_spans": [], "section": "|sol|times(|sol|-1)", "sec_num": null}, {"text": "api semantic i is the semantic information matrix of api i , and f denotes the semantic vector of the developer's target function.", "cite_spans": [], "section": "|sol|times(|sol|-1)", "sec_num": null}, {"text": ", f ) denotes the maximum of each API semantic information vector in the semantic information matrix of api i and f . We take the value of Max Sim(api semantic i , f ) as the maximum semantic similarity between developer's target functionality and api i . Note that Sim(api i , f ) is calculated by word2vec.", "cite_spans": [], "section": "Max Sim(api semantic i", "sec_num": null}, {"text": "For a candidate solution, the larger the fitness value of the solution is, the more likely it is to be selected to form the new generation, otherwise it will be eliminated.", "cite_spans": [], "section": "Max Sim(api semantic i", "sec_num": null}, {"text": "MOEA uses genetic operators for solution iteration. In our approach, by changing the genotype of the parent-solutions, the crossover and mutation operators produce massive new solutions (lists of APIs). This is helpful for overcoming the limitation of low-volume API knowledge in lightweight data. Moreover, these solutions contain lots of new API knowledge different from what is applied in the apps of our dataset, and it may give developers new ideas on API usage.", "cite_spans": [], "section": "Genetic operators", "sec_num": "4.3."}, {"text": "The crossover operator generates new solutions by combining parent solutions in last iteration. In our approach, we apply the single, random cut-point crossover operator for constructing a newborn solution based on two parent-solutions. The crossover process is shown in Part B of Fig. 4 . For the two parent-solutions, we choose a random position from them as the crossover point. Then, a child solution is generated by combining the left part of its first parent and the right part of its second parent. Similarly, we generate another child solution by combining the left part of its second parent and the right part of its first parent.", "cite_spans": [], "section": "Crossover operator", "sec_num": null}, {"text": "The mutation operator changes one bit of the selected solution with a certain probability. In our approach, we take p as the mutation probability. Suppose a population has a chromosomes and each chromosome as a candidate solution contains b APIs, then the total mutation position is abp. The following formulas are used to determine the position of which chromosome in the population is the mutation position.", "cite_spans": [], "section": "Mutation operator", "sec_num": null}, {"text": "chromosome index = abp a (5) bit index = abp%a (6)", "cite_spans": [], "section": "Mutation operator", "sec_num": null}, {"text": "According to the above formulas, we find that the mutation occurs in bit th index position of the chromosome th index chromosome. Then an API is randomly selected to replace the API at the mutation location.", "cite_spans": [], "section": "Mutation operator", "sec_num": null}, {"text": "A candidate solution in our approach corresponds to a list of collaborative APIs implementing the target functionality, where there should be no duplicate APIs. Given this, we perform the redundancy check on the APIs contained in the newly produced ones: If a solution includes duplicate APIs, then we do not let it form the new generation but continue to generate a new solution until there are no duplicate APIs in it. Finally, we take such solutions to form the new population.", "cite_spans": [], "section": "Mutation operator", "sec_num": null}, {"text": "Furthermore, we apply the Pareto-optimality principle in the process of population evolution to make the solutions converge to the Pareto front. This ensures that the final results we get are the optimal API knowledge for implementing the target functionalities of developers.", "cite_spans": [], "section": "Mutation operator", "sec_num": null}, {"text": "Overall, in our approach, we model the process of recommending API knowledge based on the developer's target functionality as a multi-objective optimization problem. The details of SPEA2 can be seen at [46] . After solving it with a multi-objective evolutionary algorithm, we obtain multiple genes (lists of APIs) that satisfy the target functionality as the recommendation information of our approach.", "cite_spans": [{"start": 202, "end": 206, "text": "[46]", "ref_id": "BIBREF43"}], "section": "Mutation operator", "sec_num": null}, {"text": "Although the Pareto optimal solutions returned by SPEA2 give the APIs satisfying the developers' demands (target functionalities), it is not easy for developers to understand and use them directly. Because referring to the code examples that use an API is a common way for developers to learn the API [16] . Thus, we analyze the code containing the recommended APIs to describe its usage scenarios for helping developers better understand the usage of recommended APIs. In Fig. 5 , we take \"get image\" as the target functionality to illustrate the details of this process.", "cite_spans": [{"start": 301, "end": 305, "text": "[16]", "ref_id": "BIBREF13"}], "section": "Associating API usage scenarios with recommendation information", "sec_num": "5."}, {"text": "For each recommended API, we traverse the FCGs of each app in our dataset with API's name as the index to find its related subgraph: methods that call API and call relations between the methods. However, not all API adjacent methods are related to the target functionality. Therefore, we filter the non-related ones before further analyzation as follows. Since the method name reflects the functionality it implements [12] [6], we take the semantic similarity between the method name and the target functionality as the indicator to judge whether the method is related to the target functionality or not. In this process, we use the intermediate results of MOEA in Section 4.1, but only take the semantic similarity between the nouns in the target functionality and the nouns in the method name for judging whether the method is target functionality related.", "cite_spans": [{"start": 418, "end": 422, "text": "[12]", "ref_id": "BIBREF9"}], "section": "Recommended API related subgraph extraction", "sec_num": "5.1."}, {"text": "Because we believe that taking verbs into semantic similarity calculation may be too strict and result in only a few methods left for fully presenting target functionality related information. As for the target functionality \"get image\", if we also calculate the similarity between \"get\" and verbs in method names, we only gain a few methods strictly related to \"get image\", such as \"getImage()\", \"getImageTintList()\", etc. However, only considering the semantic similarity between \"image\" and nouns method names can reserve more diverse methods related to \"Image\", such as \"saveImage()\", \"setImage()\", etc. Such methods may cooperate with the target functionality \"get image\" to realize a complex task. Using these methods for API usage knowledge illustration may help developers comprehend the usage of the recommended API from a high perspective.", "cite_spans": [], "section": "Recommended API related subgraph extraction", "sec_num": "5.1."}, {"text": "For an app, by taking above analysis into consideration, we finally extract recommended API related subgraphs in app: shows the target functionality related methods calling A P I i and the call relations between them.", "cite_spans": [], "section": "Recommended API related subgraph extraction", "sec_num": "5.1."}, {"text": "subgraph set app =", "cite_spans": [], "section": "Recommended API related subgraph extraction", "sec_num": "5.1."}, {"text": "However, sub graph set app cannot be used to illustrate API usage scenarios directly as we find some redundant information exists in sub graph set app , such as the same nodes appear in different subgraphs because some methods call different APIs. Therefore, we further integrate the subgraphs in sub graph set app and associate code samples with the nodes (methods) of these subgraphs to form the API usage scenario graph (AUSG) of the target functionality in app for developers to refer to.", "cite_spans": [], "section": "Related subgraphs integration", "sec_num": "5.2."}, {"text": "For sub graph set app , we merge the subgraphs into one graph ( A SU G app : API usage scenario graph of app) by removing duplicate nodes while keeping the call relations unchanged. The detailed information about this process is illustrated in Fig. 5 .", "cite_spans": [], "section": "Related subgraphs integration", "sec_num": "5.2."}, {"text": "Firstly, we get the matrix presentation of each subgraph; Secondly, we obtain the matrix of A SU G app by performing the union operation on all subgraphs' matrices; Thirdly, to prevent missing call relations between methods in different subgraphs, we further checked the call relations between nodes in A SU G app . When a call relation is not represented in the matrix of A SU G app , we complete it into the matrix;", "cite_spans": [], "section": "Related subgraphs integration", "sec_num": "5.2."}, {"text": "Finally, we construct the A SU G app based on its matrix presentation and apply androguard to get method related code and associate the code with each node (method) in A SU G app for the convenience of developers' reference.", "cite_spans": [], "section": "Related subgraphs integration", "sec_num": "5.2."}, {"text": "After process all the apps in our dataset, we get their AUSGs: A SU G set = {A SU G app 1 , ..., A SU G app n }. Here, A SU G app i denotes the information of \"get image\" related API usage scenario of app i .", "cite_spans": [], "section": "Related subgraphs integration", "sec_num": "5.2."}, {"text": "It can be seen in the bottom part of Fig. 5 , methods \"getImageHeight()\", \"getImageWidth()\" \"setImageMatrix()\", \"savePre-viousImageValues()\" and \"fitImageToView()\" in app are \"get image\" related methods for they all invoke APIs our approach recommend according to target functionality \"get image\" and cooperate with each other during program execution. This reflects the implementation structure of \"get image\", even a more complex progress related to \"image\". With the assistance of the semantics of method name in A SU G app , developers can realize that for implementing \"fit an image to view\", they may need to define some methods to obtain the height and width of the image and take some operations on the matrix of the image. Further referring to the code of the methods, developers gain a comprehensive perspective of the usage of recommended APIs.", "cite_spans": [], "section": "Related subgraphs integration", "sec_num": "5.2."}, {"text": "Since the number of edges in one AUSG indicates the richness of the call relations: the richer the call relation is, the more API usage knowledge is described in the graph. Thus, we further sort the graphs in ASUG set in descending order by the number of edges in the graph. This makes developers easy to find suitable API usage scenarios according to the richness of call relations.", "cite_spans": [], "section": "Related subgraphs integration", "sec_num": "5.2."}, {"text": "To help the end users have an overall picture of our approach, we present a specific process from the users' perspective to illustrate how to use our approach to find API knowledge related to the target functionality they want to implement. This process is shown in Fig. 6 to enable users to understand our method recommendations intuitively.", "cite_spans": [], "section": "Guideline of our approach", "sec_num": "6."}, {"text": "Suppose there is a developer named John who has just graduated from college and begun his career as an Android application developer. Currently, he is developing an application in the \"Photography\" category and he wants to get images and perform further operations on them. At this time, John wants to use our approach to find out some API knowledge that may be used to implement the target functionality \"Get Image\".", "cite_spans": [], "section": "Guideline of our approach", "sec_num": "6."}, {"text": "To achieve this goal, John only needs to do the following two things:", "cite_spans": [], "section": "Guideline of our approach", "sec_num": "6."}, {"text": "Although our approach utilizes the structural and semantic API information for API recommendation, the API semantic information used by our method is contained in the API descriptions, which is relatively fixed. Therefore we directly crawled the official Android API documentation and take the API semantic information contained in it as the build-in data of our method.", "cite_spans": [], "section": "Collecting data", "sec_num": null}, {"text": "Thus, as the user of our approach, if John or his colleagues have already collected similar applications during the product research phase, he can submit such data to our approach for analysis. Otherwise, we need John to collect the APK files containing the API structural information before using our method to get the API knowledge he needs. Specifically, we need John to collect some APK files from the \"Photograph\" category on Google play since he develops this type of application. We believe the data John collects is based on his domain expertise and is closer to the application he wants to develop. The API structural information contained in such data can help our method determine appropriate API knowledge to implement the target functionality \"Get Image\" of John.", "cite_spans": [], "section": "Collecting data", "sec_num": null}, {"text": "After collecting data in John's domain, he should give his target functionality to be implemented. Then he enters it into our method as illustrated in part A of Fig. 6 and gets the API knowledge related to the target functionality recommended by us as shown in part B and C of Fig. 6 .", "cite_spans": [], "section": "Giving the target functionality", "sec_num": null}, {"text": "Specifically, Part B shows a list of APIs our approach finds suitable to implement John's target functionality. For each recommended API, we provide its description, API level, corresponding Android OS version and change information of the API (whether the recommended API is still under maintenance or not) as the supplementary information for John to quickly learn the functionality of that API. Furthermore, for helping John learn the usage of the APIs we recommend for \"Get Image\", we also offer some API usage scenarios (code examples applying the recommended APIs) for reference in Part C. Such information describes the methods in code that invoke the API we recommend and the call relationships between them, which can illustrate the using context of the recommended APIs.", "cite_spans": [], "section": "Giving the target functionality", "sec_num": null}, {"text": "To evaluate our approach, we conduct a series of experiments for answering the following two questions:", "cite_spans": [], "section": "Experiments and results", "sec_num": "7."}, {"text": "\u2022 RQ1 (Effectiveness): Does our approach recommend appropriate API knowledge for implementing the target functionalities effectively?", "cite_spans": [], "section": "Experiments and results", "sec_num": "7."}, {"text": "\u2022 RQ2 (Usefulness): Is our approach user-friendly in API recommendation tasks practically? Specifically, RQ1 focused on inspecting the performance of our approach in mining appropriate API knowledge from the dataset according to the target functionalities of developers. The goal of RQ2 was to evaluate the experience of using our approach from the perspective of users.", "cite_spans": [], "section": "Experiments and results", "sec_num": "7."}, {"text": "Two types of data are utilized in our experiments: APK files of apps from Google Play and API descriptions in Android Tutorial. They serve as the input data to our approach. We recommend API knowledge based on the structural and semantic information within such data. We collect these data and perform our method on them to obtain proper API knowledge according to developers' target functionalities for evaluation.", "cite_spans": [], "section": "Data and participants", "sec_num": "7.1."}, {"text": "Specifically, with respect to APK files, as our method uses data provided by developers who may be in different domains, we collected APK files from Google play in five categories on Google Play, including \"Social\", \"Photography\", \"Music&Audio\", \"Maps&Navigation\" and \"Education\" to evaluate the applicability of our method comprehensively. Furthermore, we choose three common metrics (rating, APK size and updated time) in app stores as the criteria for collecting data to make our collection close to developers' collection as much as possible, considering that developers may take different criteria into account when collecting data. For each category, we rank the applications according to rating, APK size and update time separately, and then select the top 150 applications from the intersection to form the dataset of our approach. In this way, we totally get 750 APK files at last, which contain 106,775 java API methods and 65,407 android API methods as our experimental dataset. As for API description, we simply crawl the data from Android Tutorial.", "cite_spans": [], "section": "Data and participants", "sec_num": "7.1."}, {"text": "The participants of our experiments are 15 developers and 30 students as shown in Table 1 . The developers are from 10 different companies and have more than five years of software development experience. All the students are from Jilin University and have no development experience in software engineering. We required them to evaluate whether the API knowledge recommended by our approach is user-friendly to developers in practice or not. Note that the core code and results of our experiments are provided online. 1", "cite_spans": [], "section": "Data and participants", "sec_num": "7.1."}, {"text": "We evaluate the precision of our approach in API recommendation as the indicator of the performance of our approach by observing whether the APIs recommended by us are applied in the implementation of practical programming tasks.", "cite_spans": [], "section": "Experimental design", "sec_num": null}, {"text": "Specifically, firstly we construct the ground-truth set by collecting practical programming tasks related Q&As from Stack Overflow;", "cite_spans": [], "section": "Experimental design", "sec_num": null}, {"text": "Secondly, we perform our method on the data (APK files of each app category and API descriptions) collected for experiments and take the functionalities in the ground-truth set as the queries of developers to input into our method to get functionalities related API knowledge for recommendation;", "cite_spans": [], "section": "Experimental design", "sec_num": null}, {"text": "Thirdly, we calculate the recommendation precision of our approach based on the recommendation results with our experimental metrics;", "cite_spans": [], "section": "Experimental design", "sec_num": null}, {"text": "Finally, we compare our recommendation results with other API recommendation approaches for measuring the performance of our approach comprehensively.", "cite_spans": [], "section": "Experimental design", "sec_num": null}, {"text": "Stack Overflow, one of the most popular developer forums, contains extensive API knowledge related to the implementation of specific functionalities in real-world programming tasks. Collecting the functionalities and the corresponding APIs used in their implementations helps us construct the ground-truth set for evaluating if the API knowledge recommended by our approach can be used to implement the target functionalities of developers.", "cite_spans": [], "section": "Constructing the ground-truth set of RQ1", "sec_num": null}, {"text": "In our previous work [23] , we have already constructed the ground-truth set for recommendation precision evaluation. We directly apply it here and give a brief introduction to the process of the ground-truth set construction.", "cite_spans": [{"start": 21, "end": 25, "text": "[23]", "ref_id": "BIBREF20"}], "section": "Constructing the ground-truth set of RQ1", "sec_num": null}, {"text": "Specifically, we first select queries for retrieving API knowledge on Stack Overflow. Research [16] shows that developers tend to use the target functionality to be developed as queries for retrieving API knowledge applied in functionality implementation. Our previous work finds that app descriptions contain the functionalities of applications. Therefore, we take the functionalities in app descriptions to search API knowledge. Since our experimental data contains five categories of applications, we construct the corresponding truth sets for each category to measure the performance of our approach comprehensively.", "cite_spans": [{"start": 95, "end": 99, "text": "[16]", "ref_id": "BIBREF13"}], "section": "Constructing the ground-truth set of RQ1", "sec_num": null}, {"text": "For each category, we take the functionalities from the descriptions of apps, which are not the ones in our experimental dataset but in the same category, as the queries for searching related Q&As on Stack Overflow. We filter out those functionalities which cannot be found with API knowledge on Stack Overflow. Regarding the searching results (functionalities related Q&As), we only keep the ones satisfying the following two criteria: 1) the question score is positive; and 2) the has at least one answer which API entities and the score of the corresponding answer is positive.", "cite_spans": [], "section": "Constructing the ground-truth set of RQ1", "sec_num": null}, {"text": "The first criterion ensures that the data we collect has high quality. The second allows the APIs we collect are accurate because there are developers who agree with the APIs in such answers can implement the functionalities in the corresponding questions. In this way, we totally collect 37,658 questions with 250 functionalities (each category in our dataset with 50 functionalities).", "cite_spans": [], "section": "Constructing the ground-truth set of RQ1", "sec_num": null}, {"text": "Then we randomly select 10,000 questions and let the first author and student participants manually label and remove some inappropriate ones that do not aim to search APIs for implementing target functionalities. In this process, Fleiss Kappa [3] is applied to measure the agreement between the labelers. Only the kappa value is bigger than our threshold, we believe the labelers achieve almost perfect agreement. After completing this manual labeling process, all the labelers discuss their disagreement together to reach a common decision. In this way, we finally collect 7,359 questions as well as their answers and use the functionalities in questions and APIs in the corresponding answers (< f unctionalit y, A P Is in f unctionalit y related answers >) to construct our ground-truth set for our experiments.", "cite_spans": [{"start": 243, "end": 246, "text": "[3]", "ref_id": "BIBREF0"}], "section": "Constructing the ground-truth set of RQ1", "sec_num": null}, {"text": "The experimental metrics used to measure the recommendation precision of our approach are as follows:", "cite_spans": [], "section": "Experimental metrics of RQ1", "sec_num": null}, {"text": "\u2022 Precision@N, which is used to calculate the precision of top-N API recommended by our approach. The formula of Precision@N is shown as follows:", "cite_spans": [], "section": "Experimental metrics of RQ1", "sec_num": null}, {"text": "EQUATION", "cite_spans": [], "section": "Experimental metrics of RQ1", "sec_num": null}, {"text": ")", "cite_spans": [], "section": "Experimental metrics of RQ1", "sec_num": null}, {"text": "where f unctionalit y matched denotes the APIs our approach recommends according to f unctionalit y has at least one in its corresponding APIs in the ground-truth set. | f unctionalit y| denotes the number of functionalities in the ground-truth set.", "cite_spans": [], "section": "Experimental metrics of RQ1", "sec_num": null}, {"text": "\u2022 Mean Average Precision@N(MAP@N), which is used to evaluate the precision of recommendation results in information retrieval. To calculate the value of M A P @N, we first calculate the value of A P @N with the following formula:", "cite_spans": [], "section": "Experimental metrics of RQ1", "sec_num": null}, {"text": "A P @N = N k=1 P (k) \u00d7 rel(k)", "cite_spans": [], "section": "Experimental metrics of RQ1", "sec_num": null}, {"text": "number of relevant A P I s (8) where P (k) is the precision at a cut-off rank k in the API list we recommend. As for rel(k), if the API at the rank k appears in the APIs in the ground-truth set of the same functionality, its value is 1, otherwise is 0. The", "cite_spans": [{"start": 27, "end": 30, "text": "(8)", "ref_id": "BIBREF5"}], "section": "Experimental metrics of RQ1", "sec_num": null}, {"text": "The precision scores of different categories.", "cite_spans": [], "section": "Table 2", "sec_num": null}, {"text": "Precision@N MAP@N MRR P@3 P@5 P@10 MAP@3 MAP@5 MAP@10 number of relevant A P I s denotes the number of APIs which are invoked for implementing the functionality. But it is difficult for us to ensure that value. Like the previous study [45] , we let the relevant APIs be the top-N APIs in our recommendation list that match an answer from Stack Overflow for a target functionality from the total set of relevant APIs for the target functionality. Then the following formula is used to calculate M A P @N:", "cite_spans": [{"start": 235, "end": 239, "text": "[45]", "ref_id": "BIBREF42"}], "section": "Table 2", "sec_num": null}, {"text": "M A P @N = | f unctionality| i=1 A P @N | f unctionality| (9)", "cite_spans": [], "section": "Table 2", "sec_num": null}, {"text": "\u2022 MRR (Mean Reciprocal Rank), which is a metric used to calculate the recommendation accuracy. The formula of M R R is shown as follows:", "cite_spans": [], "section": "Table 2", "sec_num": null}, {"text": "EQUATION", "cite_spans": [], "section": "Table 2", "sec_num": null}, {"text": ")", "cite_spans": [], "section": "Table 2", "sec_num": null}, {"text": "where | f unctionalit y| refers the number of functionalities in the ground-truth set. rank i denotes the location of the first relevant API among the API list recommended by our approach according to the i th functionality in the ground-truth set.", "cite_spans": [], "section": "Table 2", "sec_num": null}, {"text": "Based on the above metrics, we calculate the recommended accuracy of our method. Specifically, for each functionality, we compare APIs recommended by our method with its corresponding APIs in the ground-truth set: if one API we recommend also appears in the ground-truth set, we regard it as a matched recommendation. Namely, this API can be used to implement the functionality in the developer's query. After evaluating all functionalities in the ground-truth set, we get the precision of our method in recommending APIs based on the target functionalities in different categories for measuring the performance of approach on API recommendation.", "cite_spans": [], "section": "Table 2", "sec_num": null}, {"text": "We further adopt the following two state-of-the-art methods as the baselines for illustrating the performance of our approach in API recommendation comprehensively.", "cite_spans": [], "section": "Comparing approaches of RQ1", "sec_num": null}, {"text": "\u2022 LibraryGuru. Yuan et al. [45] implement LibraryGuru, a prototype of API recommendation engine, by mining the API semantic information in Android Tutorial and SDK reference documents to recommend API knowledge.", "cite_spans": [{"start": 27, "end": 31, "text": "[45]", "ref_id": "BIBREF42"}], "section": "Comparing approaches of RQ1", "sec_num": null}, {"text": "\u2022 GAPI. Ling et al. [21] propose GAPI, a novel machine-learning-based approach for API usage recommendation, which applies graph neural networks (GNNs) to capture the structural information of projects and incorporates text information in code in the networks to present the program semantics for recommending APIs.", "cite_spans": [{"start": 20, "end": 24, "text": "[21]", "ref_id": "BIBREF18"}], "section": "Comparing approaches of RQ1", "sec_num": null}, {"text": "Table 2 shows the experimental results of API recommendation precision of our approach. We can see that our approach achieves good performance in every category. The precisions of API recommendation are up to 0.72 at top-3, 0.78 at top-5 and 0.89 at top-10 respectively. The mean average precision scores of our method are up to 0.50 at top-3, 0.49 at top-5 and 0.44 at top-10. The mean reciprocal rank score can be up to 0.69. This means for a given feature, our approach could recommend proper API knowledge according to the target functionalities of developers to help their development.", "cite_spans": [], "section": "Experimental results of RQ1", "sec_num": null}, {"text": "In spite of having high precision of our approach in API knowledge recommendation, we still find some shortcomings: (1) Some APIs supposed to be recommended are not found by our method. We believe this is because Stack Overflow contains a rich knowledge of APIs. This makes the true set built based on it containing a large variety and number of APIs. While our method is based on a small dataset for API recommendation, some APIs may not be collected at all and thus cannot be recommended. (2) Some APIs are recommended incorrectly. This is caused by the limitations of graph embedding and word embedding techniques. Although these techniques are relatively mature, there are still some cases that cannot be handled properly, which makes representations of the structural and semantic information of APIs have errors, resulting in some unrelated APIs being recommended.", "cite_spans": [], "section": "Experimental results of RQ1", "sec_num": null}, {"text": "Furthermore, some recommendation results in our experiments exhibit the ability of our approach in mining new API knowledge. Specifically, there are some APIs specific to the latest API level (level 30) are recommended, such as: \"android.view.textclassifier.TextLinks.getText();\", \"android.os.Environment.getStorageDirectory();\", etc. This is because the applications in the dataset used by our method correspond to API level 30. When we switch the APK files in our dataset to API level 29, these API level 30 specific recommendation results do not appear. We think this reflects the adaptability of our method to some extent. When a new version of API level appears, it is easier to collect applications developed based on the latest API level since we use a small-scale database, which ensures that the API knowledge recommended by our method is up-to-date. Overall, the above experimental results illustrate that our approach is able to obtain up-to-date API knowledge from a small-scale dataset and make accurate recommendations.", "cite_spans": [], "section": "Experimental results of RQ1", "sec_num": null}, {"text": "To illustrate the performance of our approach comprehensively, we further compare our recommendation results with our baselines' recommendation results. In this process, for the sake of fairness of the experimental comparison, we replicate our baselines GAPI and LibraryGuru according to their papers and perform them on our dataset to obtain the comparison results with the experimental metrics and we denote them as GAPI_replicated and LibraryGuru_replicated separately.", "cite_spans": [], "section": "Experimental results of RQ1", "sec_num": null}, {"text": "Table 3 shows the comparison results between our approach and baselines. It can be seen that our approach achieves the best performance in all experimental metrics compared with all baselines.", "cite_spans": [], "section": "Experimental results of RQ1", "sec_num": null}, {"text": "Compared with LibraryGuru_replicated, the improvement of our approach on recommendation precision at top-3, top-5 and top-10 are 53.5%, 41.2% and 28.1% respectively. The improvement in mean average precision at top-3, top-5 and top-10 are 91.7%, 24.2% and 19.4%. In terms of mean reciprocal rank, our improvement is 48.8%. Such results indicate that our approach has a better performance than LibraryGuru. We believe this means considering both structural and semantic information of APIs improves the recommendation accuracy compared with simply using API semantic information for API recommendation.", "cite_spans": [], "section": "Experimental results of RQ1", "sec_num": null}, {"text": "Compared with GAPI_replicated, in terms of recommendation precision, the improvement of our method at top-3, top-5 and top-10 are 106.3%, 242.9% and 412.5%. The improvement in mean average precision at top-3, top-5 and top-10 are 1,050%, 485.7% and 640%. As for mean reciprocal rank, our method's improvement is 195.5%. Based on such results, we think our method has a significant improvement over GAPI_replicated on the API recommendation task. This is probably because GAPI as a machine learning-based method requires large-scale data training to achieve better recommendation results, whereas our small-scale data is not enough to support GAPI to learn a good model, which is also illustrated by the authors of GAPI in the original paper [21] . However, we consider such comparison results just show that our method can achieve good recommendation results on small-scale datasets. With the above results we believe that on our small dataset, our approach can achieve good recommendation results.", "cite_spans": [{"start": 741, "end": 745, "text": "[21]", "ref_id": "BIBREF18"}], "section": "Experimental results of RQ1", "sec_num": null}, {"text": "We evaluate the user-friendliness of our approach with the following two sub-questions:", "cite_spans": [], "section": "The experiment for RQ2", "sec_num": "7.3."}, {"text": "\u2022 RQ2.1: What is the performance of our approach in comparison with a machine-learning-based one? \u2022 RQ2.2: Does the API knowledge recommended by our method helps users to improve their development efficiency? RQ2.1 measures the performance of our approach against the machine-learning-based method in terms of data volume, runtime and hardware. RQ2.2 evaluates whether the API knowledge we recommend is easily for users to use.", "cite_spans": [], "section": "The experiment for RQ2", "sec_num": "7.3."}, {"text": "We compare GAPI and our method based on our dataset, and use the following metrics for evaluating their performance:", "cite_spans": [], "section": "Experimental design of RQ2.1", "sec_num": null}, {"text": "\u2022 Training time, which measures the time it takes from model initialization to training completion.", "cite_spans": [], "section": "Experimental design of RQ2.1", "sec_num": null}, {"text": "\u2022 Response time, which measures the time it takes for the method from receiving a user request to giving the recommendation result.", "cite_spans": [], "section": "Experimental design of RQ2.1", "sec_num": null}, {"text": "\u2022 Data volume, which measures how much data is used to train the model by the method.", "cite_spans": [], "section": "Experimental design of RQ2.1", "sec_num": null}, {"text": "\u2022 Hardware, which indicates the condition of the device which runs the method.", "cite_spans": [], "section": "Experimental design of RQ2.1", "sec_num": null}, {"text": "The process of experiments consists of two phases: the training phase and the testing phase. For each category, the dataset of the experiment also includes two parts: 150 app products as the training set, and 50 functionalities (from other apps) with their corresponding APIs in the ground-truth set as the test set. To illustrate the process clearly, we use the category \"Photography\" as an example to show the details of the experiment:", "cite_spans": [], "section": "Experimental design of RQ2.1", "sec_num": null}, {"text": "In the training phase, as for GAPI, we use 150 APK files of the products to train the machine-learning-based model; meanwhile, we use the same data as well as API description texts to train our model. The training time is recorded. Then, Detailed questions for the questionnaire.", "cite_spans": [], "section": "Experimental design of RQ2.1", "sec_num": null}, {"text": "Question 1 Does the API knowledge recommended by our approach easy to understand for you? Question 2", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "Are the results of our recommendations easy to use in practice?", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "in the testing phase, we simulated a real use scenario of the model: a functionality is given to the model to gain its API recommendation list. For example, a functionality \"Get Image\" is input to the two models separately, and the time of each model recommending 10 candidate APIs is recorded as the response time. The average time for all the functionalities in the test set is the response time of the method. We repeat the experiment on five categories of applications in our dataset, and the average training and response time are gained as the results for the comparison analysis.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "Experimental results of RQ2.1 Table 4 shows the comparison results of the capability between our approach and GAPI. Moreover, we compare our approach not only with the reimplemented GAPI but also with the original GAPI paper (denoted as GAPI_original) for comprehensive evaluation.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "Compared with GAPI_replicated, since we replicate it on our dataset with our device, the data volume and hardware it uses are the same as ours. In terms of training time, it can be seen that the training time of GAPI_replicated exceeds eight times the training time of our method under the same conditions. This is caused by the complex network structure used in GAPI requiring large amounts data for training, which costs long time. While our method uses small-scale data, the time for processing data will be shorter. As for the response time, GAPI_replicated's response time is much shorter than ours. This is due to that once the training of GAPI_replicated is completed, the API vector representations are available, and only vector operations are performed during the recommendation. In contrast, our approach adopts the multi-objective evolutionary algorithm, which takes several iterations to find the optimal solution, and a large amount of crossover and mutation operations are performed in each iteration. This process takes a lot of time. Besides, the lower computing power of our device also increases the time cost. However, even though the response time of GAPI_replicated is short, its recommendation precision is much lower than that of our method (GAPI_replicated is 0.16 vs. our approach is 0.82 at top-10 precision as shown in Table 3 ) which is not enough to complete the API recommendation task.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "In comparing with GAPI_original, it can be seen that GAPI_original uses large-scale data for training on its original settings. Our method only uses 150 projects, while GAPI_original needs 1,600 projects, which is more than ten times of our data volume. Such a large data scale not only increases the cost of data collection but also relies on better hardware devices to complete the training (using GPUs). Considering that the hardware and data volume our approach uses are ease-to-satisfy, which indicates that everyone can perform our approach on their dataset with a low cost. Moreover, we find that even with a better device, GAPI_original's training time is far longer than ours.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "Overall, our method needs shorter training time but has longer response time than the machine-learning-based one, and it has a better performance on API recommendation task, especially when only the small-scale dataset is available. In practice, developers can balance the (dis)advantages of different approaches to choose an appropriate one according to their demands.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "Experimental design of RQ2.2 For assessing whether the API knowledge recommended by our approach improves the development efficiency of users, we conducted a questionnaire survey on experimental participants mainly concerning the understandability and usability of the recommended results. The two questions we draft for this investigation are shown in Table 5 .", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "Before we give the survey to our participants, we make a demo applied our approach that offers some target functionalities randomly selected from our truth set and their corresponding recommended API knowledge. Then we introduce the demo to our participants to make sure that they fully understand it and they can give their judgments towards the above two questions based on data in the demo.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "For each analysis, we provided five options for each question for participants to choose: 1 strongly disagree, 2 disagree, 3 neither, 4 agree and 5 strongly agree. Furthermore, experimental participants are free to give their comments about each question, so that we can understand their opinions clearly.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "Experimental results of RQ2.2 Table 6 presents the feedback from our participants. With respect to the first question, it can be seen that more than half of the participants (30/45) think the API knowledge we recommend is easy for them to understand. Fifteen participants (15/45) hold different opinions, nine of them take the conservative opinions and the others give the negative feedback, but none of them denies the understandability of our recommendation results.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "To delve deeper into the reasons behind the experimental results, we further analyzed the comments of participants. From the comments of negative feedback, we summarize two main reasons for the disagreement: (1) The API knowledge corresponding to some target functions in the dataset is poor or inaccurate; (2) Some code samples are difficult to read.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "We further analyze the data in our demo and find that the first one is caused by the semantics of some special functionalities in app descriptions of some categories. For example, some apps in the \"Education\" category have the following features: \"Buy the app\", \"Learn the course\", etc. These functionalities themselves are difficult to find the corresponding APIs and we believe that this case already has been reflected in the data of recommendation accuracy for each category in experiment of RQ1. The accuracy of the recommendation of our method is able to indicate that the impact of this situation is weak.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "While the second one is due to the fact that the code obtained by decompiling the APK files does not have the corresponding comments. Some of the variables do not have real meanings: they may have been de-obfuscated or do not follow the naming convention, which makes the code hard to understand. This is a situation that cannot be solved by our method. However, since the code sample knowledge serves as the auxiliary information and many experimental participants considered such information helpful in understanding the recommended API knowledge, we believe that such impact is acceptable.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "With respect to the second question, the feedbacks are exciting. Over 86% (39/45) of participants believe that our recommendation results are easy to use in practice. Three participants hold conservative opinions and three participants have negative opinions. When we further analyze the comments in the feedback from these six participants, we find that the reason they think the recommendation results may not work very well is also due to the code samples in the recommendation results were not easy to understand. It has been analyzed as the second reason for question 1, therefore we do not mention it again.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "We also find a lot of positive comments on our approach in the feedback of experimental participants, which are summarized as follows: (1) AUSGs in our recommended results help developers understand the usage of the recommended API knowledge intuitively; (2) Offering code samples save developers the time of going to the forum posts to find code that contains recommended APIs.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "Besides, we also explore the composition of the participants holding various opinions. We found that students with little development experience are the majority among those who hold supportive opinions. We believe this indicates that our approach is applicable to newcomers. As for the composition of the negative opinions, we find developers with much experience are the majority. This indicates that our approach still needs to be optimized to suit the need of experienced developers.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "In summary, experimental participants believe the API knowledge recommended by our approach is user-friendly. They think the AUSGs reflect the code structure for using the recommended APIs to implement target functionality, which helps them digest the knowledge of API usage. Referring to the code samples corresponding to the methods in AUSGs saves the time cost of finding code containing the recommended APIs. This indicates the usefulness of our approach's recommended results in practice to some extent.", "cite_spans": [], "section": "Detailed questions", "sec_num": null}, {"text": "The experimental results show our approach achieves relatively good performance in API recommendation. However, the validity of our approach still has some potential threats. We analyze them from the following two aspects.", "cite_spans": [], "section": "Threats to the validity of experiments", "sec_num": "7.4."}, {"text": "The threats to the internal validity of our studies are mainly related to the errors in the implementation of our approach and the baseline methods. 1) In our approach, we adopt graph and word embedding algorithms to process the APK files and API descriptions separately to obtain the representation of API structural and semantic information. Even though these techniques have been already well-developed, there still exist some situations they cannot deal with. This may cause errors in the representations of APIs and has an impact on the performance of our approach. However, we have tried our best the choose suitable algorithms for our task to minimize such impact. 2) The baselines we choose are two state-of-theart methods for API recommendation. To make sure the fairness of comparison, we replicate their methods according to the published papers. However, even though the papers of these methods have a relatively clear statement of the models they apply, it is difficult for us to replicate them identically to their code. This may have an impact on the performance of the replication methods. Yet we make our best to ensure that all settings are consistent with the original paper when we replicate the model, which minimizes the impact of replication errors. Moreover, although fine-tuning the model can decrease the training time of the machine-learning-based baseline for it need not re-train the whole model, we do not fine-tune our baseline in the experiment because the fine-tuning is not stated as the capability of the baseline GAPI, and its effectiveness on the problem of API recommendation is still not validated.", "cite_spans": [], "section": "Threats to the validity of experiments", "sec_num": "7.4."}, {"text": "The threats to the external validity of our studies are mainly composed of four aspects. 1) We only evaluate the effectiveness and usefulness of our approach with our dataset. Therefore, we cannot assure that our method can achieve the same performance on other datasets as it performs on our dataset. 2) The Q&As collected from Stack Overflow to form the ground-truth set for evaluating API recommendation precision of our approach maybe not be enough to cover all API knowledge for practical functionalities implementation. This may result in some reasonable APIs being treated as inappropriate ones to reduce the recommendation precision of our method. 3) The degree of our experimental participants' subjective judgments and carefulness spent in our study may affect the validity. To reduce this threat, we recruit experiment participants who have extensive development experiences and a high level of expertise, and students who are interested and serious about our work. We believe this can reduce the impact as much as possible. 4) The questions in the questionnaire are expressed in a positive way. This may incline participants to respond positively. However, while answering the questions, participants are allowed to make comments to express their opinions clearly. This reduces the impact of the way of setting the questions.", "cite_spans": [], "section": "Threats to the validity of experiments", "sec_num": "7.4."}, {"text": "Many approaches have been proposed to recommend appropriate API knowledge according to developers' target functionalities for improving the development efficiency. The works related to our approach are summarized into the following two categories.", "cite_spans": [], "section": "Related work", "sec_num": "8."}, {"text": "Many researchers build tools for recommending API knowledge to developers by utilizing the semantic information in the API-related data to bridge the lexical gap for API recommendation. Traditional API recommendation methods generally employ keyword matching to search relevant code snippets based on the lexical similarity between the searching query and source code [17] [22] . Since these approaches do not fully exploit the semantic information in the data, they expected carefully designed search queries containing the names of correlative API classes or methods and could not handle well for queries with flexible expressions.", "cite_spans": [{"start": 368, "end": 377, "text": "[17] [22]", "ref_id": null}], "section": "Related work", "sec_num": "8."}, {"text": "To fully \"understand\" developers' target functionalities, many natural language processing techniques have been applied to API recommendation for better capturing the semantic meaning of API-related information. Ferdian Thung et al. propose an automated approach to recommend methods in library APIs according to the features to be implemented by comparing the semantic information of the requested feature with the semantic information of the textual description of API documentations [41] . Xin Ye et al. bridge the lexical gap by projecting natural language statements and code snippets as meaning vectors in a shared representation space [43] . Mohammad Masudur Rahman et al. propose RACK, a novel API recommendation technique, for recommending relevant APIs for a natural language query by using the crowdsourced knowledge contained in Stack Overflow [35] . Xin Xia et al. propose BIKER to tackle the Task-API knowledge gap. They extract candidate APIs for a program task and rank APIs based on the similarity between the developer's query and Stack Overflow posts [16] [7] . Luca Poonzanelli et al. present PROMPTER, a plug-in for the Eclipse IDE which automatically searches and identifies relevant Stack Overflow discussions for recommendation [34] . Riccardo Rubei et al. propose PostFinder, an approach that analyzes the project under development to extract suitable context, and allows developers to retrieve messages from Stack Overflow being relevant to the API function calls that have already been invoked [38] .", "cite_spans": [{"start": 486, "end": 490, "text": "[41]", "ref_id": "BIBREF38"}, {"start": 642, "end": 646, "text": "[43]", "ref_id": "BIBREF40"}, {"start": 856, "end": 860, "text": "[35]", "ref_id": "BIBREF32"}, {"start": 1070, "end": 1074, "text": "[16]", "ref_id": "BIBREF13"}, {"start": 1075, "end": 1078, "text": "[7]", "ref_id": "BIBREF4"}, {"start": 1252, "end": 1256, "text": "[34]", "ref_id": "BIBREF31"}, {"start": 1521, "end": 1525, "text": "[38]", "ref_id": "BIBREF35"}], "section": "Related work", "sec_num": "8."}, {"text": "However, when the API-related text and the query do not share similar words, these methods would be invalid. Therefore, our approach takes the structural information of API in code to complement the semantic information of API to deal with the situations where such methods are hard to handle.", "cite_spans": [], "section": "Related work", "sec_num": "8."}, {"text": "Many researchers try to obtain richer knowledge from large-scale API-related data for API recommendation through machine learning methods. Since the information of graph structure in code resource provides another dimension to improve the search accuracy and can be complementary with semantic similarity [20] , many researchers take the code resource as the training data for their methods to obtain the API knowledge contained therein. Collin McMillan et al. use the PageRank and the SAN algorithm to implement Portfolio for finding the relevant nodes in graph as the answer [26] . Anh Tuan Nguyen et al. present an API recommendation approach that taps into the predicted power of repetitive code changes to provide relevant API recommendations for developers [28] . Trong Duc Nguyen et al. develop API2Vec to learn API embeddings from API sequences extracted from the AST in source code [31] . Tam The Nguyen et al. a novel approach to learn API from bytecode by using call sequences involving the related API objects as the input the Hidden Markov model for android API recommendation [30] . Xuan Li et al. a Relationship-Aware Code Search approach for finding relevant snippets to implement a specific feature by mining the graph structure from the collected code snippets [19] . Xiaodong Gu et al. propose DEEPAPI, a learning based to generate API usage sequences for a natural language query [14] . Jue Wang et al. propose a novel approach called Usage Miner (UP-Miner) that mines succinct high-coverage usage patterns of API from source [42] . Jaroslav Fowkes et present PAM (Probabilistic API Miner), a near parameter-free probabilistic algorithm for the most API call patterns from Java corpus [11] . Ling et al. propose a novel approach for API usage recommendation, named GAPI, which uses graph neural networks (GNNs) to capture the high-order collaborative signals from API calls [21] . Phoung T. Nguyen et al. and implement FOCUS as a novel approach to provide with API calls and source code while they are Nevertheless, these approaches usually require large-scale code as training data. Processing and maintaining such a codebase brings high costs.", "cite_spans": [{"start": 305, "end": 309, "text": "[20]", "ref_id": "BIBREF17"}, {"start": 577, "end": 581, "text": "[26]", "ref_id": "BIBREF23"}, {"start": 763, "end": 767, "text": "[28]", "ref_id": "BIBREF25"}, {"start": 891, "end": 895, "text": "[31]", "ref_id": "BIBREF28"}, {"start": 1090, "end": 1094, "text": "[30]", "ref_id": "BIBREF27"}, {"start": 1279, "end": 1283, "text": "[19]", "ref_id": "BIBREF16"}, {"start": 1400, "end": 1404, "text": "[14]", "ref_id": "BIBREF11"}, {"start": 1546, "end": 1550, "text": "[42]", "ref_id": "BIBREF39"}, {"start": 1705, "end": 1709, "text": "[11]", "ref_id": "BIBREF8"}, {"start": 1894, "end": 1898, "text": "[21]", "ref_id": "BIBREF18"}], "section": "Related work", "sec_num": "8."}, {"text": "Research shows that evolutionary search can generate optimal solutions at an acceptable computational cost [36] based on a lightweight dataset. By taking these factors into account, some researchers explore the API recommendation issue from another direction. They begin to use the evolutionary algorithms for Web service API knowledge recommendation. Mihai Suciu et al. consider the hybridization between adaptive heuristics and the multi-objective algorithm to search for an optimal compromise among three objectives related to a variant of the Qos-based Web service composition [40] . Yang Yu et al. propose F-MOGP, a new search and optimization approach based on the reducing space searching strategy, to handle many objectives when solving high-dimensional the QoS-based Web service composition problem [44] . Nuri Almarimi et al. introduce an automated approach to recommend service sets for automatic mashup creation [10] . Weifeng Pan et al. propose a novel Mashup service clustering approach based on structural similarity and genetic algorithm based clustering algorithm [32] .", "cite_spans": [{"start": 107, "end": 111, "text": "[36]", "ref_id": "BIBREF33"}, {"start": 581, "end": 585, "text": "[40]", "ref_id": "BIBREF37"}, {"start": 808, "end": 812, "text": "[44]", "ref_id": "BIBREF41"}, {"start": 924, "end": 928, "text": "[10]", "ref_id": "BIBREF7"}, {"start": 1081, "end": 1085, "text": "[32]", "ref_id": "BIBREF29"}], "section": "Related work", "sec_num": "8."}, {"text": "Although these methods apply the multi-objective evolutionary computation way to solve the API recommendation problem as our approach, there are still some differences between our works. In our approach, construct a lightweight dataset for API recommendation on the characteristics of app store. Besides, we consider the structural and semantic information of APIs in the process. This enables our approach to achieve good recommendation results on small-scale datasets and is more suitable for app development.", "cite_spans": [], "section": "Related work", "sec_num": "8."}, {"text": "In this paper, we propose a multi-objective evolutionary algorithm based approach to recommend API knowledge according to developers' target functionalities. Unlike the approaches based on large-scale data for API knowledge mining and solely utilizing the semantic information of API for recommendation, our approach is lightweight by using both semantic and structural information from small-scale data, and it allows everyone to gain their own model for their development process. To achieve this goal, we first represent the API structural and semantic information from the code and API documentation separately using graph embedding and natural language processing techniques. Then, based on the information, we apply SPEA2 to find the API knowledge that satisfies the target functionality both structurally and semantically for recommendation. Finally, we further interpret the recommended information with API usage scenarios for developers to help them better understand the recommended API knowledge, and provide a guideline of our approach to introduce how to use our approach.", "cite_spans": [], "section": "Conclusion and future work", "sec_num": "9."}, {"text": "The experiments based on data from Google Play, Android Tutorial and Stack Overflow show that our approach can recommend appropriate API knowledge based on the target functionalities of developers: Precision@10, MAP@10 and MRR can be up to 0.89, 0.44 and 0.69 respectively. Moreover, our approach gains such good recommendation results based on less than 1/10 of the project number in the machine-learning-based method with short time and lower device requirement. In addition, the questionnaire survey on the user-friendliness of our recommended results shows that our recommended API knowledge is easy for developers to understand and use. It indicates the usefulness of the API recommendation results of our approach.", "cite_spans": [], "section": "Conclusion and future work", "sec_num": "9."}, {"text": "In the future, we intend to further extend the dimension of our approach to find API knowledge for implementing the target functionality more precisely by adding appropriate objective functions and developing API recommendation tools to better support app development. ", "cite_spans": [], "section": "Conclusion and future work", "sec_num": "9."}, {"text": "Xun", "cite_spans": [], "section": "CRediT authorship contribution statement", "sec_num": null}, {"text": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.", "cite_spans": [], "section": "Declaration of competing interest", "sec_num": null}, {"text": "https://github .com /lxstart1024 /APIrecommendation _MOEA.", "cite_spans": [], "section": "", "sec_num": null}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Web service api recommendation for automated mashup creation using multi-objective evolutionary search", "authors": [{"first": "Nuri", "middle": [], "last": "Almarimi", "suffix": ""}, {"first": "Ali", "middle": [], "last": "Ouni", "suffix": ""}, {"first": "Salah", "middle": [], "last": "Bouktif", "suffix": ""}, {"first": "Mohamed", "middle": ["Wiem"], "last": "Mkaouer", "suffix": ""}, {"first": "Raula", "middle": [], "last": "Gaikovina Kula", "suffix": ""}, {"first": "Mohamed", "middle": ["Aymen"], "last": "Saied", "suffix": ""}], "dblp_id": null, "year": 2019, "venue": "Appl. Soft Comput", "volume": "85", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Nuri Almarimi, Ali Ouni, Salah Bouktif, Mohamed Wiem Mkaouer, Raula Gaikovina Kula, Mohamed Aymen Saied, Web service api recommendation for automated mashup creation using multi-objective evolutionary search, Appl. Soft Comput. 85 (2019).", "links": null}, "BIBREF1": {"ref_id": "b1", "title": "Generating api call rules from version history and stack overflow posts", "authors": [{"first": "Shams", "middle": [], "last": "Azad", "suffix": ""}, {"first": "Peter", "middle": ["C"], "last": "Rigby", "suffix": ""}, {"first": "Latifa", "middle": [], "last": "Guerrouj", "suffix": ""}], "dblp_id": null, "year": 2017, "venue": "ACM Trans. Softw. Eng. Methodol", "volume": "25", "issue": "", "pages": "1--22", "other_ids": {}, "num": null, "urls": [], "raw_text": "Shams Azad, Peter C. Rigby, Latifa Guerrouj, Generating api call rules from version history and stack overflow posts, ACM Trans. Softw. Eng. Methodol. 25 (2017) 1-22.", "links": null}, "BIBREF2": {"ref_id": "b2", "title": "Comparative analysis of low discrepancy sequence-based initialization approaches using population-based algorithms for solving the global optimization problems", "authors": [{"first": "Waqas", "middle": [], "last": "Haider Bangyal", "suffix": ""}, {"first": "Kashif", "middle": [], "last": "Nisar", "suffix": ""}, {"first": "Ag", "middle": [], "last": "Asri", "suffix": ""}, {"first": "Ag", "middle": [], "last": "Ibrahim", "suffix": ""}, {"first": "Muhammad", "middle": ["Reazul"], "last": "Haque", "suffix": ""}, {"first": "Joel", "middle": ["J P C"], "last": "Rodrigues", "suffix": ""}, {"first": "Danda", "middle": ["B"], "last": "Rawat", "suffix": ""}], "dblp_id": null, "year": 2021, "venue": "Appl. Sci", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Waqas Haider Bangyal, Kashif Nisar, Ag. Asri, Ag. Ibrahim, Muhammad Reazul Haque, Joel J.P.C. Rodrigues, Danda B. Rawat, Comparative analysis of low discrepancy sequence-based initialization approaches using population-based algorithms for solving the global optimization problems, Appl. Sci. (2021).", "links": null}, "BIBREF3": {"ref_id": "b3", "title": "The impact of identifier style on effort and comprehension", "authors": [{"first": "David", "middle": ["W"], "last": "Binkley", "suffix": ""}, {"first": "Marcia", "middle": [], "last": "Dawn", "suffix": ""}, {"first": "J", "middle": [], "last": "Lawrie", "suffix": ""}, {"first": "Jonathan", "middle": ["I"], "last": "Maletic", "suffix": ""}, {"first": "Christopher", "middle": [], "last": "Morrell", "suffix": ""}, {"first": "Bonita", "middle": [], "last": "Sharif", "suffix": ""}], "dblp_id": null, "year": 2012, "venue": "Empir. Softw. Eng", "volume": "18", "issue": "", "pages": "219--276", "other_ids": {}, "num": null, "urls": [], "raw_text": "David W. Binkley, Marcia Dawn J. Lawrie, Jonathan I. Maletic, Christopher Morrell, Bonita Sharif, The impact of identifier style on effort and comprehension, Empir. Softw. Eng. 18 (2012) 219-276.", "links": null}, "BIBREF4": {"ref_id": "b4", "title": "Biker: a tool for bi-information source based api method recommendation", "authors": [{"first": "Liang", "middle": [], "last": "Cai", "suffix": ""}, {"first": "Haoye", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Qiao", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Xin", "middle": [], "last": "Xia", "suffix": ""}, {"first": "Zhenchang", "middle": [], "last": "Xing", "suffix": ""}, {"first": "D", "middle": [], "last": "Lo", "suffix": ""}], "dblp_id": "conf/sigsoft/CaiWH0X019", "year": 2019, "venue": "Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Liang Cai, Haoye Wang, Qiao Huang, Xin Xia, Zhenchang Xing, D. Lo, Biker: a tool for bi-information source based api method recommendation, in: Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2019.", "links": null}, "BIBREF5": {"ref_id": "b5", "title": "Holistic combination of structural and textual code information for context based api recommendation", "authors": [{"first": "Chi", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Xin", "middle": [], "last": "Peng", "suffix": ""}, {"first": "Zhenchang", "middle": [], "last": "Xing", "suffix": ""}, {"first": "Jun", "middle": [], "last": "Sun", "suffix": ""}, {"first": "Xin", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Yifan", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "Wenyun", "middle": [], "last": "Zhao", "suffix": ""}], "dblp_id": null, "year": 2020, "venue": "", "volume": "", "issue": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2010.07514[abs"]}, "num": null, "urls": [], "raw_text": "Chi Chen, Xin Peng, Zhenchang Xing, Jun Sun, Xin Wang, Yifan Zhao, Wenyun Zhao, Holistic combination of structural and textual code information for context based api recommendation, arXiv, arXiv:2010 .07514 [abs], 2020.", "links": null}, "BIBREF6": {"ref_id": "b6", "title": "Storydroid: automated generation of storyboard for Android apps", "authors": [{"first": "Sen", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Lingling", "middle": [], "last": "Fan", "suffix": ""}, {"first": "Chunyang", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Ting", "middle": [], "last": "Su", "suffix": ""}, {"first": "Wenhe", "middle": [], "last": "Li", "suffix": ""}, {"first": "Yang", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Lihua", "middle": [], "last": "Xu", "suffix": ""}], "dblp_id": "conf/icse/ChenFCSLLX19", "year": 2019, "venue": "IEEE/ACM 41st International Conference on Software Engineering (ICSE)", "volume": "", "issue": "", "pages": "596--607", "other_ids": {}, "num": null, "urls": [], "raw_text": "Sen Chen, Lingling Fan, Chunyang Chen, Ting Su, Wenhe Li, Yang Liu, Lihua Xu, Storydroid: automated generation of storyboard for Android apps, in: 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), 2019, pp. 596-607.", "links": null}, "BIBREF7": {"ref_id": "b7", "title": "Measuring nominal scale agreement among many raters", "authors": [{"first": "Joseph", "middle": ["L"], "last": "Fleiss", "suffix": ""}], "dblp_id": null, "year": 1971, "venue": "Psychol. Bull", "volume": "76", "issue": "", "pages": "378--382", "other_ids": {}, "num": null, "urls": [], "raw_text": "Joseph L. Fleiss, Measuring nominal scale agreement among many raters, Psychol. Bull. 76 (1971) 378-382.", "links": null}, "BIBREF8": {"ref_id": "b8", "title": "Parameter-free probabilistic api mining across github", "authors": [{"first": "M", "middle": [], "last": "Jaroslav", "suffix": ""}, {"first": "Charles", "middle": [], "last": "Fowkes", "suffix": ""}, {"first": "", "middle": [], "last": "Sutton", "suffix": ""}], "dblp_id": "conf/sigsoft/FowkesS16", "year": 2016, "venue": "Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Jaroslav M. Fowkes, Charles Sutton, Parameter-free probabilistic api mining across github, in: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, 2016.", "links": null}, "BIBREF9": {"ref_id": "b9", "title": "A neural model for method name generation from functional description", "authors": [{"first": "Sa", "middle": [], "last": "Gao", "suffix": ""}, {"first": "Chunyang", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Zhenchang", "middle": [], "last": "Xing", "suffix": ""}, {"first": "Yukun", "middle": [], "last": "Ma", "suffix": ""}, {"first": "Wen", "middle": [], "last": "Song", "suffix": ""}, {"first": "Shang-Wei", "middle": [], "last": "Lin", "suffix": ""}], "dblp_id": "conf/wcre/GaoCXMSL19", "year": 2019, "venue": "IEEE 26th International Conference on Software Analysis, Evolution and Reengineering", "volume": "", "issue": "", "pages": "414--421", "other_ids": {}, "num": null, "urls": [], "raw_text": "Sa Gao, Chunyang Chen, Zhenchang Xing, Yukun Ma, Wen Song, Shang-Wei Lin, A neural model for method name generation from functional descrip- tion, in: 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER), 2019, pp. 414-421.", "links": null}, "BIBREF10": {"ref_id": "b10", "title": "node2vec: scalable feature learning for networks", "authors": [{"first": "Aditya", "middle": [], "last": "Grover", "suffix": ""}, {"first": "Jure", "middle": [], "last": "Leskovec", "suffix": ""}], "dblp_id": "conf/kdd/GroverL16", "year": 2016, "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Aditya Grover, Jure Leskovec, node2vec: scalable feature learning for networks, in: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016.", "links": null}, "BIBREF11": {"ref_id": "b11", "title": "Deep api learning", "authors": [{"first": "Xiaodong", "middle": [], "last": "Gu", "suffix": ""}, {"first": "Hongyu", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "D", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Sunghun", "middle": [], "last": "Kim", "suffix": ""}], "dblp_id": "conf/sigsoft/GuZZK16", "year": 2016, "venue": "Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Xiaodong Gu, Hongyu Zhang, D. Zhang, Sunghun Kim, Deep api learning, in: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, 2016.", "links": null}, "BIBREF12": {"ref_id": "b12", "title": "The unreasonable effectiveness of data", "authors": [{"first": "Y", "middle": [], "last": "Alon", "suffix": ""}, {"first": "Peter", "middle": [], "last": "Halevy", "suffix": ""}, {"first": "Fernando", "middle": ["C"], "last": "Norvig", "suffix": ""}, {"first": "", "middle": [], "last": "Pereira", "suffix": ""}], "dblp_id": null, "year": 2009, "venue": "IEEE Intell. Syst", "volume": "24", "issue": "", "pages": "8--12", "other_ids": {}, "num": null, "urls": [], "raw_text": "Alon Y. Halevy, Peter Norvig, Fernando C. Pereira, The unreasonable effectiveness of data, IEEE Intell. Syst. 24 (2009) 8-12.", "links": null}, "BIBREF13": {"ref_id": "b13", "title": "Api method recommendation without worrying about the task-api knowledge gap", "authors": [{"first": "Qiao", "middle": [], "last": "Huang", "suffix": ""}, {"first": "Xin", "middle": [], "last": "Xia", "suffix": ""}, {"first": "Zhenchang", "middle": [], "last": "Xing", "suffix": ""}, {"first": "D", "middle": [], "last": "Lo", "suffix": ""}, {"first": "Xinyu", "middle": [], "last": "Wang", "suffix": ""}], "dblp_id": "conf/kbse/HuangXXLW18", "year": 2018, "venue": "IEEE/ACM International Conference on Automated Software Engineering (ASE)", "volume": "", "issue": "", "pages": "293--304", "other_ids": {}, "num": null, "urls": [], "raw_text": "Qiao Huang, Xin Xia, Zhenchang Xing, D. Lo, Xinyu Wang, Api method recommendation without worrying about the task-api knowledge gap, in: 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), 2018, pp. 293-304.", "links": null}, "BIBREF14": {"ref_id": "b14", "title": "Krugle code search architecture", "authors": [{"first": "Ken", "middle": [], "last": "Krugler", "suffix": ""}], "dblp_id": null, "year": 2013, "venue": "Finding Source Code on the Web for Remix and Reuse", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Ken Krugler, Krugle code search architecture, in: Finding Source Code on the Web for Remix and Reuse, 2013.", "links": null}, "BIBREF15": {"ref_id": "b15", "title": "Achieving balance between proximity and diversity in multi-objective evolutionary algorithm", "authors": [{"first": "Ke", "middle": [], "last": "Li", "suffix": ""}, {"first": "Sam", "middle": [], "last": "Tak Wu", "suffix": ""}, {"first": "Jingjing", "middle": [], "last": "Kwong", "suffix": ""}, {"first": "M", "middle": [], "last": "Cao", "suffix": ""}, {"first": "Jinhua", "middle": [], "last": "Li", "suffix": ""}, {"first": "Ruimin", "middle": [], "last": "Zheng", "suffix": ""}, {"first": "", "middle": [], "last": "Shen", "suffix": ""}], "dblp_id": null, "year": 2012, "venue": "Inf. Sci", "volume": "182", "issue": "", "pages": "220--242", "other_ids": {}, "num": null, "urls": [], "raw_text": "Ke Li, Sam Tak Wu Kwong, Jingjing Cao, M. Li, Jinhua Zheng, Ruimin Shen, Achieving balance between proximity and diversity in multi-objective evolutionary algorithm, Inf. Sci. 182 (2012) 220-242.", "links": null}, "BIBREF16": {"ref_id": "b16", "title": "Relationship-aware code search for javascript frameworks", "authors": [{"first": "Xuan", "middle": [], "last": "Li", "suffix": ""}, {"first": "Zerui", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Qianxiang", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Shoumeng", "middle": [], "last": "Yan", "suffix": ""}, {"first": "Tao", "middle": [], "last": "Xie", "suffix": ""}, {"first": "Hong", "middle": [], "last": "Mei", "suffix": ""}], "dblp_id": "conf/sigsoft/LiWWYXM16", "year": 2016, "venue": "Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Xuan Li, Zerui Wang, Qianxiang Wang, Shoumeng Yan, Tao Xie, Hong Mei, Relationship-aware code search for javascript frameworks, in: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, 2016.", "links": null}, "BIBREF17": {"ref_id": "b17", "title": "Graph embedding based api graph search and recommendation", "authors": [{"first": "Chunyang", "middle": [], "last": "Ling", "suffix": ""}, {"first": "Yanzhen", "middle": [], "last": "Zou", "suffix": ""}, {"first": "Zeqi", "middle": [], "last": "Lin", "suffix": ""}, {"first": "Bing", "middle": [], "last": "Xie", "suffix": ""}], "dblp_id": null, "year": 2019, "venue": "J. Comput. Sci. Technol", "volume": "34", "issue": "", "pages": "993--1006", "other_ids": {}, "num": null, "urls": [], "raw_text": "Chunyang Ling, Yanzhen Zou, Zeqi Lin, Bing Xie, Graph embedding based api graph search and recommendation, J. Comput. Sci. Technol. 34 (2019) 993-1006.", "links": null}, "BIBREF18": {"ref_id": "b18", "title": "Graph neural network based collaborative filtering for api usage recommendation", "authors": [{"first": "Chunyang", "middle": [], "last": "Ling", "suffix": ""}, {"first": "Yanzhen", "middle": [], "last": "Zou", "suffix": ""}, {"first": "Bing", "middle": [], "last": "Xie", "suffix": ""}], "dblp_id": "conf/wcre/LingZX21", "year": 2021, "venue": "2021 IEEE International Conference on Software Analysis, Evolution and Reengineering", "volume": "", "issue": "", "pages": "36--47", "other_ids": {}, "num": null, "urls": [], "raw_text": "Chunyang Ling, Yanzhen Zou, Bing Xie, Graph neural network based collaborative filtering for api usage recommendation, in: 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), 2021, pp. 36-47.", "links": null}, "BIBREF19": {"ref_id": "b19", "title": "Sourcerer: mining and searching Internet-scale software repositories", "authors": [{"first": "Erik", "middle": ["J"], "last": "Linstead", "suffix": ""}, {"first": "Krishna", "middle": [], "last": "Sushil", "suffix": ""}, {"first": "Trung", "middle": [], "last": "Bajracharya", "suffix": ""}, {"first": "Chi", "middle": [], "last": "Ngo", "suffix": ""}, {"first": "Paul", "middle": [], "last": "Rigor", "suffix": ""}, {"first": "Cristina", "middle": ["V"], "last": "Lopes", "suffix": ""}, {"first": "Pierre", "middle": [], "last": "Baldi", "suffix": ""}], "dblp_id": null, "year": 2008, "venue": "Data Min. Knowl. Discov", "volume": "18", "issue": "", "pages": "300--336", "other_ids": {}, "num": null, "urls": [], "raw_text": "Erik J. Linstead, Sushil Krishna Bajracharya, Trung Chi Ngo, Paul Rigor, Cristina V. Lopes, Pierre Baldi, Sourcerer: mining and searching Internet-scale software repositories, Data Min. Knowl. Discov. 18 (2008) 300-336.", "links": null}, "BIBREF20": {"ref_id": "b20", "title": "Application programming interface recommendation according to the knowledge indexed by app feature mined from app stores", "authors": [{"first": "Lei", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Xun", "middle": [], "last": "Li", "suffix": ""}, {"first": "Yuzhou", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Huaxiao", "middle": [], "last": "Liu", "suffix": ""}], "dblp_id": null, "year": 2021, "venue": "J. Softw. Evol. Process", "volume": "33", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Lei Liu, Xun Li, Yuzhou Liu, Huaxiao Liu, Application programming interface recommendation according to the knowledge indexed by app feature mined from app stores, J. Softw. Evol. Process 33 (2021).", "links": null}, "BIBREF21": {"ref_id": "b21", "title": "Mining domain knowledge from app descriptions", "authors": [{"first": "Yuzhou", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Lei", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Huaxiao", "middle": [], "last": "Liu", "suffix": ""}, {"first": "Xiaoyu", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Hongji", "middle": [], "last": "Yang", "suffix": ""}], "dblp_id": null, "year": 2017, "venue": "J. Syst. Softw", "volume": "133", "issue": "", "pages": "126--144", "other_ids": {}, "num": null, "urls": [], "raw_text": "Yuzhou Liu, Lei Liu, Huaxiao Liu, Xiaoyu Wang, Hongji Yang, Mining domain knowledge from app descriptions, J. Syst. Softw. 133 (2017) 126-144.", "links": null}, "BIBREF22": {"ref_id": "b22", "title": "An empirical study of api stability and adoption in the Android ecosystem", "authors": [{"first": "Tyler", "middle": [], "last": "Mcdonnell", "suffix": ""}, {"first": "Baishakhi", "middle": [], "last": "Ray", "suffix": ""}, {"first": "Miryung", "middle": [], "last": "Kim", "suffix": ""}], "dblp_id": "conf/icsm/McDonnellRK13", "year": 2013, "venue": "2013 IEEE International Conference on Software Maintenance", "volume": "", "issue": "", "pages": "70--79", "other_ids": {}, "num": null, "urls": [], "raw_text": "Tyler McDonnell, Baishakhi Ray, Miryung Kim, An empirical study of api stability and adoption in the Android ecosystem, in: 2013 IEEE International Conference on Software Maintenance, 2013, pp. 70-79.", "links": null}, "BIBREF23": {"ref_id": "b23", "title": "Portfolio: Finding Relevant Functions and Their Usages", "authors": [{"first": "Collin", "middle": [], "last": "Mcmillan", "suffix": ""}, {"first": "Mary", "middle": [], "last": "Williamsburg", "suffix": ""}, {"first": "Qing", "middle": [], "last": "Xie", "suffix": ""}], "dblp_id": null, "year": 2011, "venue": "", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Collin McMillan, Mary Williamsburg, Qing Xie, Portfolio: Finding Relevant Functions and Their Usages, 2011.", "links": null}, "BIBREF24": {"ref_id": "b24", "title": "Distributed representations of words and phrases and their compositionality", "authors": [{"first": "Tomas", "middle": [], "last": "Mikolov", "suffix": ""}, {"first": "Ilya", "middle": [], "last": "Sutskever", "suffix": ""}, {"first": "Kai", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Gregory", "middle": ["S"], "last": "Corrado", "suffix": ""}, {"first": "Jeffrey", "middle": [], "last": "Dean", "suffix": ""}], "dblp_id": "conf/nips/MikolovSCCD13", "year": 2013, "venue": "NIPS", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, Jeffrey Dean, Distributed representations of words and phrases and their compositionality, in: NIPS, 2013.", "links": null}, "BIBREF25": {"ref_id": "b25", "title": "Api code recommendation using statistical learning from fine-grained changes", "authors": [{"first": "Anh", "middle": [], "last": "Tuan Nguyen", "suffix": ""}, {"first": "Michael", "middle": ["C"], "last": "Hilton", "suffix": ""}, {"first": "Mihai", "middle": [], "last": "Codoban", "suffix": ""}, {"first": "Anh", "middle": [], "last": "Hoan", "suffix": ""}, {"first": "Lily", "middle": [], "last": "Nguyen", "suffix": ""}, {"first": "Eli", "middle": [], "last": "Mast", "suffix": ""}, {"first": "Tien", "middle": ["Nhut"], "last": "Rademacher", "suffix": ""}, {"first": "Danny", "middle": [], "last": "Nguyen", "suffix": ""}, {"first": "", "middle": [], "last": "Dig", "suffix": ""}], "dblp_id": "conf/sigsoft/NguyenHCNMRND16", "year": 2016, "venue": "Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Anh Tuan Nguyen, Michael C. Hilton, Mihai Codoban, Hoan Anh Nguyen, Lily Mast, Eli Rademacher, Tien Nhut Nguyen, Danny Dig, Api code recommen- dation using statistical learning from fine-grained changes, in: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, 2016.", "links": null}, "BIBREF26": {"ref_id": "b26", "title": "Recommending api function calls and code snippets to support software development", "authors": [{"first": "Phuong", "middle": ["T"], "last": "Nguyen", "suffix": ""}, {"first": "Juri", "middle": [], "last": "Di Rocco", "suffix": ""}, {"first": "Claudio", "middle": ["Di"], "last": "Sipio", "suffix": ""}, {"first": "Davide", "middle": [], "last": "Di Ruscio", "suffix": ""}, {"first": "Massimiliano", "middle": [], "last": "Di Penta", "suffix": ""}], "dblp_id": null, "year": 2022, "venue": "IEEE Trans. Softw. Eng", "volume": "48", "issue": "", "pages": "2417--2438", "other_ids": {}, "num": null, "urls": [], "raw_text": "Phuong T. Nguyen, Juri Di Rocco, Claudio Di Sipio, Davide Di Ruscio, Massimiliano Di Penta, Recommending api function calls and code snippets to support software development, IEEE Trans. Softw. Eng. 48 (2022) 2417-2438.", "links": null}, "BIBREF27": {"ref_id": "b27", "title": "Learning api usages from bytecode: a statistical approach", "authors": [{"first": "Hung", "middle": [], "last": "Tam The Nguyen", "suffix": ""}, {"first": "Phong", "middle": [], "last": "Viet Pham", "suffix": ""}, {"first": "Minh", "middle": [], "last": "Vu", "suffix": ""}, {"first": "Tung", "middle": [], "last": "", "suffix": ""}, {"first": "Thanh", "middle": [], "last": "Nguyen", "suffix": ""}], "dblp_id": "conf/icse/NguyenPVN16", "year": 2016, "venue": "IEEE/ACM 38th International Conference on Software Engineering (ICSE)", "volume": "", "issue": "", "pages": "416--427", "other_ids": {}, "num": null, "urls": [], "raw_text": "Tam The Nguyen, Hung Viet Pham, Phong Minh Vu, Tung Thanh Nguyen, Learning api usages from bytecode: a statistical approach, in: 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), 2016, pp. 416-427.", "links": null}, "BIBREF28": {"ref_id": "b28", "title": "Exploring api embedding for api usages and applications", "authors": [{"first": "Trong", "middle": [], "last": "Duc Nguyen", "suffix": ""}, {"first": "Anh", "middle": ["Tuan"], "last": "Nguyen", "suffix": ""}, {"first": "Hung", "middle": [], "last": "Dang Phan", "suffix": ""}, {"first": "Tien", "middle": ["Nhut"], "last": "Nguyen", "suffix": ""}], "dblp_id": "conf/icse/NguyenNPN17", "year": 2017, "venue": "IEEE/ACM 39th International Conference on Software Engineering (ICSE)", "volume": "", "issue": "", "pages": "438--449", "other_ids": {}, "num": null, "urls": [], "raw_text": "Trong Duc Nguyen, Anh Tuan Nguyen, Hung Dang Phan, Tien Nhut Nguyen, Exploring api embedding for api usages and applications, in: 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE), 2017, pp. 438-449.", "links": null}, "BIBREF29": {"ref_id": "b29", "title": "Structure-aware mashup service clustering for cloud-based Internet of things using genetic algorithm based clustering algorithm", "authors": [{"first": "Weifeng", "middle": [], "last": "Pan", "suffix": ""}, {"first": "Chunlai", "middle": [], "last": "Chai", "suffix": ""}], "dblp_id": null, "year": 2018, "venue": "Future Gener. Comput. Syst", "volume": "87", "issue": "", "pages": "267--277", "other_ids": {}, "num": null, "urls": [], "raw_text": "Weifeng Pan, Chunlai Chai, Structure-aware mashup service clustering for cloud-based Internet of things using genetic algorithm based clustering algorithm, Future Gener. Comput. Syst. 87 (2018) 267-277.", "links": null}, "BIBREF30": {"ref_id": "b30", "title": "Deepwalk: online learning of social representations", "authors": [{"first": "Bryan", "middle": [], "last": "Perozzi", "suffix": ""}, {"first": "Rami", "middle": [], "last": "Al-Rfou", "suffix": ""}, {"first": "Steven", "middle": [], "last": "Skiena", "suffix": ""}], "dblp_id": "conf/kdd/PerozziAS14", "year": 2014, "venue": "Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Bryan Perozzi, Rami Al-Rfou, Steven Skiena, Deepwalk: online learning of social representations, in: Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2014.", "links": null}, "BIBREF31": {"ref_id": "b31", "title": "A self-confident recommender system", "authors": [{"first": "Luca", "middle": [], "last": "Ponzanelli", "suffix": ""}, {"first": "Gabriele", "middle": [], "last": "Bavota", "suffix": ""}, {"first": "Massimiliano", "middle": [], "last": "Di Penta", "suffix": ""}, {"first": "Rocco", "middle": [], "last": "Oliveto", "suffix": ""}, {"first": "Michele", "middle": ["Lanza"], "last": "Prompter", "suffix": ""}], "dblp_id": null, "year": 2014, "venue": "IEEE International Conference on Software Maintenance and Evolution", "volume": "", "issue": "", "pages": "577--580", "other_ids": {}, "num": null, "urls": [], "raw_text": "Luca Ponzanelli, Gabriele Bavota, Massimiliano Di Penta, Rocco Oliveto, Michele Lanza Prompter, A self-confident recommender system, in: 2014 IEEE International Conference on Software Maintenance and Evolution, 2014, pp. 577-580.", "links": null}, "BIBREF32": {"ref_id": "b32", "title": "Rack: automatic api recommendation using crowdsourced knowledge", "authors": [{"first": "Chanchal", "middle": [], "last": "Mohammad Masudur Rahman", "suffix": ""}, {"first": "D", "middle": [], "last": "Kumar Roy", "suffix": ""}, {"first": "", "middle": [], "last": "Lo", "suffix": ""}], "dblp_id": "conf/wcre/RahmanRL16", "year": 2016, "venue": "IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)", "volume": "1", "issue": "", "pages": "349--359", "other_ids": {}, "num": null, "urls": [], "raw_text": "Mohammad Masudur Rahman, Chanchal Kumar Roy, D. Lo, Rack: automatic api recommendation using crowdsourced knowledge, in: 2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER), vol. 1, 2016, pp. 349-359.", "links": null}, "BIBREF33": {"ref_id": "b33", "title": "Evolutionary composition of qos-aware web services: a many-objective perspective", "authors": [{"first": "Aurora", "middle": [], "last": "Ram\u00edrez", "suffix": ""}, {"first": "Jos\u00e9", "middle": [], "last": "Antonio Parejo", "suffix": ""}, {"first": "Jos\u00e9 Ra\u00fal", "middle": [], "last": "Romero", "suffix": ""}, {"first": "Sergio", "middle": [], "last": "Segura", "suffix": ""}, {"first": "Antonio", "middle": [], "last": "Ruiz Cort\u00e9s", "suffix": ""}], "dblp_id": null, "year": 2017, "venue": "Expert Syst. Appl", "volume": "72", "issue": "", "pages": "357--370", "other_ids": {}, "num": null, "urls": [], "raw_text": "Aurora Ram\u00edrez, Jos\u00e9 Antonio Parejo, Jos\u00e9 Ra\u00fal Romero, Sergio Segura, Antonio Ruiz Cort\u00e9s, Evolutionary composition of qos-aware web services: a many-objective perspective, Expert Syst. Appl. 72 (2017) 357-370.", "links": null}, "BIBREF34": {"ref_id": "b34", "title": "The effect of diversity maintenance on prediction in dynamic multi-objective optimization", "authors": [{"first": "Guo", "middle": [], "last": "Gan Ruan", "suffix": ""}, {"first": "Jinhua", "middle": [], "last": "Yu", "suffix": ""}, {"first": "Juan", "middle": [], "last": "Zheng", "suffix": ""}, {"first": "Shengxiang", "middle": [], "last": "Zou", "suffix": ""}, {"first": "", "middle": [], "last": "Yang", "suffix": ""}], "dblp_id": null, "year": 2017, "venue": "Appl. Soft Comput", "volume": "58", "issue": "", "pages": "631--647", "other_ids": {}, "num": null, "urls": [], "raw_text": "Gan Ruan, Guo Yu, Jinhua Zheng, Juan Zou, Shengxiang Yang, The effect of diversity maintenance on prediction in dynamic multi-objective optimization, Appl. Soft Comput. 58 (2017) 631-647.", "links": null}, "BIBREF35": {"ref_id": "b35", "title": "Postfinder: mining stack overflow posts to support software developers", "authors": [{"first": "Riccardo", "middle": [], "last": "Rubei", "suffix": ""}, {"first": "Claudio", "middle": ["Di"], "last": "Sipio", "suffix": ""}, {"first": "Phuong", "middle": ["T"], "last": "Nguyen", "suffix": ""}, {"first": "Juri", "middle": [], "last": "Di Rocco", "suffix": ""}, {"first": "Davide", "middle": [], "last": "Di Ruscio", "suffix": ""}], "dblp_id": null, "year": 2020, "venue": "Inf. Softw. Technol", "volume": "127", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Riccardo Rubei, Claudio Di Sipio, Phuong T. Nguyen, Juri Di Rocco, Davide Di Ruscio, Postfinder: mining stack overflow posts to support software developers, Inf. Softw. Technol. 127 (2020) 106367.", "links": null}, "BIBREF36": {"ref_id": "b36", "title": "Comprehensive integration of api usage patterns", "authors": [{"first": "Qi", "middle": [], "last": "Shen", "suffix": ""}, {"first": "Shijun", "middle": [], "last": "Wu", "suffix": ""}, {"first": "Yanzhen", "middle": [], "last": "Zou", "suffix": ""}, {"first": "Bing", "middle": [], "last": "Xie", "suffix": ""}], "dblp_id": "conf/iwpc/ShenWZX21", "year": 2021, "venue": "IEEE/ACM 29th International Conference on Program Comprehension (ICPC)", "volume": "", "issue": "", "pages": "83--93", "other_ids": {}, "num": null, "urls": [], "raw_text": "Qi Shen, Shijun Wu, Yanzhen Zou, Bing Xie, Comprehensive integration of api usage patterns, in: 2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC), 2021, pp. 83-93.", "links": null}, "BIBREF37": {"ref_id": "b37", "title": "Adaptive moea/d for qos-based web service composition", "authors": [{"first": "Alexandru", "middle": [], "last": "Mihai", "suffix": ""}, {"first": "Denis", "middle": [], "last": "Suciu", "suffix": ""}, {"first": "Marcel", "middle": [], "last": "Pallez", "suffix": ""}, {"first": "", "middle": [], "last": "Cremene", "suffix": ""}, {"first": "Dan", "middle": [], "last": "Dumitru", "suffix": ""}, {"first": "", "middle": [], "last": "Dumitrescu", "suffix": ""}], "dblp_id": "conf/evoW/SuciuPCD13", "year": 2013, "venue": "", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Mihai Alexandru Suciu, Denis Pallez, Marcel Cremene, Dumitru Dan Dumitrescu, Adaptive moea/d for qos-based web service composition, in: EvoCOP, 2013.", "links": null}, "BIBREF38": {"ref_id": "b38", "title": "Automatic recommendation of api methods from feature requests", "authors": [{"first": "Ferdian", "middle": [], "last": "Thung", "suffix": ""}, {"first": "Shaowei", "middle": [], "last": "Wang", "suffix": ""}, {"first": "D", "middle": [], "last": "Lo", "suffix": ""}, {"first": "Julia", "middle": ["L"], "last": "Lawall", "suffix": ""}], "dblp_id": "conf/kbse/ThungWLL13", "year": 2013, "venue": "IEEE/ACM International Conference on Automated Software Engineering (ASE)", "volume": "", "issue": "", "pages": "290--300", "other_ids": {}, "num": null, "urls": [], "raw_text": "Ferdian Thung, Shaowei Wang, D. Lo, Julia L. Lawall, Automatic recommendation of api methods from feature requests, in: 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE), 2013, pp. 290-300.", "links": null}, "BIBREF39": {"ref_id": "b39", "title": "Mining succinct and high-coverage api usage patterns from source code", "authors": [{"first": "Jue", "middle": [], "last": "Wang", "suffix": ""}, {"first": "Yingnong", "middle": [], "last": "Dang", "suffix": ""}, {"first": "Hongyu", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "Kai", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Tao", "middle": [], "last": "Xie", "suffix": ""}, {"first": "D", "middle": [], "last": "Zhang", "suffix": ""}], "dblp_id": "conf/msr/WangDZCXZ13", "year": 2013, "venue": "2013 10th Working Conference on Mining Software Repositories (MSR)", "volume": "", "issue": "", "pages": "319--328", "other_ids": {}, "num": null, "urls": [], "raw_text": "Jue Wang, Yingnong Dang, Hongyu Zhang, Kai Chen, Tao Xie, D. Zhang, Mining succinct and high-coverage api usage patterns from source code, in: 2013 10th Working Conference on Mining Software Repositories (MSR), 2013, pp. 319-328.", "links": null}, "BIBREF40": {"ref_id": "b40", "title": "From word embeddings to document similarities for improved information retrieval in software engineering", "authors": [{"first": "Xin", "middle": [], "last": "Ye", "suffix": ""}, {"first": "Hui", "middle": [], "last": "Shen", "suffix": ""}, {"first": "Xiao", "middle": [], "last": "Ma", "suffix": ""}, {"first": "Razvan", "middle": ["C"], "last": "Bunescu", "suffix": ""}, {"first": "Chang", "middle": [], "last": "Liu", "suffix": ""}], "dblp_id": "conf/icse/YeSMBL16", "year": 2016, "venue": "IEEE/ACM 38th International Conference Software Engineering (ICSE)", "volume": "", "issue": "", "pages": "404--415", "other_ids": {}, "num": null, "urls": [], "raw_text": "Xin Ye, Hui Shen, Xiao Ma, Razvan C. Bunescu, Chang Liu, From word embeddings to document similarities for improved information retrieval in software engineering, in: 2016 IEEE/ACM 38th International Conference Software Engineering (ICSE), 2016, pp. 404-415.", "links": null}, "BIBREF41": {"ref_id": "b41", "title": "F-mogp: a novel many-objective evolutionary approach to qos-aware data intensive web service composition", "authors": [{"first": "Yang", "middle": [], "last": "Yu", "suffix": ""}, {"first": "Hui", "middle": ["Mengjie"], "last": "Zhang", "suffix": ""}], "dblp_id": "conf/cec/YuMZ15", "year": 2015, "venue": "IEEE Congress on Evolutionary Computation (CEC)", "volume": "", "issue": "", "pages": "2843--2850", "other_ids": {}, "num": null, "urls": [], "raw_text": "Yang Yu, Hui Mengjie Zhang, F-mogp: a novel many-objective evolutionary approach to qos-aware data intensive web service composition, in: 2015 IEEE Congress on Evolutionary Computation (CEC), 2015, pp. 2843-2850.", "links": null}, "BIBREF42": {"ref_id": "b42", "title": "Api recommendation for event-driven Android application development", "authors": [{"first": "Weizhao", "middle": [], "last": "Yuan", "suffix": ""}, {"first": "H", "middle": [], "last": "Hoang", "suffix": ""}, {"first": "Lingxiao", "middle": [], "last": "Nguyen", "suffix": ""}, {"first": "Yuting", "middle": [], "last": "Jiang", "suffix": ""}, {"first": "Jianjun", "middle": [], "last": "Chen", "suffix": ""}, {"first": "Haibo", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "", "middle": [], "last": "Yu", "suffix": ""}], "dblp_id": null, "year": 2019, "venue": "Inf. Softw. Technol", "volume": "107", "issue": "", "pages": "30--47", "other_ids": {}, "num": null, "urls": [], "raw_text": "Weizhao Yuan, Hoang H. Nguyen, Lingxiao Jiang, Yuting Chen, Jianjun Zhao, Haibo Yu, Api recommendation for event-driven Android application development, Inf. Softw. Technol. 107 (2019) 30-47.", "links": null}, "BIBREF43": {"ref_id": "b43", "title": "Improving the Strength Pareto Evolutionary Algorithm", "authors": [{"first": "Eckart", "middle": [], "last": "Zitzler", "suffix": ""}, {"first": "Marco", "middle": [], "last": "Laumanns", "suffix": ""}, {"first": "Lothar", "middle": [], "last": "Thiele", "suffix": ""}], "dblp_id": null, "year": 2001, "venue": "", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Eckart Zitzler, Marco Laumanns, Lothar Thiele, Spea2: Improving the Strength Pareto Evolutionary Algorithm, 2001.", "links": null}}}, "ner": [{"syntactic": ["machine learning", "natural language processing", "data mining", "optimal solutions", "recommendation methods", "recommendation", "graph embeddings", "semantics", "multi-objective optimization problem", "semantic information", "genetic algorithms"], "semantic": ["machine learning", "natural language processing", "data mining", "personalized recommendation", "multi-objective optimisation", "optimal solutions", "recommendation", "recommendation systems", "recommender systems", "semantics", "recommendation methods", "semantic information", "genetic algorithms", "collaborative filtering"], "union": ["machine learning", "natural language processing", "multi-objective optimisation", "optimal solutions", "recommendation", "recommendation systems", "semantics", "multi-objective optimization problem", "recommendation methods", "recommender systems", "semantic information", "collaborative filtering", "data mining", "personalized recommendation", "graph embeddings", "genetic algorithms"], "enhanced": ["artificial intelligence", "natural languages", "evolutionary algorithms", "computer systems", "optimization problems", "recommendation algorithms", "information retrieval", "computer science", "graph theory"], "Metrics": [], "ProgLang": [], "Dataset": [], "MathTerm": [], "IT Framework": [], "ISO": [], "Technology": ["Google"], "Terms": ["APIs", "MAP@N", "API"], "TechName": []}]}