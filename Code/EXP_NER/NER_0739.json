{"paper_id": "0739", "header": {"generated_with": "S2ORC 1.0.0", "date_generated": "2024-03-20T17:53:06.117969Z"}, "title": "IoT Malware Data Augmentation using a Generative Adversarial Network", "authors": [{"first": "John", "middle": [], "last": "Carter", "suffix": "", "affiliation": {"laboratory": "", "institution": "Drexel University", "location": {}}, "email": ""}, {"first": "Pavlos", "middle": [], "last": "Protopapas", "suffix": "", "affiliation": {"laboratory": "", "institution": "Harvard University", "location": {}}, "email": "pavlos@seas.harvard.edu"}, {"first": "Spiros", "middle": [], "last": "Mancoridis", "suffix": "", "affiliation": {"laboratory": "", "institution": "Drexel University", "location": {}}, "email": ""}, {"first": "Erick", "middle": [], "last": "Galinkin", "suffix": "", "affiliation": {"laboratory": "", "institution": "Drexel University", "location": {}}, "email": ""}], "year": "", "venue": null, "identifiers": {}, "abstract": "Behavioral malware detection has been shown to be an effective method for detecting malware running on computing hosts. Machine learning (ML) models are often used for this task, which use representative behavioral data from a device to make a classification as to whether an observation is malware or not. Although these models can perform well, machine learning models in security are often trained on imbalanced training datasets that yield poor real-world efficacy, as they favor the overrepresented class. Thus, we need a way to augment the underrepresented class. Some common data augmentation techniques include SMOTE, data resampling/upsampling, or using generative algorithms. In this work, we explore using generative algorithms for this task, and show how those results compare to results obtained using SMOTE and upsampling. Specifically, we feed the less-represented class of data into a Generative Adversarial Network (GAN) to create enough realistic synthetic data to balance the dataset. In this work, we show how using a GAN to balance a dataset that favors benign data helps a shallow Neural Network achieve a higher Area Under the Receiver Operating Characteristic Curve (AUC) and a lower False Positive Rate (FPR).", "pdf_parse": {"abstract": [{"text": "Behavioral malware detection has been shown to be an effective method for detecting malware running on computing hosts. Machine learning (ML) models are often used for this task, which use representative behavioral data from a device to make a classification as to whether an observation is malware or not. Although these models can perform well, machine learning models in security are often trained on imbalanced training datasets that yield poor real-world efficacy, as they favor the overrepresented class. Thus, we need a way to augment the underrepresented class. Some common data augmentation techniques include SMOTE, data resampling/upsampling, or using generative algorithms. In this work, we explore using generative algorithms for this task, and show how those results compare to results obtained using SMOTE and upsampling. Specifically, we feed the less-represented class of data into a Generative Adversarial Network (GAN) to create enough realistic synthetic data to balance the dataset. In this work, we show how using a GAN to balance a dataset that favors benign data helps a shallow Neural Network achieve a higher Area Under the Receiver Operating Characteristic Curve (AUC) and a lower False Positive Rate (FPR).", "cite_spans": [], "section": "Abstract", "sec_num": null}], "body_text": [{"text": "Machine learning models are able to take a small amount of data and produce an accurate classification of whether an observation is malware or not. In the behavioral setting, it is difficult to collect a representative sample of normal, benign usage in a real-world environment and an equally balanced sample that introduces malware into that same environment. For behavioral malware classification, this means that the data are composed of a majority class -in our case, the benign data -that greatly outrepresents the malware data (He & Garcia, 2009) . A binary classification problem with heavily imbalanced data yields a classifier with a high false positive rate -a phenomenon very detrimental to a task as important as malware detection.", "cite_spans": [{"start": 533, "end": 552, "text": "(He & Garcia, 2009)", "ref_id": "BIBREF14"}], "section": "Introduction", "sec_num": "1."}, {"text": "We seek to mitigate the problem of imbalanced data by using a Generative Adversarial Network (GAN). Using the GAN, we synthesize more malware data from the small datasets collected on the device to balance the amount of malware data and benign data with the intent of improving the efficacy of the classifier. We show that while a classifier trained on only a small, real dataset can have a slightly higher accuracy than a classifier trained with synthetic data, the FPR is unacceptably high and the AUC is significantly lower. Likewise, we also show that using data augmentation techniques such as SMOTE and Imbalanced Learn's RandomOverSampler yield slightly higher accuracy, but an even higher FPR and lower AUC, which makes both of these methods unusable for our task. On the contrary, a classifier trained using synthetic data from a GAN has a similar accuracy, a much lower FPR, and a significantly higher AUC, making it the more practical and useful option for malware detection.", "cite_spans": [], "section": "Introduction", "sec_num": "1."}, {"text": "The real malware data consist of kernel-level system calls of the operating system (Forrest et al., 1996; Liu et al., 2005) run on an embedded system Internet of Things (IoT) device during periods of known benign behavior, as well as during separate, controlled periods where malware was implanted on the device. We choose to use system calls because they are one of the most explanatory and complete ways to determine the current behavior of a device. In an effort to confront Advanced Persistent Threats (APT), our malware data consists of two conventional APT-inspired backdoor malware samples and a behaviorally-metamorphic APT-inspired backdoor. Our conventional APTs have fixed data exfiltration rates and wait times between exfiltrations, whereas our new APT sample randomizes both of these parameters for more unpredictable behavior. We refer to this new type of malware as behaviorally metamorphic malware. The behaviorally metamorphic APT malware sample attempts to evade behavioral detection similarly to how jitter is used by malware like Emotet (Joshi et al., 2022) .", "cite_spans": [{"start": 83, "end": 105, "text": "(Forrest et al., 1996;", "ref_id": "BIBREF10"}, {"start": 106, "end": 123, "text": "Liu et al., 2005)", "ref_id": "BIBREF20"}, {"start": 1058, "end": 1078, "text": "(Joshi et al., 2022)", "ref_id": "BIBREF16"}], "section": "Introduction", "sec_num": "1."}, {"text": "In our work, we specifically examine backdoor malware, like those used by APTs. An APT can be described as a cyberattack that compromises a target host or network for a prolonged period of time for the purpose of passive surveillance or active data exfiltration (Li et al., 2011) . Unlike many other types of attackers, an APT is more concerned with data exfiltration than harming devices on a network (Zhao et al., 2015) . The malware used in this work are tasked with automatically exfiltrating files on the infected devices to a remote server specified by the Command and Control (C&C) server.", "cite_spans": [{"start": 262, "end": 279, "text": "(Li et al., 2011)", "ref_id": "BIBREF19"}, {"start": 402, "end": 421, "text": "(Zhao et al., 2015)", "ref_id": "BIBREF29"}], "section": "Previous Work", "sec_num": "2."}, {"text": "Behavioral malware detection seeks to detect malicious activity by learning the functionality and actions of malware during its execution (Aslan & Samet, 2020) . Traditionally, behavioral heuristics were written by human analysts for particular malware families. Today, behavioral malware detection often uses machine learning models to observe malware behavior using system or network data -in our case, kernel-level system calls. In one study by Hasan et al. (Hasan et al., 2019) , a variety of machine learning models were used, such as Support Vector Machines, Random Forests, Decision Trees, and Neural Networks. As opposed to signature-based detections, behavioral approaches are effective because they remain capable of detecting malware even if its code or instruction set changes, since the malware's behavior will be similar, if not identical. The drawbacks to this type of approach -as with many machine learning approaches -are that it can be prone to dataset bias, and it is often difficult to distinguish between benign and malware behaviors (Aslan & Samet, 2020; Pokrywka, 2008) . One reason it is difficult to distinguish between benign and malicious activity is due to ongoing benign behaviors even in the presence of malware, since the benign functionality of a device does not cease when malware is executed. This is especially true for malware that focuses on subtle data exploration and exfiltration rather than obvious, destructive acts such as encrypting the host's file systems in the case of e.g., ransomware. In this work, we seek to mitigate the drawbacks of behavioral malware detection, which establishes the basis for our current work: to improve performance and usability of behavioral malware detectors by distinguishing more clearly between benign and malicious behaviors and, importantly, lower the false positive rate.", "cite_spans": [{"start": 138, "end": 159, "text": "(Aslan & Samet, 2020)", "ref_id": "BIBREF2"}, {"start": 448, "end": 481, "text": "Hasan et al. (Hasan et al., 2019)", "ref_id": "BIBREF13"}, {"start": 1056, "end": 1077, "text": "(Aslan & Samet, 2020;", "ref_id": "BIBREF2"}, {"start": 1078, "end": 1093, "text": "Pokrywka, 2008)", "ref_id": "BIBREF24"}], "section": "Behavioral Malware Detection", "sec_num": "2.1."}, {"text": "There has been previous work on APT malware detection using network traffic data and DNS information (Marchetti et al., 2016; Zhao et al., 2015) , as well as through event correlation (Brogi & Tong, 2016) , which attempts to determine whether certain APT attack phases have been initiated (Han et al., 2021) . There has also been work in using threat intelligence models for APT detection (Han et al., 2021) .", "cite_spans": [{"start": 101, "end": 125, "text": "(Marchetti et al., 2016;", "ref_id": "BIBREF21"}, {"start": 126, "end": 144, "text": "Zhao et al., 2015)", "ref_id": "BIBREF29"}, {"start": 184, "end": 204, "text": "(Brogi & Tong, 2016)", "ref_id": "BIBREF5"}, {"start": 289, "end": 307, "text": "(Han et al., 2021)", "ref_id": "BIBREF12"}, {"start": 389, "end": 407, "text": "(Han et al., 2021)", "ref_id": "BIBREF12"}], "section": "Behavioral Malware Detection", "sec_num": "2.1."}, {"text": "In addition to well-known dataset augmentation techniques such as SMOTE (Chawla et al., 2002) , there has been some work in augmenting imbalanced datasets using GANs, such as work by Zhou et al. (Zhou et al., 2018) . Many of these, such as work by Sampath et al. and Kim et al. pertain to computer vision problems (Kim et al., 2020; Sampath et al., 2021) . There is prior work on the use of GANs for data augmentation in malware detection (Chen et al., 2021) , but that work focuses on the problem of static analysis by treating binaries as images -a technique similar to that of Raff et al. (Raff et al., 2018) . They compare those results with other traditional augmentation techniques for image datasets, such as flipping, cutting, and zooming.", "cite_spans": [{"start": 72, "end": 93, "text": "(Chawla et al., 2002)", "ref_id": "BIBREF6"}, {"start": 183, "end": 214, "text": "Zhou et al. (Zhou et al., 2018)", "ref_id": "BIBREF30"}, {"start": 248, "end": 285, "text": "Sampath et al. and Kim et al. pertain", "ref_id": null}, {"start": 314, "end": 332, "text": "(Kim et al., 2020;", "ref_id": "BIBREF18"}, {"start": 333, "end": 354, "text": "Sampath et al., 2021)", "ref_id": "BIBREF28"}, {"start": 439, "end": 458, "text": "(Chen et al., 2021)", "ref_id": "BIBREF7"}, {"start": 580, "end": 611, "text": "Raff et al. (Raff et al., 2018)", "ref_id": "BIBREF25"}], "section": "Data Augmentation Techniques", "sec_num": "2.2."}, {"text": "To our knowledge, there has not been work in the area of using kernel-level system calls for APT behavioral malware detection, especially work that emphasizes lowering the false-positive rate using synthetically-generated data from a GAN. To this end, we show that using system calls for APT malware detection is effective and practical, especially when using a model trained with GAN-generated synthetic data.", "cite_spans": [], "section": "Data Augmentation Techniques", "sec_num": "2.2."}, {"text": "A Generative Adversarial Network is a type of generative machine learning model described by a zero-sum two-player game between a Discriminator and a Generator (Farnia & Ozdaglar, 2020; Goodfellow et al., 2014) . The Generator takes random numbers as input and generates a synthetic data to feed to the Discriminator. The Discriminator takes a sample as input and outputs the probability that the sample is real rather than created by the Generator. Although the GAN's training process is a competition between the Generator and the Discriminator, each of them are not able to control the opponent's parameters directly.", "cite_spans": [{"start": 160, "end": 185, "text": "(Farnia & Ozdaglar, 2020;", "ref_id": "BIBREF9"}, {"start": 186, "end": 210, "text": "Goodfellow et al., 2014)", "ref_id": "BIBREF11"}], "section": "Generative Adversarial Networks", "sec_num": "2.3."}, {"text": "There has been a great deal of progress in GANs since their inception in the paper by Goodfellow et al. (Goodfellow et al., 2014) , such as Conditional GANs (Mirza & Osindero, 2014) and Wasserstein GANs (or WGAN) (Arjovsky et al., 2017) . In this work, we use the original Goodfellow et al. GAN implementation due to its simplicity and sufficiency for our task.", "cite_spans": [{"start": 86, "end": 129, "text": "Goodfellow et al. (Goodfellow et al., 2014)", "ref_id": "BIBREF11"}, {"start": 157, "end": 181, "text": "(Mirza & Osindero, 2014)", "ref_id": "BIBREF22"}, {"start": 213, "end": 236, "text": "(Arjovsky et al., 2017)", "ref_id": "BIBREF0"}], "section": "Generative Adversarial Networks", "sec_num": "2.3."}, {"text": "Our dataset consists of benign data collected under normal conditions and malicious data that is collected during periods of malware execution. Training and testing data contain both benign and malware data. While the testing data is balanced between benign and malware data, the training dataset heavily favors benign data since it more accurately represents the true distribution of the device's behavior. The malware training data was collected during periods when two conventional APTs were run.", "cite_spans": [], "section": "Dataset Composition", "sec_num": "3.1."}, {"text": "The malware testing data was collected during a period in which our behaviorally-metamorphic APT was run. Conventional APTs in this context refer to the regularity of the exfiltration behavior of APTs. This type of behavior is representative of APT samples found in the wild. In contrast, the behaviorally-metamorphic APT we have designed and implemented randomizes both the exfiltration time and wait time between exfiltrations. This behavior is depicted in Figure 1 , where the x-axis represents the exfiltration time and the y-axis represents the wait time between exfiltrations. Each data point represents a successive pair of time periods where the malware works and then sleeps for a period of time.", "cite_spans": [], "section": "Dataset Composition", "sec_num": "3.1."}, {"text": "We chose to use the conventional APTs for the malware training data and the behaviorally-metamorphic APT for testing to see how well the ML model can generalize from training on a dataset of more similar data points to testing on a sparser dataset. Since we believe sophisticated malware behavior is more similar to our APT that could be found in the wild and which exfiltrates at regular intervals, while the futuristic behaviorally-metamorphic APT is our attempt at modeling an APT that exfiltrates at randomized intervals.", "cite_spans": [], "section": "Dataset Composition", "sec_num": "3.1."}, {"text": "behaviorally-metamorphic APT, we aim to see how well we can detect this type of malware with classifiers trained on more primitive APT behavior.", "cite_spans": [], "section": "Dataset Composition", "sec_num": "3.1."}, {"text": "The data consist of system call traces obtained from an IoT device. The system call sensor is run during periods of benign behavior, when no malware is present on the device, as well as during separate periods when malware is running on the device. The benign data consist of communication between two other components of the ecosystem: an IoT camera and a client app viewing the camera's live video feed. This communication between ecosystem components provides a foundation for realistic IoT device behavior. The malware data consist of system calls generated by the malware's execution in addition to the normal, benign, use of the IoT camera and client app. As noted above, three APT datasets are used in the malware data: two conventional APTs and one behaviorally-metamorphic APT.", "cite_spans": [], "section": "Dataset Acquisition", "sec_num": "3.2."}, {"text": "The initial data processing step involves grouping the collected data into segments that are more useful for behavioral malware detection. Figure 2 details this process in addition to the explanation below. After the raw system calls are logged, they are grouped by timestamp using a user-specified window size. This window size can be thought of as a parameter that breaks up the total amount of data collection time into a user-specified number of buckets. Through experimentation, we set the window size to be 10 milliseconds, though this is a tunable parameter. A bag-of-n-grams approach was then used in the groupings (Kang et al., 2005; Liu et al., 2005) , where the value of n was user-specified (Aslan & Samet, 2020) . This means that the feature set is composed of the number of observations of each n consecutive system calls in a particular time window. Through empirical analysis, we found that a value of n = 1 is optimal for both performance efficiency and detection efficacy in our data set. Since we chose a value of n = 1, the feature set consists simply of the number of times each system call was observed during each time window.", "cite_spans": [{"start": 623, "end": 642, "text": "(Kang et al., 2005;", "ref_id": "BIBREF17"}, {"start": 643, "end": 660, "text": "Liu et al., 2005)", "ref_id": "BIBREF20"}, {"start": 703, "end": 724, "text": "(Aslan & Samet, 2020)", "ref_id": "BIBREF2"}], "section": "Initial Data Processing", "sec_num": "3.3."}, {"text": "An auxiliary data processing approach we tried was using Term Frequency-Inverse Document Frequency (TF-IDF) (Ramos, 2003) , which normalizes the system call counts instead of using only the total number of times the system call was seen. Although the final accuracy of the malware detector was slightly boosted from using TF-IDF, the FPR also went up slightly. From that we can conclude that TF-IDF provides no significant benefits over using the raw counts of system calls observed in a particular time window.", "cite_spans": [{"start": 108, "end": 121, "text": "(Ramos, 2003)", "ref_id": "BIBREF26"}], "section": "Initial Data Processing", "sec_num": "3.3."}, {"text": "After the data has been processed, they are fed to an autoencoder.", "cite_spans": [], "section": "Autoencoder", "sec_num": "3.4."}, {"text": "An autoencoder is an unsupervised learning model responsible for learning data representations (Baldi, 2011) . By simplifying the data and removing as much distortion and noise as possible, the output provides more useful data for other machine learning models (Baldi, 2011; Rumelhart et al., 1986) . In our case, we seek to reduce the noise in our data prior to feeding it to the GAN, as well as the classifier to improve the performance of the models. The input feature set is reduced from the number of features to 256 nodes, then 128, and finally 32 nodes. After this, the same number of nodes is used for each output layer.", "cite_spans": [{"start": 95, "end": 108, "text": "(Baldi, 2011)", "ref_id": "BIBREF3"}, {"start": 261, "end": 274, "text": "(Baldi, 2011;", "ref_id": "BIBREF3"}, {"start": 275, "end": 298, "text": "Rumelhart et al., 1986)", "ref_id": "BIBREF27"}], "section": "Autoencoder", "sec_num": "3.4."}, {"text": "Data input to the Autoencoder were split into a 2/3 training, 1/3 testing set. The autoencoder was trained using the Adam optimizer (Kingma & Ba, 2014) with a learning rate of 1 \u00d7 e-3 and a weight decay of 1 \u00d7 e-3.", "cite_spans": [{"start": 132, "end": 151, "text": "(Kingma & Ba, 2014)", "ref_id": "BIBREF19"}], "section": "Autoencoder", "sec_num": "3.4."}, {"text": "After collecting real data from the IoT device, we fork the process such that one branch feeds only the real data to our neural network classifier, and the other branch feeds the malware data to the GAN, which provides additional synthetic malware data to balance the dataset that will subsequently be fed to the classifier.", "cite_spans": [], "section": "Datasets", "sec_num": "4.1."}, {"text": "The baseline benchmark for the performance of our method is Train Real/Test Real (TRTR), which is a malware classifier trained on an imbalanced dataset. Next, the same classifier architecture is fitted using a dataset comprised of benign data and synthetic malware data that balances the amount of benign and malware data, and then tested using the same test dataset that was used in the TRTR classification, which gives us Train Synthetic/Test Real (TSTR). Lastly, we create a combination training dataset that consists of the real training data used in the TRTR classification as well as synthetic data, again with the amount of synthetic data needed to balance the amount of benign and malware data. In other words, we examine the number of observations provided in the real benign and real malware data, and synthesize the amount of data needed for balance between them: the number of benign observations minus the number of malware observations. We then add these newly GAN-synthesized malware observations to the real malware data collected on-device. This combination includes real data points, which provide useful variety in the dataset, as well as a balanced dataset, which aids in preventing the classifier from being biased towards one class. In some ways, this combination dataset encompasses the best aspects of the TRTR dataset and the TSTR dataset. We denote this last dataset as (TS+TR)TR, since the training data are a combination of synthetic and real data.", "cite_spans": [], "section": "Datasets", "sec_num": "4.1."}, {"text": "In this work, we train one GAN to create malware data similar to the real malware data collected on-device. The high-level architecture of the GAN is depicted in Figure 3 . The GAN has three layers and uses batch normalization. In addition, the ReLU activation function is used between linear layers in the Generator, as well as dropout (p = 0.1) before the output layer. The leaky ReLU function (\u03b1 = 0.1) is used between linear layers in the Discriminator. The generator and the discriminator both use binary cross-entropy as their loss functions, as shown in Equation 2. During the training process, the Generator becomes better at fooling the Discriminator, while the Discriminator improves its ability to spot a fake data sample from the Generator. This two player scenario means that the Generator and Discriminator should eventually find an equilibrium in the form of the two loss functions converging. Although in our experimentation the discriminator and generator losses generally converged relatively quickly, such as the losses shown in Figure 4 , there are no convergence guarantees, in general.", "cite_spans": [], "section": "Generative Adversarial Network", "sec_num": "4.2."}, {"text": "For classification of the data samples, we use scikit-learn's MLPClassifier (Pedregosa et al., 2011) model. This model is a three-layer neural network using L2 regularization (\u03b1 = 1e-3), a logistic sigmoid activation function, and the Adam optimizer with learning rate 1e-3. Each of the parameters are user-specified and were chosen through experimentation with the data. This model was chosen for its usefulness as an all-purpose, lightweight machine learning model, which can be deployed onto any device, including a resource-constrained IoT device.", "cite_spans": [{"start": 76, "end": 100, "text": "(Pedregosa et al., 2011)", "ref_id": "BIBREF23"}], "section": "Neural Network Classifier", "sec_num": "4.3."}, {"text": "This metric, proposed by Heusel et al. (Heusel et al., 2017) , defines a distance between two data distributions, which in our case refer to the real and synthetic data distributions. We calculate the FID using the real malware distribution using data collected on the IoT device, and the synthetic malware data created by the GAN. The formula for the Fr\u00e9chet distance is given in Equation 1.", "cite_spans": [{"start": 25, "end": 60, "text": "Heusel et al. (Heusel et al., 2017)", "ref_id": "BIBREF15"}], "section": "The Fr\u00e9chet Inception Distance (FID)", "sec_num": "4.4."}, {"text": "F ID = ||\u00b5 r -\u00b5 g || 2 +T r(\u03a3 r +\u03a3 g -2(\u03a3 r \u03a3 g ) 1/2 ) (1)", "cite_spans": [], "section": "The Fr\u00e9chet Inception Distance (FID)", "sec_num": "4.4."}, {"text": "A lower FID indicates a higher quality of synthetic data. An example of how the FID looks over the course of the GAN training process as well as its eventual convergence is shown in Figure 4 . ", "cite_spans": [], "section": "The Fr\u00e9chet Inception Distance (FID)", "sec_num": "4.4."}, {"text": "Another metric is the Train-Synthetic/Test-Real (TSTR) accuracy, proposed by Esteban et al., which is the accuracy of a ML model trained on GAN-generated data and tested on a set of real data points not seen during the GAN training (Esteban et al., 2017) . This metric indicates the generalizability of the classifier since it is trained on one distinct dataset and tested on another. It also provides feedback about how well the GAN Generator is synthesizing new data. Similarly, we use the Train-Real/Test-Real (TRTR) metric, which is simply the output of training the ML classifier on real data and testing it with data not seen during training. In general, the TSTR accuracy for our experiments was relatively high given the input data, as exemplified in Figure 4 . This indicates that the ML classifier was able to generalize well between being trained on synthetic data and being tested on real data.", "cite_spans": [{"start": 232, "end": 254, "text": "(Esteban et al., 2017)", "ref_id": "BIBREF8"}], "section": "Train-Synthetic/Test-Real Accuracy", "sec_num": "4.5."}, {"text": "Lastly, we examine the loss functions for the Generator and the Discriminator. The loss function for both the Generator and the Discriminator is Binary Cross Entropy, which is defined in Equation 2.", "cite_spans": [], "section": "Binary Cross Entropy Loss", "sec_num": "4.6."}, {"text": "BCELoss = - 1 n n i=1 y i * log(p(y i ))+(1-y i ) * log(1-p(y i ))", "cite_spans": [], "section": "Binary Cross Entropy Loss", "sec_num": "4.6."}, {"text": "(2) We found that the loss functions stabilize relatively quickly as the Discriminator and Generator compete during the training process. After the losses plateaued, they would usually remain steady for the duration of the GAN training, as shown in Figure 4 .", "cite_spans": [], "section": "Binary Cross Entropy Loss", "sec_num": "4.6."}, {"text": "The figures in this section were obtained after running the aforementioned malware for several well-defined and separate data collection periods. The training data collection periods for each malware execution are denoted by the x-axis of each of Figures 5, 6 and 7, while the y-axis denotes the metrics discussed: accuracy, false positive rate, and area under the curve, respectively. The training data collection periods shown on the x-axis of each of the figures represent only the duration of malware execution data, while the benign training data is held constant, at 120 minutes for each of these collection periods. For the testing data we used a balanced dataset: 180 minutes of benign data and 180 minutes of malware data.", "cite_spans": [], "section": "Experimental Results", "sec_num": "5."}, {"text": "Despite the seeming superficiality of the execution duration, they represent a large difference in data size and capture the imbalance between benign and malware data in real-world scenarios. On the leftmost side of Figures 5, 6 and 7 , benign training data is 120 minutes compared to 2 minutes of malware data, a distribution that favors benign data 60 to 1.", "cite_spans": [], "section": "Experimental Results", "sec_num": "5."}, {"text": "For comparison with the GAN results, we also include in the following graphs the results from using SMOTE and RandomOverSampler from Imbalanced Learn. RandomOverSampler over-samples the minority Intuitively, the results show that while the classifiers trained with real data, with SMOTE, or with upsampling, performed slightly better in terms of accuracy, they are more likely to classify benign data points as malware, to a higher FPR and a lower AUC.", "cite_spans": [], "section": "Experimental Results", "sec_num": "5."}, {"text": "Conversely, the classifiers trained with only synthetic data are more reluctant to classify data points as malware, which results in a slightly lower accuracy, but a significantly higher AUC and lower FPR.", "cite_spans": [], "section": "Experimental Results", "sec_num": "5."}, {"text": "Figure 5 shows the TSTR accuracy, the TRTR accuracy, as well as the accuracy in using the combination of synthetic and real training data, denoted (TS+TR)TR. For comparison, it also shows the accuracies obtained after using SMOTE and RandomOverSampler from Imbalanced Learn.", "cite_spans": [], "section": "Accuracy", "sec_num": "5.1."}, {"text": "Overall, the (TS+TR)TR, TRTR, SMOTE, and RandomOverSampler each had similar accuracies, with the TRTR accuracy closely behind it. A high accuracy using the (TS+TR)TR classifier is reasonable because this training dataset has the luxury of having some real data augmented with synthetic data. In other words, this classifier has some real data points to work with ", "cite_spans": [], "section": "Accuracy", "sec_num": "5.1."}, {"text": "The False Positive Rate measures the ratio between the number of false positives and the number of actual negative events, and is shown in Equation 3.", "cite_spans": [], "section": "False Positive Rate", "sec_num": "5.2."}, {"text": "EQUATION", "cite_spans": [], "section": "False Positive Rate", "sec_num": "5.2."}, {"text": "This is an important metric for malware detection classifiers, since it is not feasible for malware detection software to keep alerting users to malware infection that has not actually occurred.", "cite_spans": [], "section": "False Positive Rate", "sec_num": "5.2."}, {"text": "Although the accuracy was generally higher for classifiers trained using the real data, or a combination including real data, the FPR was also significantly higher for classifiers trained with those datasets. This is particularly true for the larger malware training datasets, expressed in terms of the duration of data collection, as shown on the right side of the graphs in Figure 6 .", "cite_spans": [], "section": "False Positive Rate", "sec_num": "5.2."}, {"text": "The maximum FPR for classifiers trained with real data ranges from 4%-13%, while the maximum FPR for classifiers trained with synthetic data was approximately 2% for APT 1 and 1% for APT 2, and for most data collection durations it was significantly lower than 1%.", "cite_spans": [], "section": "False Positive Rate", "sec_num": "5.2."}, {"text": "Although a 1% FPR is still higher than the acceptable rate, it is a significant improvement over a 12% FPR, which would be completely unusable for our use case.", "cite_spans": [], "section": "False Positive Rate", "sec_num": "5.2."}, {"text": "The Area Under the Curve (AUC) measures the ability of a classifier to differentiate between classes in the data, and can be used as a summary of the Receiver Operating Characteristic (ROC) curve.", "cite_spans": [], "section": "Area Under the Curve", "sec_num": "5.3."}, {"text": "AUC is an effective metric for evaluating classifiers and it has been suggested that it is actually preferable to overall accuracy for some problem domains (Bradley, 1997) . One such domain could be malware detection, since a low FPR is more important in malware detection than in other classification problems.", "cite_spans": [{"start": 156, "end": 171, "text": "(Bradley, 1997)", "ref_id": "BIBREF4"}], "section": "Area Under the Curve", "sec_num": "5.3."}, {"text": "As shown in Figure 7 , the AUC values for classifiers trained with datasets that include the GAN-generated data are consistently higher than the AUC values for classifiers trained with only real data. In this case, the classifiers trained with datasets that include the GAN-generated data are represented by the red and green lines.", "cite_spans": [], "section": "Area Under the Curve", "sec_num": "5.3."}, {"text": "In the left side of Figure 7 , the red and/or green lines are higher than the rest for all but one data point, while the red and green lines are higher than all the data points on the right side of Figure 7 . In some cases, the classifiers trained with datasets that include the GAN-generated data are able to achieve significantly higher AUC than with only the real data or using SMOTE or RandomOverSampler.", "cite_spans": [], "section": "Area Under the Curve", "sec_num": "5.3."}, {"text": "In this work, we collected real benign and malware data from an IoT device, consisting of OS kernel-level system calls.", "cite_spans": [], "section": "Conclusions", "sec_num": "6."}, {"text": "Malware data consisted of data from three types of APT-inspired backdoors: two conventional APTs with standard exfiltration behavior and one hand-crafted behaviorally-metamorphic APT with random exfiltration. We believe the future of APTs, and malware in general, will involve malware with more stealthy and random behavior in order to avoid both legacy signature-based malware detection and more recent behavioral malware detection that are not enhanced by GAN-generated data.", "cite_spans": [], "section": "Conclusions", "sec_num": "6."}, {"text": "We demonstrated that while a typical neural network classifier trained on conventional APTs and tested on the behaviorally-metamorphic APT achieves an impressive level of accuracy, it suffers from a high false positive rate and lower AUC. Many of these performance problems are due to the fact that the dataset is imbalanced, which in our case means that there is a lot more benign training data than malware training data. To lower the FPR and increase the AUC it is necessary to balance the dataset. To this end, we built and trained a Generative Adversarial Network to artificially synthesize malware data in order to make up the difference between the amount of benign and malware training data. We also used SMOTE and Oversampling for comparison, which are two common data augmentation techniques.", "cite_spans": [], "section": "Conclusions", "sec_num": "6."}, {"text": "The main contribution of this work is a ML framework in which a GAN is used to balance a dataset artificially, yielding a more effective neural network classifier with a significantly lower FPR and a significantly higher AUC without sacrificing the accuracy of the model.", "cite_spans": [], "section": "Conclusions", "sec_num": "6."}, {"text": "Although the simple GAN architecture we used was effective in boosting the efficacy of the classifier, there are new types of GANs that could yield better results. Applying some of these newer GANs, such as Conditional GANs (Mirza & Osindero, 2014) and Wasserstein GANs (WGAN) (Arjovsky et al., 2017) , to our problem space could be an interesting avenue of research to pursue. Moreover, although the neural network classifier works well off-the-shelf, other models such as Random Forests or Decision Trees could be explored as well.", "cite_spans": [{"start": 224, "end": 248, "text": "(Mirza & Osindero, 2014)", "ref_id": "BIBREF22"}, {"start": 277, "end": 300, "text": "(Arjovsky et al., 2017)", "ref_id": "BIBREF0"}], "section": "Future Work", "sec_num": "6.1."}, {"text": "Lastly, we would like to try this method using other types of malware, in addition to the APT used in this work. We believe the findings in this work will be similar given other types of malware data, but may be less useful in cases of noisier malware since noisier malware can generally be detected more easily without advanced ML.", "cite_spans": [], "section": "Future Work", "sec_num": "6.1."}, {"text": "This research was funded by the Auerbach Berger Chair of Cybersecurity held by Spiros Mancoridis.", "cite_spans": [], "section": "Acknowledgement", "sec_num": "7."}], "bib_entries": {"BIBREF0": {"ref_id": "b0", "title": "Wasserstein generative adversarial networks", "authors": [{"first": "M", "middle": [], "last": "Arjovsky", "suffix": ""}, {"first": "S", "middle": [], "last": "Chintala", "suffix": ""}, {"first": "L", "middle": [], "last": "Bottou", "suffix": ""}], "dblp_id": "conf/icml/ArjovskyCB17", "year": 2017, "venue": "Proceedings of the 34th international conference on machine learning", "volume": "", "issue": "", "pages": "214--223", "other_ids": {}, "num": null, "urls": [], "raw_text": "Arjovsky, M., Chintala, S., & Bottou, L. (2017). Wasserstein generative adversarial networks. In D. Precup & Y. W. Teh (Eds.), Proceedings of the 34th international conference on machine learning (pp. 214-223).", "links": null}, "BIBREF2": {"ref_id": "b2", "title": "A comprehensive review on malware detection approaches", "authors": [{"first": "\u00d6", "middle": ["A"], "last": "Aslan", "suffix": ""}, {"first": "R", "middle": [], "last": "Samet", "suffix": ""}], "dblp_id": null, "year": 2020, "venue": "IEEE Access", "volume": "8", "issue": "", "pages": "6249--6271", "other_ids": {}, "num": null, "urls": [], "raw_text": "Aslan, \u00d6. A., & Samet, R. (2020). A comprehensive review on malware detection approaches. IEEE Access, 8, 6249-6271.", "links": null}, "BIBREF3": {"ref_id": "b3", "title": "Autoencoders, unsupervised learning and deep architectures", "authors": [{"first": "P", "middle": [], "last": "Baldi", "suffix": ""}], "dblp_id": "journals/jmlr/Baldi12", "year": 2011, "venue": "Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop", "volume": "27", "issue": "", "pages": "37--50", "other_ids": {}, "num": null, "urls": [], "raw_text": "Baldi, P. (2011). Autoencoders, unsupervised learning and deep architectures. Proceedings of the 2011 International Conference on Unsupervised and Transfer Learning Workshop -Volume 27, 37-50.", "links": null}, "BIBREF4": {"ref_id": "b4", "title": "The use of the area under the roc curve in the evaluation of machine learning algorithms", "authors": [{"first": "A", "middle": ["P"], "last": "Bradley", "suffix": ""}], "dblp_id": null, "year": 1997, "venue": "Pattern Recognition", "volume": "30", "issue": "7", "pages": "1145--1159", "other_ids": {}, "num": null, "urls": [], "raw_text": "Bradley, A. P. (1997). The use of the area under the roc curve in the evaluation of machine learning algorithms. Pattern Recognition, 30(7), 1145-1159.", "links": null}, "BIBREF5": {"ref_id": "b5", "title": "Terminaptor: Highlighting advanced persistent threats through information flow tracking", "authors": [{"first": "G", "middle": [], "last": "Brogi", "suffix": ""}, {"first": "V", "middle": ["V T"], "last": "Tong", "suffix": ""}], "dblp_id": "conf/ntms/BrogiT16", "year": 2016, "venue": "8th IFIP International Conference on New Technologies, Mobility and Security (NTMS)", "volume": "", "issue": "", "pages": "1--5", "other_ids": {}, "num": null, "urls": [], "raw_text": "Brogi, G., & Tong, V. V. T. (2016). Terminaptor: Highlighting advanced persistent threats through information flow tracking. 2016 8th IFIP International Conference on New Technologies, Mobility and Security (NTMS), 1-5.", "links": null}, "BIBREF6": {"ref_id": "b6", "title": "Smote: Synthetic minority over-sampling technique", "authors": [{"first": "N", "middle": ["V"], "last": "Chawla", "suffix": ""}, {"first": "K", "middle": ["W"], "last": "Bowyer", "suffix": ""}, {"first": "L", "middle": ["O"], "last": "Hall", "suffix": ""}, {"first": "W", "middle": ["P"], "last": "Kegelmeyer", "suffix": ""}], "dblp_id": null, "year": 2002, "venue": "Journal of artificial intelligence research", "volume": "16", "issue": "", "pages": "321--357", "other_ids": {}, "num": null, "urls": [], "raw_text": "Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P. (2002). Smote: Synthetic minority over-sampling technique. Journal of artificial intelligence research, 16, 321-357.", "links": null}, "BIBREF7": {"ref_id": "b7", "title": "Using generative adversarial networks for data augmentation in android malware detection", "authors": [{"first": "Y.-M", "middle": [], "last": "Chen", "suffix": ""}, {"first": "C.-H", "middle": [], "last": "Yang", "suffix": ""}, {"first": "G.-C", "middle": [], "last": "Chen", "suffix": ""}], "dblp_id": "conf/desec/ChenYC21", "year": 2021, "venue": "IEEE Conference on Dependable and Secure Computing (DSC)", "volume": "", "issue": "", "pages": "1--8", "other_ids": {}, "num": null, "urls": [], "raw_text": "Chen, Y.-M., Yang, C.-H., & Chen, G.-C. (2021). Using generative adversarial networks for data augmentation in android malware detection. 2021 IEEE Conference on Dependable and Secure Computing (DSC), 1-8.", "links": null}, "BIBREF8": {"ref_id": "b8", "title": "Real-valued (medical) time series generation with recurrent conditional gans", "authors": [{"first": "C", "middle": [], "last": "Esteban", "suffix": ""}, {"first": "S", "middle": ["L"], "last": "Hyland", "suffix": ""}, {"first": "G", "middle": [], "last": "R\u00e4tsch", "suffix": ""}], "dblp_id": null, "year": 2017, "venue": "", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Esteban, C., Hyland, S. L., & R\u00e4tsch, G. (2017). Real-valued (medical) time series generation with recurrent conditional gans.", "links": null}, "BIBREF9": {"ref_id": "b9", "title": "Gans may have no nash equilibria", "authors": [{"first": "F", "middle": [], "last": "Farnia", "suffix": ""}, {"first": "A", "middle": [], "last": "Ozdaglar", "suffix": ""}], "dblp_id": null, "year": 2020, "venue": "", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Farnia, F., & Ozdaglar, A. (2020). Gans may have no nash equilibria.", "links": null}, "BIBREF10": {"ref_id": "b10", "title": "A sense of self for unix processes", "authors": [{"first": "S", "middle": [], "last": "Forrest", "suffix": ""}, {"first": "S", "middle": [], "last": "Hofmeyr", "suffix": ""}, {"first": "A", "middle": [], "last": "Somayaji", "suffix": ""}, {"first": "T", "middle": [], "last": "Longstaff", "suffix": ""}], "dblp_id": "conf/sp/ForrestHSL96", "year": 1996, "venue": "Proceedings 1996 IEEE Symposium on Security and Privacy", "volume": "", "issue": "", "pages": "120--128", "other_ids": {}, "num": null, "urls": [], "raw_text": "Forrest, S., Hofmeyr, S., Somayaji, A., & Longstaff, T. (1996). A sense of self for unix processes. Proceedings 1996 IEEE Symposium on Security and Privacy, 120-128.", "links": null}, "BIBREF11": {"ref_id": "b11", "title": "Generative adversarial nets", "authors": [{"first": "I", "middle": ["J"], "last": "Goodfellow", "suffix": ""}, {"first": "J", "middle": [], "last": "Pouget-Abadie", "suffix": ""}, {"first": "M", "middle": [], "last": "Mirza", "suffix": ""}, {"first": "B", "middle": [], "last": "Xu", "suffix": ""}, {"first": "D", "middle": [], "last": "Warde-Farley", "suffix": ""}, {"first": "S", "middle": [], "last": "Ozair", "suffix": ""}, {"first": "A", "middle": [], "last": "Courville", "suffix": ""}, {"first": "Y", "middle": [], "last": "Bengio", "suffix": ""}], "dblp_id": "conf/nips/GoodfellowPMXWOCB14", "year": 2014, "venue": "Proceedings of the 27th International Conference on Neural Information Processing Systems", "volume": "2", "issue": "", "pages": "2672--2680", "other_ids": {}, "num": null, "urls": [], "raw_text": "Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., & Bengio, Y. (2014). Generative adversarial nets. Proceedings of the 27th International Conference on Neural Information Processing Systems -Volume 2, 2672-2680.", "links": null}, "BIBREF12": {"ref_id": "b12", "title": "Aptmalinsight: Identify and cognize apt malware based on system call information and ontology knowledge framework", "authors": [{"first": "W", "middle": [], "last": "Han", "suffix": ""}, {"first": "J", "middle": [], "last": "Xue", "suffix": ""}, {"first": "Y", "middle": [], "last": "Wang", "suffix": ""}, {"first": "F", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "X", "middle": [], "last": "Gao", "suffix": ""}], "dblp_id": null, "year": 2021, "venue": "Information Sciences", "volume": "546", "issue": "", "pages": "633--664", "other_ids": {}, "num": null, "urls": [], "raw_text": "Han, W., Xue, J., Wang, Y., Zhang, F., & Gao, X. (2021). Aptmalinsight: Identify and cognize apt malware based on system call information and ontology knowledge framework. Information Sciences, 546, 633-664.", "links": null}, "BIBREF13": {"ref_id": "b13", "title": "Attack and anomaly detection in iot sensors in iot sites using machine learning approaches", "authors": [{"first": "M", "middle": [], "last": "Hasan", "suffix": ""}, {"first": "M", "middle": ["M"], "last": "Islam", "suffix": ""}, {"first": "M", "middle": ["I I"], "last": "Zarif", "suffix": ""}, {"first": "M", "middle": [], "last": "Hashem", "suffix": ""}], "dblp_id": null, "year": 2019, "venue": "Internet of Things", "volume": "7", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Hasan, M., Islam, M. M., Zarif, M. I. I., & Hashem, M. (2019). Attack and anomaly detection in iot sensors in iot sites using machine learning approaches. Internet of Things, 7, 100059.", "links": null}, "BIBREF14": {"ref_id": "b14", "title": "Learning from imbalanced data", "authors": [{"first": "H", "middle": [], "last": "He", "suffix": ""}, {"first": "E", "middle": ["A"], "last": "Garcia", "suffix": ""}], "dblp_id": null, "year": 2009, "venue": "IEEE Transactions on Knowledge and Data Engineering", "volume": "21", "issue": "9", "pages": "1263--1284", "other_ids": {}, "num": null, "urls": [], "raw_text": "He, H., & Garcia, E. A. (2009). Learning from imbalanced data. IEEE Transactions on Knowledge and Data Engineering, 21(9), 1263-1284.", "links": null}, "BIBREF15": {"ref_id": "b15", "title": "Gans trained by a two time-scale update rule converge to a local nash equilibrium", "authors": [{"first": "M", "middle": [], "last": "Heusel", "suffix": ""}, {"first": "H", "middle": [], "last": "Ramsauer", "suffix": ""}, {"first": "T", "middle": [], "last": "Unterthiner", "suffix": ""}, {"first": "B", "middle": [], "last": "Nessler", "suffix": ""}, {"first": "S", "middle": [], "last": "Hochreiter", "suffix": ""}], "dblp_id": "conf/nips/HeuselRUNH17", "year": 2017, "venue": "Proceedings of the 31st International Conference on Neural Information Processing Systems", "volume": "", "issue": "", "pages": "6629--6640", "other_ids": {}, "num": null, "urls": [], "raw_text": "Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., & Hochreiter, S. (2017). Gans trained by a two time-scale update rule converge to a local nash equilibrium. Proceedings of the 31st International Conference on Neural Information Processing Systems, 6629-6640.", "links": null}, "BIBREF16": {"ref_id": "b16", "title": "Identifying beaconing malware using elastic", "authors": [{"first": "A", "middle": [], "last": "Joshi", "suffix": ""}, {"first": "T", "middle": [], "last": "Veasey", "suffix": ""}, {"first": "C", "middle": [], "last": "Chamberlain", "suffix": ""}], "dblp_id": null, "year": 2022, "venue": "", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Joshi, A., Veasey, T., & Chamberlain, C. (2022). Identifying beaconing malware using elastic.", "links": null}, "BIBREF17": {"ref_id": "b17", "title": "Learning classifiers for misuse and anomaly detection using a bag of system calls representation", "authors": [{"first": "D.-K", "middle": [], "last": "Kang", "suffix": ""}, {"first": "D", "middle": [], "last": "Fuller", "suffix": ""}, {"first": "V", "middle": [], "last": "Honavar", "suffix": ""}], "dblp_id": null, "year": 2005, "venue": "Proceedings from the Sixth Annual IEEE SMC Information Assurance Workshop", "volume": "", "issue": "", "pages": "118--125", "other_ids": {}, "num": null, "urls": [], "raw_text": "Kang, D.-K., Fuller, D., & Honavar, V. (2005). Learning classifiers for misuse and anomaly detection using a bag of system calls representation. Proceedings from the Sixth Annual IEEE SMC Information Assurance Workshop, 118-125.", "links": null}, "BIBREF18": {"ref_id": "b18", "title": "Gan-based anomaly detection in imbalance problems", "authors": [{"first": "J", "middle": [], "last": "Kim", "suffix": ""}, {"first": "K", "middle": [], "last": "Jeong", "suffix": ""}, {"first": "H", "middle": [], "last": "Choi", "suffix": ""}, {"first": "K", "middle": [], "last": "Seo", "suffix": ""}], "dblp_id": "conf/eccv/KimJCS20", "year": 2020, "venue": "Computer Vision -ECCV 2020 Workshops", "volume": "", "issue": "", "pages": "128--145", "other_ids": {}, "num": null, "urls": [], "raw_text": "Kim, J., Jeong, K., Choi, H., & Seo, K. (2020). Gan-based anomaly detection in imbalance problems. Computer Vision -ECCV 2020 Workshops: Glasgow, UK, August 23-28, 2020, Proceedings, Part VI, 128-145.", "links": null}, "BIBREF19": {"ref_id": "b19", "title": "Evidence of advanced persistent threat: A case study of malware for political espionage", "authors": [{"first": "D", "middle": ["P"], "last": "Kingma", "suffix": ""}, {"first": "J", "middle": [], "last": "Ba", "suffix": ""}, {"first": "F", "middle": [], "last": "Li", "suffix": ""}, {"first": "A", "middle": [], "last": "Lai", "suffix": ""}, {"first": "D", "middle": [], "last": "Ddl", "suffix": ""}], "dblp_id": "conf/malware/LiLD11", "year": 2011, "venue": "6th International Conference on Malicious and Unwanted Software", "volume": "", "issue": "", "pages": "102--109", "other_ids": {}, "num": null, "urls": [], "raw_text": "Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. Li, F., Lai, A., & Ddl, D. (2011). Evidence of advanced persistent threat: A case study of malware for political espionage. 2011 6th International Conference on Malicious and Unwanted Software, 102-109.", "links": null}, "BIBREF20": {"ref_id": "b20", "title": "A comparison of system call feature representations for insider threat detection", "authors": [{"first": "A", "middle": [], "last": "Liu", "suffix": ""}, {"first": "C", "middle": [], "last": "Martin", "suffix": ""}, {"first": "T", "middle": [], "last": "Hetherington", "suffix": ""}, {"first": "S", "middle": [], "last": "Matzner", "suffix": ""}], "dblp_id": null, "year": 2005, "venue": "Proceedings from the Sixth Annual IEEE SMC Information Assurance Workshop", "volume": "", "issue": "", "pages": "340--347", "other_ids": {}, "num": null, "urls": [], "raw_text": "Liu, A., Martin, C., Hetherington, T., & Matzner, S. (2005). A comparison of system call feature representations for insider threat detection. Proceedings from the Sixth Annual IEEE SMC Information Assurance Workshop, 340-347.", "links": null}, "BIBREF21": {"ref_id": "b21", "title": "Analysis of high volumes of network traffic for advanced persistent threat detection [Traffic and Performance in the Big Data Era", "authors": [{"first": "M", "middle": [], "last": "Marchetti", "suffix": ""}, {"first": "F", "middle": [], "last": "Pierazzi", "suffix": ""}, {"first": "M", "middle": [], "last": "Colajanni", "suffix": ""}, {"first": "A", "middle": [], "last": "Guido", "suffix": ""}], "dblp_id": null, "year": 2016, "venue": "Computer Networks", "volume": "109", "issue": "", "pages": "127--141", "other_ids": {}, "num": null, "urls": [], "raw_text": "Marchetti, M., Pierazzi, F., Colajanni, M., & Guido, A. (2016). Analysis of high volumes of network traffic for advanced persistent threat detection [Traffic and Performance in the Big Data Era]. Computer Networks, 109, 127-141.", "links": null}, "BIBREF22": {"ref_id": "b22", "title": "Conditional generative adversarial nets", "authors": [{"first": "M", "middle": [], "last": "Mirza", "suffix": ""}, {"first": "S", "middle": [], "last": "Osindero", "suffix": ""}], "dblp_id": null, "year": 2014, "venue": "", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Mirza, M., & Osindero, S. (2014). Conditional generative adversarial nets.", "links": null}, "BIBREF23": {"ref_id": "b23", "title": "Scikit-learn: Machine learning in Python", "authors": [{"first": "F", "middle": [], "last": "Pedregosa", "suffix": ""}, {"first": "G", "middle": [], "last": "Varoquaux", "suffix": ""}, {"first": "A", "middle": [], "last": "Gramfort", "suffix": ""}, {"first": "V", "middle": [], "last": "Michel", "suffix": ""}, {"first": "B", "middle": [], "last": "Thirion", "suffix": ""}, {"first": "O", "middle": [], "last": "Grisel", "suffix": ""}, {"first": "M", "middle": [], "last": "Blondel", "suffix": ""}, {"first": "P", "middle": [], "last": "Prettenhofer", "suffix": ""}, {"first": "R", "middle": [], "last": "Weiss", "suffix": ""}, {"first": "V", "middle": [], "last": "Dubourg", "suffix": ""}, {"first": "J", "middle": [], "last": "Vanderplas", "suffix": ""}, {"first": "A", "middle": [], "last": "Passos", "suffix": ""}, {"first": "D", "middle": [], "last": "Cournapeau", "suffix": ""}, {"first": "M", "middle": [], "last": "Brucher", "suffix": ""}, {"first": "M", "middle": [], "last": "Perrot", "suffix": ""}, {"first": "E", "middle": [], "last": "Duchesnay", "suffix": ""}], "dblp_id": null, "year": 2011, "venue": "Journal of Machine Learning Research", "volume": "12", "issue": "", "pages": "2825--2830", "other_ids": {}, "num": null, "urls": [], "raw_text": "Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., & Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12, 2825-2830.", "links": null}, "BIBREF24": {"ref_id": "b24", "title": "Reducing false alarm rate in anomaly detection with layered filtering", "authors": [{"first": "R", "middle": [], "last": "Pokrywka", "suffix": ""}], "dblp_id": "conf/iccS/Pokrywka08", "year": 2008, "venue": "Computational science -iccs 2008", "volume": "", "issue": "", "pages": "396--404", "other_ids": {}, "num": null, "urls": [], "raw_text": "Pokrywka, R. (2008). Reducing false alarm rate in anomaly detection with layered filtering. In M. Bubak, G. D. van Albada, J. Dongarra, & P. M. A. Sloot (Eds.), Computational science -iccs 2008 (pp. 396-404). Springer Berlin Heidelberg.", "links": null}, "BIBREF25": {"ref_id": "b25", "title": "Malware detection by eating a whole exe", "authors": [{"first": "E", "middle": [], "last": "Raff", "suffix": ""}, {"first": "J", "middle": [], "last": "Barker", "suffix": ""}, {"first": "J", "middle": [], "last": "Sylvester", "suffix": ""}, {"first": "R", "middle": [], "last": "Brandon", "suffix": ""}, {"first": "B", "middle": [], "last": "Catanzaro", "suffix": ""}, {"first": "C", "middle": ["K"], "last": "Nicholas", "suffix": ""}], "dblp_id": "conf/aaai/RaffBSBCN18", "year": 2018, "venue": "Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Raff, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B., & Nicholas, C. K. (2018). Malware detection by eating a whole exe. Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence.", "links": null}, "BIBREF26": {"ref_id": "b26", "title": "Using tf-idf to determine word relevance in document queries", "authors": [{"first": "J", "middle": [], "last": "Ramos", "suffix": ""}], "dblp_id": null, "year": 2003, "venue": "", "volume": "", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Ramos, J. (2003). Using tf-idf to determine word relevance in document queries.", "links": null}, "BIBREF27": {"ref_id": "b27", "title": "Learning internal representations by error propagation", "authors": [{"first": "D", "middle": ["E"], "last": "Rumelhart", "suffix": ""}, {"first": "G", "middle": ["E"], "last": "Hinton", "suffix": ""}, {"first": "R", "middle": ["J"], "last": "Williams", "suffix": ""}], "dblp_id": null, "year": 1986, "venue": "Parallel distributed processing: Explorations in the microstructure of cognition", "volume": "1", "issue": "", "pages": "318--362", "other_ids": {}, "num": null, "urls": [], "raw_text": "Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning internal representations by error propagation. In Parallel distributed processing: Explorations in the microstructure of cognition, vol. 1: Foundations (pp. 318-362). MIT Press.", "links": null}, "BIBREF28": {"ref_id": "b28", "title": "A survey on generative adversarial networks for imbalance problems in computer vision tasks", "authors": [{"first": "V", "middle": [], "last": "Sampath", "suffix": ""}, {"first": "I", "middle": [], "last": "Maurtua", "suffix": ""}, {"first": "J", "middle": ["J A"], "last": "Mart\u00edn", "suffix": ""}, {"first": "A", "middle": [], "last": "Gutierrez", "suffix": ""}], "dblp_id": null, "year": 2021, "venue": "Journal of Big Data", "volume": "8", "issue": "", "pages": "", "other_ids": {}, "num": null, "urls": [], "raw_text": "Sampath, V., Maurtua, I., Mart\u00edn, J. J. A., & Gutierrez, A. (2021). A survey on generative adversarial networks for imbalance problems in computer vision tasks. Journal of Big Data, 8.", "links": null}, "BIBREF29": {"ref_id": "b29", "title": "Detecting apt malware infections based on malicious dns and traffic analysis", "authors": [{"first": "G", "middle": [], "last": "Zhao", "suffix": ""}, {"first": "K", "middle": [], "last": "Xu", "suffix": ""}, {"first": "L", "middle": [], "last": "Xu", "suffix": ""}, {"first": "B", "middle": [], "last": "Wu", "suffix": ""}], "dblp_id": null, "year": 2015, "venue": "IEEE Access", "volume": "3", "issue": "", "pages": "1132--1142", "other_ids": {}, "num": null, "urls": [], "raw_text": "Zhao, G., Xu, K., Xu, L., & Wu, B. (2015). Detecting apt malware infections based on malicious dns and traffic analysis. IEEE Access, 3, 1132-1142.", "links": null}, "BIBREF30": {"ref_id": "b30", "title": "Gan-based semi-supervised for imbalanced data classification", "authors": [{"first": "T", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "W", "middle": [], "last": "Liu", "suffix": ""}, {"first": "C", "middle": [], "last": "Zhou", "suffix": ""}, {"first": "L", "middle": [], "last": "Chen", "suffix": ""}], "dblp_id": null, "year": 2018, "venue": "4th International Conference on Information Management (ICIM)", "volume": "", "issue": "", "pages": "17--21", "other_ids": {}, "num": null, "urls": [], "raw_text": "Zhou, T., Liu, W., Zhou, C., & Chen, L. (2018). Gan-based semi-supervised for imbalanced data classification. 2018 4th International Conference on Information Management (ICIM), 17-21.", "links": null}}}, "ner": [{"syntactic": ["malware detection", "machine learning", "data augmentation", "generative adversarial networks", "neural networks", "malwares"], "semantic": ["malware detection", "machine learning", "data augmentation", "malicious software", "neural networks", "malicious codes", "malwares", "malware analysis"], "union": ["malware detection", "machine learning", "neural networks", "generative adversarial networks", "data augmentation", "malicious software", "malicious codes", "malwares", "malware analysis"], "enhanced": ["artificial intelligence", "bayesian analysis", "intrusion detection", "computer viruses", "operating systems", "computer crime", "network security", "dynamic analysis"], "Metrics": ["AUC", "False Positive"], "ProgLang": [], "Dataset": [], "MathTerm": [], "IT Framework": [], "ISO": [], "Technology": [], "Terms": ["FPR", "computing"], "TechName": ["GAN", "ML"]}]}